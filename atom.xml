<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title> </title>
  
  <subtitle>...chasing dreams, living reality</subtitle>
  <link href="https://ooge0.github.io/hexo-blog/atom.xml" rel="self"/>
  
  <link href="https://ooge0.github.io/hexo-blog/"/>
  <updated>2024-12-23T10:01:13.235Z</updated>
  <id>https://ooge0.github.io/hexo-blog/</id>
  
  <author>
    <name>si0n4ra</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Knowledge Graph</title>
    <link href="https://ooge0.github.io/hexo-blog/ai_nlp/knowledge_graph/"/>
    <id>https://ooge0.github.io/hexo-blog/ai_nlp/knowledge_graph/</id>
    <published>2024-12-22T09:21:11.000Z</published>
    <updated>2024-12-23T10:01:13.235Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ol><li><a href="https://sysblok.ru/glossary/knowledge-graph-ili-graf-znanij-chto-jeto-takoe-i-gde-primenjaetsja/">Read ‘Knowledge Graph или граф знаний: что это такое и где применяется’ on sysblok.ru</a></li><li><a href="https://lod-cloud.net/clouds/lod-cloud.svga"><code>Linked Open Data</code> Knowledge Graph on lod-cloud.net</a></li><li><a href="https://webmaestro.com.ua/ru/blog/knowledge-graph/">Read <code>Граф знаний Google: что это такое и как туда попасть</code> on webmaestro.com.ua</a></li><li><a href="">Read &#96;&#96; on</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://sysblok.ru/glos</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="NLP" scheme="https://ooge0.github.io/hexo-blog/tags/NLP/"/>
    
    <category term="knowledge_graph" scheme="https://ooge0.github.io/hexo-blog/tags/knowledge-graph/"/>
    
  </entry>
  
  <entry>
    <title>Remote access to Ubuntu machine via ssh. Commands.</title>
    <link href="https://ooge0.github.io/hexo-blog/devops/post_devops__remote_access_to_ubuntu_machine_via_ssh_commands/"/>
    <id>https://ooge0.github.io/hexo-blog/devops/post_devops__remote_access_to_ubuntu_machine_via_ssh_commands/</id>
    <published>2024-12-19T08:18:22.000Z</published>
    <updated>2024-12-19T15:26:38.662Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Task-List"><a href="#Task-List" class="headerlink" title="Task List:"></a>Task List:</h2><ol><li><p>Check that any SSH services are installed on the remote Linux machine  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg -l | grep ssh</span><br></pre></td></tr></table></figure></li><li><p>Check for the correct cervice name<br>Run the following command to list all available services related to SSH:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl list-units --<span class="built_in">type</span>=service | grep ssh</span><br></pre></td></tr></table></figure><p> You might see service names like:</p><ul><li>ssh.service</li><li>sshd.service</li><li>openssh-server.service</li></ul></li><li><p>Check that <code>openssh-server</code> is installed  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install openssh-server</span><br></pre></td></tr></table></figure></li><li><p>Verify the installed <code>openssh-server</code> configuration  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl status sshd</span><br></pre></td></tr></table></figure></li><li><p>Check secure SSH access via the configuration file  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure></li><li><p>Confirm that <code>openssh-server</code> is running  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl start sshd &amp;&amp; <span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> sshd</span><br></pre></td></tr></table></figure></li><li><p>Test SSH connection from a remote system  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh username@&lt;remote_machine_ip&gt;</span><br></pre></td></tr></table></figure></li><li><p>Transfer files using SSH from <code>&lt;local_machine&gt;</code> to <code>&lt;remote_machine&gt;</code>  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp /path/to/local/file username@&lt;remote_machine_ip&gt;:/path/to/remote/destination</span><br></pre></td></tr></table></figure></li></ol><h2 id="Additional-Commands"><a href="#Additional-Commands" class="headerlink" title="Additional Commands:"></a>Additional Commands:</h2><ol><li><p>Restart the SSH service after making configuration changes  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl restart sshd</span><br></pre></td></tr></table></figure></li><li><p>Check the active SSH sessions on the remote machine  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">who</span> | grep ssh</span><br></pre></td></tr></table></figure></li><li><p>Allow only key-based authentication for SSH connections  </p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /etc/ssh/sshd_config</span><br><span class="line"><span class="comment"># Change the following:</span></span><br><span class="line"><span class="comment"># PasswordAuthentication no</span></span><br><span class="line"><span class="comment"># PermitRootLogin no</span></span><br></pre></td></tr></table></figure></li><li><p>Monitor SSH access logs  </p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">tail</span> -f /var/log/auth.log</span><br></pre></td></tr></table></figure></li><li><p>Put the syste to suspend, by <code>power management</code> (alias <code>pm</code>):</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> pm-suspend</span><br></pre></td></tr></table></figure></li><li><p>Put the syste to suspend by <code>systemctl</code>:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">suspend</span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Task-List&quot;&gt;&lt;a href=&quot;#Task-List&quot; c</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="ssh" scheme="https://ooge0.github.io/hexo-blog/tags/ssh/"/>
    
    <category term="devops" scheme="https://ooge0.github.io/hexo-blog/tags/devops/"/>
    
  </entry>
  
  <entry>
    <title>Troubleshooting SSH connection termination after `sshd_config` changes</title>
    <link href="https://ooge0.github.io/hexo-blog/devops/post_devops__troubleshooting_ssh_connection_termination_after_sshd_config_changes/"/>
    <id>https://ooge0.github.io/hexo-blog/devops/post_devops__troubleshooting_ssh_connection_termination_after_sshd_config_changes/</id>
    <published>2024-12-19T08:18:22.000Z</published>
    <updated>2024-12-19T15:28:31.724Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Steps-to-verify-and-resolve-the-issue"><a href="#Steps-to-verify-and-resolve-the-issue" class="headerlink" title="Steps to verify and resolve the issue:"></a>Steps to verify and resolve the issue:</h2><ol><li><p><strong>Check if SSH server (<code>sshd</code>) is installed</strong>  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg -l | grep openssh-server</span><br></pre></td></tr></table></figure><p>If not installed:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install openssh-server</span><br></pre></td></tr></table></figure></li><li><p><strong>Check if the SSH service is active</strong><br>Identify the SSH service and verify its status:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl status ssh.service</span><br></pre></td></tr></table></figure><p>If not running:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl start ssh.service</span><br><span class="line"><span class="built_in">sudo</span> systemctl <span class="built_in">enable</span> ssh.service</span><br></pre></td></tr></table></figure><p>If the service name differs:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl list-units --<span class="built_in">type</span>=service | grep ssh</span><br></pre></td></tr></table></figure></li><li><p><strong>Validate Changes to <code>sshd_config</code></strong><br>Test for syntax errors in the configuration:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> sshd -t</span><br></pre></td></tr></table></figure><p>Correct any errors found in <code>/etc/ssh/sshd_config</code>.</p></li><li><p><strong>Prevent system suspend by disabling suspend mode.</strong><br>Temporarily disable suspend mode:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target</span><br></pre></td></tr></table></figure><p>To make this change persistent, edit <code>/etc/systemd/logind.conf</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /etc/systemd/logind.conf</span><br></pre></td></tr></table></figure><p>Add or modify the following lines:</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">HandleLidSwitch</span>=ignore</span><br><span class="line"><span class="attr">HandleSuspendKey</span>=ignore</span><br><span class="line"><span class="attr">HandleLidSwitchDocked</span>=ignore</span><br><span class="line"><span class="attr">IdleAction</span>=ignore</span><br></pre></td></tr></table></figure><p><strong>!!! IMPORTANT</strong><br>&#96;Do not mixed up configuration if you did any manipulations with preventing machine be sleeping when ‘lid’ is closed.’</p><p>Reload the configuration:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudosystemctlrestartsystemd−logindz</span><br></pre></td></tr></table></figure></li><li><p>Confirm SSH Usage</p><p>Check for active SSH sessions:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">who</span>∣grepssh</span><br></pre></td></tr></table></figure><p>Verify the SSH port is open:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudonetstat−tuln∣grep:22</span><br></pre></td></tr></table></figure><p>If using a custom port, update firewall rules:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudoufwallow&lt;customport&gt;/tcpsudoufwreload</span><br></pre></td></tr></table></figure></li><li><p>Custom scrtipt for preventing suspend mode from <strong>&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system-sleep&#x2F;</strong></p><ol><li><p>Create script fiel<code>ssh_keep_awake.sh</code> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /usr/lib/systemd/system-sleep/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure></li><li><p>Add there script for getting <code>ip</code> of connected via SSH remote machine</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># add some sleep delay to manage execution of script. </span></span><br><span class="line"><span class="built_in">sleep</span> 1</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Checking for active SSH sessions...&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the &#x27;w&#x27; command and store the output</span></span><br><span class="line">w_output=$(w -h)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;w command output: <span class="variable">$w_output</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract the IP addresses of users logged in via SSH</span></span><br><span class="line">ip=$(<span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$w_output</span>&quot;</span> | grep -oP <span class="string">&#x27;(\d&#123;1,3&#125;\.)&#123;3&#125;\d&#123;1,3&#125;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Detected IP: <span class="variable">$ip</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$ip</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;No active SSH session detected.&quot;</span></span><br><span class="line">   <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;User is still logged in from <span class="variable">$ip</span>&quot;</span></span><br><span class="line">   <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></li><li><p>Check the script location and permissions:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">ls</span> -l /usr/lib/systemd/system-sleep/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure><p>It should show something like:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-rwxr-xr-x 1 root root 123 Dec 19 14:00 /usr/lib/systemd/system-sleep/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure></li><li><p>Grant access to the file</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> +x /usr/lib/systemd/system-sleep/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure></li><li><p>For checking active SSH session on remote Linux machine execute</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w -h </span><br></pre></td></tr></table></figure><p>Console should show exisintg session for all users.</p></li><li><p>Run and check script execution via</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> /usr/lib/systemd/system-sleep/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure><p>  <strong>Expected Output:</strong></p><ul><li>The output should print the raw result of w -h and then show the detected IP address.</li><li>If there is an active SSH session, it should print “User is still logged in from <IP>“.</li><li>If no session is found, it should print “No active SSH session detected.”.</li></ul></li></ol></li><li><p>Custom scrtipt for preventing suspend mode from <strong>&#x2F;etc&#x2F;pm&#x2F;sleep.d&#x2F;</strong></p><ol><li><p>Create script fiel<code>ssh_keep_awake.sh</code> </p>   <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /usr/lib/systemd/system-sleep/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure></li><li><p>Add there script for getting <code>ip</code> of connected via SSH remote machine</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">sleep</span> 1</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Checking for active SSH sessions...&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the &#x27;w&#x27; command and store the output</span></span><br><span class="line">w_output=$(w -h)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;w command output: <span class="variable">$w_output</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extract the IP addresses of users logged in via SSH</span></span><br><span class="line">ip=$(<span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$w_output</span>&quot;</span> | grep -oP <span class="string">&#x27;(\d&#123;1,3&#125;\.)&#123;3&#125;\d&#123;1,3&#125;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Detected IP: <span class="variable">$ip</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$ip</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;No active SSH session detected.&quot;</span></span><br><span class="line">   <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">&quot;User is still logged in from <span class="variable">$ip</span>&quot;</span></span><br><span class="line">   <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></li><li><p>Check the script location and permissions:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">ls</span> -l /etc/pm/sleep.d/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure><p>It should show something like:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-rwxr-xr-x 1 root root 123 Dec 19 14:00 /etc/pm/sleep.d/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure></li><li><p>Grant access to the file</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> +x /etc/pm/sleep.d/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure></li><li><p>For checking active SSH session on remote Linux machine execute</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w -h </span><br></pre></td></tr></table></figure><p>Console should show exisintg session for all users.</p></li><li><p>Run and check script execution via</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> /etc/pm/sleep.d/ssh_keep_awake.sh</span><br></pre></td></tr></table></figure><p>  <strong>Expected Output:</strong></p><ul><li>The output should print the raw result of w -h and then show the detected IP address.</li><li>If there is an active SSH session, it should print “User is still logged in from <IP>“.</li><li>If no session is found, it should print “No active SSH session detected.”.</li></ul></li></ol></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Steps-to-verify-and-resolve-the-i</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="ssh" scheme="https://ooge0.github.io/hexo-blog/tags/ssh/"/>
    
    <category term="devops" scheme="https://ooge0.github.io/hexo-blog/tags/devops/"/>
    
  </entry>
  
  <entry>
    <title>Exploring OpenAI models locally without APIs (DRAFT-GUIDE)</title>
    <link href="https://ooge0.github.io/hexo-blog/ai/post_ai_prompt_engineer_task_llm_locally/"/>
    <id>https://ooge0.github.io/hexo-blog/ai/post_ai_prompt_engineer_task_llm_locally/</id>
    <published>2024-12-16T16:56:12.000Z</published>
    <updated>2024-12-22T17:12:23.365Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>This post related to :</em></p><ol><li><a href="/hexo-blog/ai/post_ai_prompt_engineer_task_llm_via_api/">Interaction with OpenAPI API for prompt engineering tasks(DRAFT-GUIDE)</a></li></ol><hr><p>This guide provides a structured approach to exploring OpenAI models locally, focusing on setting up a local environment and evaluating the performance and behavior of models without relying on external APIs.  </p><h2 id="Key-objectives"><a href="#Key-objectives" class="headerlink" title="Key objectives"></a>Key objectives</h2><ul><li>Set up OpenAI models on a local machine.  </li><li>Explore model behavior using local resources.  </li><li>Refine and test prompts in an offline environment.</li></ul><hr><h2 id="Steps-to-complete-the-task"><a href="#Steps-to-complete-the-task" class="headerlink" title="Steps to complete the task"></a>Steps to complete the task</h2><h3 id="1-Prepare-the-environment"><a href="#1-Prepare-the-environment" class="headerlink" title="1. Prepare the environment"></a>1. <strong>Prepare the environment</strong></h3><p>Install necessary tools and libraries to work with models locally:  </p><pre><code class="bash">pip install torch transformers  </code></pre><p>Ensure your hardware supports GPU acceleration for optimal performance. Install GPU-compatible versions of PyTorch if applicable:  </p><pre><code class="bash">pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  </code></pre><hr><h3 id="2-Download-and-set-up-models-locally"><a href="#2-Download-and-set-up-models-locally" class="headerlink" title="2. Download and set up models locally"></a>2. <strong>Download and set up models locally</strong></h3><h4 id="a-Download-pre-trained-models"><a href="#a-Download-pre-trained-models" class="headerlink" title="a. Download pre-trained models"></a>a. <strong>Download pre-trained models</strong></h4><p>Use the <code>transformers</code> library by Hugging Face to download and cache pre-trained models:  </p><pre><code class="python">from transformers import AutoModelForCausalLM, AutoTokenizer  def load_model_and_tokenizer(model_name=&quot;gpt2&quot;):      tokenizer = AutoTokenizer.from_pretrained(model_name)      model = AutoModelForCausalLM.from_pretrained(model_name)      return model, tokenizer  model, tokenizer = load_model_and_tokenizer(&quot;gpt2&quot;)  </code></pre><h4 id="b-Ensure-model-compatibility"><a href="#b-Ensure-model-compatibility" class="headerlink" title="b. Ensure model compatibility"></a>b. <strong>Ensure model compatibility</strong></h4><p>Check the system resources and configure model usage (e.g., CPU vs. GPU):  </p><pre><code class="python">import torch  device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)  model = model.to(device)  </code></pre><hr><h3 id="3-Interact-with-the-model"><a href="#3-Interact-with-the-model" class="headerlink" title="3. Interact with the model"></a>3. <strong>Interact with the model</strong></h3><h4 id="a-Generate-responses"><a href="#a-Generate-responses" class="headerlink" title="a. Generate responses"></a>a. <strong>Generate responses</strong></h4><p>Create a function to generate responses from the local model:  </p><pre><code class="python">def generate_response(prompt, model, tokenizer, max_length=50):      inputs = tokenizer.encode(prompt, return_tensors=&quot;pt&quot;).to(model.device)      outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1)      return tokenizer.decode(outputs[0], skip_special_tokens=True)  response = generate_response(&quot;What is AI?&quot;, model, tokenizer)  print(response)  </code></pre><hr><h3 id="4-Design-effective-prompts"><a href="#4-Design-effective-prompts" class="headerlink" title="4. Design effective prompts"></a>4. <strong>Design effective prompts</strong></h3><h4 id="a-Structure-prompts-for-clarity"><a href="#a-Structure-prompts-for-clarity" class="headerlink" title="a. Structure prompts for clarity"></a>a. <strong>Structure prompts for clarity</strong></h4><ul><li>Clearly define tasks or roles for the model.  </li><li>Use concise instructions with examples when necessary.</li></ul><p>Example:  </p><pre><code class="python">def structured_prompt(task_description, examples=[]):      prompt = f&quot;Task: &#123;task_description&#125;\n&quot;      for example in examples:          prompt += f&quot;Example: &#123;example&#125;\n&quot;      return prompt  custom_prompt = structured_prompt(&quot;Explain AI&quot;, [&quot;What is artificial intelligence?&quot;, &quot;Define AI applications&quot;])  </code></pre><h4 id="b-Experiment-with-settings"><a href="#b-Experiment-with-settings" class="headerlink" title="b. Experiment with settings"></a>b. <strong>Experiment with settings</strong></h4><p>Tweak parameters like temperature, top-p, and repetition penalty to modify outputs:  </p><pre><code class="python">def generate_with_settings(prompt, model, tokenizer, temperature=0.7):      inputs = tokenizer.encode(prompt, return_tensors=&quot;pt&quot;).to(model.device)      outputs = model.generate(inputs, temperature=temperature, max_length=100, top_p=0.9)      return tokenizer.decode(outputs[0], skip_special_tokens=True)  response = generate_with_settings(custom_prompt, model, tokenizer)  print(response)  </code></pre><hr><h3 id="5-Evaluate-model-performance"><a href="#5-Evaluate-model-performance" class="headerlink" title="5. Evaluate model performance"></a>5. <strong>Evaluate model performance</strong></h3><h4 id="a-Define-metrics"><a href="#a-Define-metrics" class="headerlink" title="a. Define metrics"></a>a. <strong>Define metrics</strong></h4><ul><li><strong>Accuracy</strong>: Evaluate outputs against a known dataset.  </li><li><strong>Relevance</strong>: Rate how well the output aligns with input prompts.</li></ul><h4 id="b-Analyze-outputs"><a href="#b-Analyze-outputs" class="headerlink" title="b. Analyze outputs"></a>b. <strong>Analyze outputs</strong></h4><p>Log inputs and outputs for debugging and analysis:  </p><pre><code class="python">def log_interaction(prompt, response, log_file=&quot;local_logs.txt&quot;):      with open(log_file, &quot;a&quot;) as file:          file.write(f&quot;Prompt: &#123;prompt&#125;\nResponse: &#123;response&#125;\n\n&quot;)  log_interaction(custom_prompt, response)  </code></pre><hr><h3 id="6-Optimize-model-usage"><a href="#6-Optimize-model-usage" class="headerlink" title="6. Optimize model usage"></a>6. <strong>Optimize model usage</strong></h3><h4 id="a-Batch-processing"><a href="#a-Batch-processing" class="headerlink" title="a. Batch processing"></a>a. <strong>Batch processing</strong></h4><p>Process multiple inputs in parallel for efficiency:  </p><pre><code class="python">def batch_generate(prompts, model, tokenizer):      inputs = tokenizer(prompts, return_tensors=&quot;pt&quot;, padding=True, truncation=True).to(model.device)      outputs = model.generate(**inputs, max_length=50)      return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]  batch_responses = batch_generate([&quot;What is AI?&quot;, &quot;Define machine learning&quot;], model, tokenizer)  print(batch_responses)  </code></pre><h4 id="b-Fine-tuning-for-custom-tasks"><a href="#b-Fine-tuning-for-custom-tasks" class="headerlink" title="b. Fine-tuning for custom tasks"></a>b. <strong>Fine-tuning for custom tasks</strong></h4><p>Download and fine-tune the model with a custom dataset for specific use cases.  </p><hr><h2 id="Tools-and-libraries-overview"><a href="#Tools-and-libraries-overview" class="headerlink" title="Tools and libraries overview"></a>Tools and libraries overview</h2><ul><li><strong>Model handling</strong>: Hugging Face Transformers  </li><li><strong>Performance optimization</strong>: PyTorch with GPU support  </li><li><strong>Data logging</strong>: Python’s <code>logging</code> module</li></ul><hr><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>By following these steps, you can explore OpenAI models locally without relying on external APIs. This guide provides a framework for setting up, testing, and optimizing prompts for various tasks using locally hosted models.  </p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;This post related to :&lt;/em&gt;&lt;/p&gt;
&lt;o</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="prompt_engineering" scheme="https://ooge0.github.io/hexo-blog/tags/prompt-engineering/"/>
    
    <category term="local_development" scheme="https://ooge0.github.io/hexo-blog/tags/local-development/"/>
    
  </entry>
  
  <entry>
    <title>Windows OS apps</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/12/13/post_os__windows%20app/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/12/13/post_os__windows%20app/</id>
    <published>2024-12-13T07:18:22.000Z</published>
    <updated>2024-12-16T08:25:18.485Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Monitorian"><a href="#Monitorian" class="headerlink" title="Monitorian"></a>Monitorian</h2><ul><li><strong>Monitorian app description</strong>: Monitorian is a desktop tool to adjust the brightness of multiple monitors with ease. The user can change the brightness of monitors, including external ones, either individually or in unison. In addition, the user can change the adjustable range of brightness and contrast for each monitor seamlessly.</br>To control an external monitor, the monitor must be DDC/CI compatible and the function enabled. If a monitor is connected through an converter, docking station or other device, such a device must be also compatible.<ul><li><a href="https://github.com/emoacht/Monitorian">Monitorian home page</a></li><li><a href="https://apps.microsoft.com/detail/9nw33j738bl0?hl=en-GB&gl=UA">Monitorian Microsoft store download page</a></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Monitorian&quot;&gt;&lt;a href=&quot;#Monitorian&quot;</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="apps" scheme="https://ooge0.github.io/hexo-blog/tags/apps/"/>
    
    <category term="windows_os" scheme="https://ooge0.github.io/hexo-blog/tags/windows-os/"/>
    
  </entry>
  
  <entry>
    <title>Text Generation Coherence vs. Text Generation Quality</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/12/12/post_linguistic__text_coherence_vs_text_quiality/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/12/12/post_linguistic__text_coherence_vs_text_quiality/</id>
    <published>2024-12-12T09:21:11.000Z</published>
    <updated>2024-12-12T10:54:20.189Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="1-Text-Generation-Coherence"><a href="#1-Text-Generation-Coherence" class="headerlink" title="1. Text Generation Coherence"></a>1. Text Generation Coherence</h2><p>Coherence refers to the logical and structural flow of the text. A coherent text feels connected and makes sense as a whole. It ensures that:</p><ul><li><strong>Logical Progression</strong>: Sentences and paragraphs follow each other in a natural order.</li><li><strong>Topic Consistency</strong>: The generated text remains focused on a single theme or idea.</li><li><strong>Contextual Relevance</strong>: Each part of the text relates appropriately to the previous and following parts.</li><li><strong>Absence of Contradictions</strong>: There are no logical inconsistencies or contradictory statements.</li></ul><h3 id="Example"><a href="#Example" class="headerlink" title="Example:"></a>Example:</h3><ul><li><p><strong>Coherent Text</strong>:</p><blockquote><p>“The sun was shining brightly in the clear blue sky. Birds chirped as children played in the park. It was a perfect day for a picnic.”</p></blockquote><ul><li>This is coherent because the sentences are connected and describe a single scene.</li></ul></li><li><p><strong>Incoherent Text</strong>:</p><blockquote><p>“The sun was shining. Suddenly, a spaceship landed in the park. Watermelons are tasty.”</p></blockquote><ul><li>This lacks coherence due to abrupt topic shifts and lack of logical flow.</li></ul></li></ul><p><strong>Key Challenge:</strong> Ensuring the generated text flows smoothly across different parts without jumping topics or introducing unrelated ideas.</p><hr><h2 id="2-Text-Generation-Quality"><a href="#2-Text-Generation-Quality" class="headerlink" title="2. Text Generation Quality"></a>2. Text Generation Quality</h2><p>Quality refers to how well the generated text meets overall standards of good writing. It is a broader measure that includes:</p><ul><li><strong>Grammar and Syntax</strong>: Free of grammatical errors and awkward sentence structures.</li><li><strong>Vocabulary Use</strong>: Appropriate word choice, richness of language, and precision.</li><li><strong>Creativity and Style</strong>: Ability to generate text that is engaging, varied, and stylistically appropriate for the context.</li><li><strong>Correctness</strong>: Facts and information presented are accurate.</li><li><strong>Relevance</strong>: Addresses the input or prompt directly and completely.</li></ul><h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example:"></a>Example:</h3><ul><li><p><strong>High-Quality Text</strong>:</p><blockquote><p>“Artificial intelligence has revolutionized many industries, offering unparalleled efficiency and innovation. From healthcare to finance, its impact is profound.”</p></blockquote><ul><li>This text is grammatically correct, well-structured, and relevant.</li></ul></li><li><p><strong>Low-Quality Text</strong>:</p><blockquote><p>“Artificial intelligance revolution in industries many, efficiently innovation offering. Healthcare finance profound impact is.”</p></blockquote><ul><li>This text is grammatically incorrect and poorly structured.</li></ul></li></ul><p><strong>Key Challenge:</strong> Balancing creativity, accuracy, and linguistic correctness to produce engaging and relevant content.</p><hr><h2 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h2><table><thead><tr><th><strong>Aspect</strong></th><th><strong>Text Generation Coherence</strong></th><th><strong>Text Generation Quality</strong></th></tr></thead><tbody><tr><td><strong>Focus</strong></td><td>Logical flow and connection between parts of the text.</td><td>Overall writing standards, including grammar, style, and relevance.</td></tr><tr><td><strong>Scope</strong></td><td>Specific to structural and contextual alignment.</td><td>Broader, encompassing coherence, grammar, creativity, etc.</td></tr><tr><td><strong>Evaluation</strong></td><td>Assesses transitions, logical progression, and focus.</td><td>Evaluates overall effectiveness, correctness, and engagement.</td></tr><tr><td><strong>Common Issues</strong></td><td>Topic shifts, contradictions, lack of context.</td><td>Grammatical errors, awkward phrasing, irrelevance.</td></tr></tbody></table><hr><h2 id="Real-World-Importance"><a href="#Real-World-Importance" class="headerlink" title="Real-World Importance"></a>Real-World Importance</h2><ul><li><strong>Coherence</strong> is critical for tasks requiring deep contextual understanding, such as writing long essays or technical documents.</li><li><strong>Quality</strong> is essential for creating polished and professional output, such as marketing content or customer communications.</li></ul><blockquote><p>While coherence is a subset of quality, high-quality text must always be coherent. However, coherent text might not necessarily be high-quality if it lacks creativity, relevance, or stylistic finesse.</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;1-Text-Generation-Coherence&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="NLP" scheme="https://ooge0.github.io/hexo-blog/tags/NLP/"/>
    
    <category term="linguistic" scheme="https://ooge0.github.io/hexo-blog/tags/linguistic/"/>
    
  </entry>
  
  <entry>
    <title>Fine-Tuning vs. Training Models for Specific Tasks</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/12/10/post_ai_ml_basiscs__fune_tuning_vs_training_models_for_specific_tasks/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/12/10/post_ai_ml_basiscs__fune_tuning_vs_training_models_for_specific_tasks/</id>
    <published>2024-12-10T17:30:33.000Z</published>
    <updated>2024-12-10T17:30:22.717Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Fine-tuning and training are two common approaches to adapting machine learning models for specific tasks. While training involves building a model from scratch or pre-trained weights, fine-tuning adapts an already trained model to perform well on a particular task. Below, we explore the nuances of these approaches for various popular architectures, including FFNs, CNNs, LSTMs, and Transformers.</p><hr><h2 id="Key-differences-between-fine-tuning-and-training"><a href="#Key-differences-between-fine-tuning-and-training" class="headerlink" title="Key differences between fine-tuning and training"></a>Key differences between fine-tuning and training</h2><table><thead><tr><th>Aspect</th><th>Fine-Tuning</th><th>Training</th></tr></thead><tbody><tr><td><strong>Starting Point</strong></td><td>Pre-trained model weights from a related task (e.g., ImageNet for vision, GPT for text).</td><td>Randomly initialized weights.</td></tr><tr><td><strong>Data Requirements</strong></td><td>Requires less data; leverages knowledge from the pre-trained model.</td><td>Requires large amounts of labeled data.</td></tr><tr><td><strong>Training Duration</strong></td><td>Generally shorter; only adjusts some layers.</td><td>Longer; all parameters are learned from scratch.</td></tr><tr><td><strong>Resource Needs</strong></td><td>Less compute-intensive due to reduced training scope.</td><td>High resource demands for extensive training.</td></tr><tr><td><strong>Use Case</strong></td><td>When data is limited or computational resources are constrained.</td><td>When custom architecture or large task-specific datasets are available.</td></tr></tbody></table><hr><h2 id="Baselines-for-fine-tuning-training"><a href="#Baselines-for-fine-tuning-training" class="headerlink" title="Baselines for fine-tuning&#x2F;training"></a>Baselines for fine-tuning&#x2F;training</h2><h3 id="1-Feedforward-Networks-FFNs"><a href="#1-Feedforward-Networks-FFNs" class="headerlink" title="1. Feedforward Networks (FFNs)"></a>1. Feedforward Networks (FFNs)</h3><ul><li><strong>Baseline</strong>: Fully connected layers with non-linear activations.</li><li><strong>Fine-Tuning</strong>: Modify output layers to match the target task and optionally freeze earlier layers.</li><li><strong>Training</strong>: Start with random initialization, requiring carefully tuned learning rates and weight initialization methods.</li></ul><h3 id="2-Convolutional-Neural-Networks-CNNs"><a href="#2-Convolutional-Neural-Networks-CNNs" class="headerlink" title="2. Convolutional Neural Networks (CNNs)"></a>2. Convolutional Neural Networks (CNNs)</h3><ul><li><strong>Baseline</strong>: Architectures like VGG, ResNet, or EfficientNet, pre-trained on ImageNet.</li><li><strong>Fine-Tuning</strong>: Replace the classification head to match target classes, often freezing earlier convolutional layers.</li><li><strong>Training</strong>: Train from scratch if the task involves entirely different visual domains (e.g., medical imaging).</li></ul><h3 id="3-Recurrent-Neural-Networks-RNNs-and-Variants-LSTMs-GRUs"><a href="#3-Recurrent-Neural-Networks-RNNs-and-Variants-LSTMs-GRUs" class="headerlink" title="3. Recurrent Neural Networks (RNNs) and Variants (LSTMs, GRUs)"></a>3. Recurrent Neural Networks (RNNs) and Variants (LSTMs, GRUs)</h3><ul><li><strong>Baseline</strong>: Pre-trained word embeddings (e.g., GloVe, Word2Vec) or models like ELMo.</li><li><strong>Fine-Tuning</strong>: Use pre-trained embeddings, fine-tune the LSTM layers on sequential tasks.</li><li><strong>Training</strong>: Train an LSTM network from scratch for language modeling or time-series tasks.</li></ul><h3 id="4-Transformers"><a href="#4-Transformers" class="headerlink" title="4. Transformers"></a>4. Transformers</h3><ul><li><strong>Baseline</strong>: Models like BERT, GPT, or T5.</li><li><strong>Fine-Tuning</strong>: Modify the decoder head, adjust hyperparameters like learning rate and layer freezing.</li><li><strong>Training</strong>: Start with pre-trained embeddings; for unique tasks, initialize the Transformer from scratch (high compute).</li></ul><hr><h2 id="Technical-details-of-popular-architectures"><a href="#Technical-details-of-popular-architectures" class="headerlink" title="Technical details of popular architectures"></a>Technical details of popular architectures</h2><table><thead><tr><th>Model</th><th>Baseline Task</th><th>Fine-Tuning Scope</th><th>Training Considerations</th></tr></thead><tbody><tr><td><strong>VGG16</strong></td><td>Image Classification (ImageNet)</td><td>Replace final dense layer, freeze initial layers.</td><td>High memory usage, simpler architecture to optimize.</td></tr><tr><td><strong>ResNet50</strong></td><td>Image Classification (ImageNet)</td><td>Adjust classification head; fine-tune deeper layers as needed.</td><td>Skip connections improve gradient flow.</td></tr><tr><td><strong>BERT</strong></td><td>Masked Language Model (MLM)</td><td>Modify for classification, QA, or summarization.</td><td>Pre-training requires MLM objectives.</td></tr><tr><td><strong>GPT-3</strong></td><td>Text Generation</td><td>Fine-tune specific tasks by updating decoder head.</td><td>Requires extensive GPU resources for full training.</td></tr><tr><td><strong>LSTM</strong></td><td>Sequential Data Modeling</td><td>Fine-tune on embeddings, adjust for target sequence length.</td><td>Long training times due to sequential processing.</td></tr><tr><td><strong>EfficientNet</strong></td><td>Image Classification</td><td>Replace head; scale input resolution for task-specific datasets.</td><td>Compound scaling optimizes trade-offs in performance.</td></tr></tbody></table><hr><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Fine-tuning and training models depend heavily on the task, available data, and computational resources. Fine-tuning is generally faster and resource-efficient, making it ideal for adapting large pre-trained models to specific tasks. On the other hand, training from scratch offers flexibility when creating custom architectures but demands extensive data and compute. By understanding these approaches, practitioners can select the most suitable method for their applications.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Fine-tuning and training are two commo</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Comparison of popular models and architectures</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/12/10/post_ai_nn__comparison_of_popular_models_and_architectures/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/12/10/post_ai_nn__comparison_of_popular_models_and_architectures/</id>
    <published>2024-12-10T17:30:33.000Z</published>
    <updated>2024-12-13T07:38:16.744Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Related to:</p><ul><li><a href="../../../../post_ai_nn__list_of_neural_network_models_architectures_and_basic_components">List of neural network models, architectures, and basic components</a></li></ul><hr><h2 id="Table-Single-models-with-options"><a href="#Table-Single-models-with-options" class="headerlink" title="Table  - Single models with options"></a>Table  - Single models with options</h2><h1 id="Detailed-Breakdown-of-Popular-Models-and-Architectures"><a href="#Detailed-Breakdown-of-Popular-Models-and-Architectures" class="headerlink" title="Detailed Breakdown of Popular Models and Architectures"></a>Detailed Breakdown of Popular Models and Architectures</h1><h2 id="Autoencoders"><a href="#Autoencoders" class="headerlink" title="Autoencoders"></a>Autoencoders</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Encoder, Decoder, Latent Space</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>Reconstruction Loss</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Weights (Changeable), Latent Dimensions (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Reconstruction Accuracy</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Learning Rate, Latent Dimension Size (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Lower Reconstruction Error</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Effective Latent Space Size, Training Convergence Rate</td></tr></tbody></table><h2 id="CNN-Convolutional-Neural-Networks"><a href="#CNN-Convolutional-Neural-Networks" class="headerlink" title="CNN (Convolutional Neural Networks)"></a>CNN (Convolutional Neural Networks)</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Convolution Layers, Pooling, Fully Connected Layers</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>Accuracy, Precision, Recall, F1-Score</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Filter Weights (Changeable), Input Channels (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Detection Accuracy</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Kernel Size, Stride, Number of Filters (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Higher Feature Extraction Quality</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Filter Efficiency, Computational Cost</td></tr></tbody></table><h2 id="RNN-Recurrent-Neural-Networks"><a href="#RNN-Recurrent-Neural-Networks" class="headerlink" title="RNN (Recurrent Neural Networks)"></a>RNN (Recurrent Neural Networks)</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Recurrent Layers, Activation Functions</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>Perplexity, Accuracy, BLEU Score (NLP)</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Hidden State (Changeable), Sequence Length (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Temporal Pattern Capture Efficiency</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Learning Rate, Hidden State Size (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Sequence Learning Performance</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Effective Sequence Memory Size</td></tr></tbody></table><h2 id="LSTM-Long-Short-Term-Memory-Networks"><a href="#LSTM-Long-Short-Term-Memory-Networks" class="headerlink" title="LSTM (Long Short-Term Memory Networks)"></a>LSTM (Long Short-Term Memory Networks)</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>LSTM Cells (Input, Forget, Output Gates)</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>Perplexity, Accuracy (Time-Series, NLP)</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Cell Weights (Changeable), Memory Cell (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Long-Term Dependency Capture Efficiency</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Learning Rate, Number of Layers (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Retention of Long-Term Dependencies</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Sequence Retention and Gradient Stability</td></tr></tbody></table><h2 id="GNN-Graph-Neural-Networks"><a href="#GNN-Graph-Neural-Networks" class="headerlink" title="GNN (Graph Neural Networks)"></a>GNN (Graph Neural Networks)</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Node Embeddings, Edge Features, Graph Convolutions</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>Node Classification Accuracy, Link Prediction</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Edge Weights (Changeable), Node Attributes (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Graph Feature Capture Efficiency</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Number of Layers, Embedding Size (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Graph-Level Feature Generalization</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Graph Topology Learning</td></tr></tbody></table><h2 id="BERT-Bidirectional-Encoder-Representations-from-Transformers"><a href="#BERT-Bidirectional-Encoder-Representations-from-Transformers" class="headerlink" title="BERT (Bidirectional Encoder Representations from Transformers)"></a>BERT (Bidirectional Encoder Representations from Transformers)</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Encoder, Multi-Head Attention, Feedforward Layers</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>F1-Score, Exact Match (QA), Perplexity</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Token Embeddings (Changeable), Vocabulary (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Contextual Understanding Quality</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Learning Rate, Batch Size, Sequence Length (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Contextual Embedding Accuracy</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Attention Mechanism, Positional Encoding</td></tr></tbody></table><h2 id="BART-Bidirectional-and-Auto-Regressive-Transformers"><a href="#BART-Bidirectional-and-Auto-Regressive-Transformers" class="headerlink" title="BART (Bidirectional and Auto-Regressive Transformers)"></a>BART (Bidirectional and Auto-Regressive Transformers)</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Encoder-Decoder, Multi-Head Attention, Feedforward</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>Rouge Score, BLEU Score</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Attention Weights (Changeable), Vocabulary (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Summarization and Translation Accuracy</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Learning Rate, Number of Heads (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Text Generation Quality</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Encoder-Decoder Consistency</td></tr></tbody></table><h2 id="T5-Text-to-Text-Transfer-Transformer"><a href="#T5-Text-to-Text-Transfer-Transformer" class="headerlink" title="T5 (Text-to-Text Transfer Transformer)"></a>T5 (Text-to-Text Transfer Transformer)</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Encoder-Decoder, Attention Mechanisms, Feedforward</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>Rouge Score, BLEU Score</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Token Embeddings (Changeable), Vocabulary (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Text-to-Text Conversion Accuracy</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Sequence Length, Beam Width (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Text Generation Coherence</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Attention Span, Latent Representation Quality</td></tr></tbody></table><h2 id="LLAMA"><a href="#LLAMA" class="headerlink" title="LLAMA"></a>LLAMA</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Transformer Layers, Feedforward Layers, Attention</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Restricted for Modifications</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>F1-Score, Rouge Score</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Attention Weights (Changeable), Vocabulary (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Latent Representation Consistency</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Number of Layers, Head Size (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Layer-to-Layer Weight Propagation</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Transformer Block Efficiency</td></tr></tbody></table><h2 id="GPT-Generative-Pre-trained-Transformer"><a href="#GPT-Generative-Pre-trained-Transformer" class="headerlink" title="GPT (Generative Pre-trained Transformer)"></a>GPT (Generative Pre-trained Transformer)</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Transformer Decoder, Feedforward Layers, Attention</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>Perplexity, BLEU Score</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Attention Weights (Changeable), Vocabulary (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Generative Text Coherence</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Learning Rate, Model Depth, Token Limit (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Generative Text Quality</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Token Context Understanding</td></tr></tbody></table><h2 id="ViT-Vision-Transformer"><a href="#ViT-Vision-Transformer" class="headerlink" title="ViT (Vision Transformer)"></a>ViT (Vision Transformer)</h2><table><thead><tr><th><strong>Category</strong></th><th><strong>Details</strong></th></tr></thead><tbody><tr><td><strong>Basic Components</strong></td><td>Patch Embedding, Transformer Layers, Attention</td></tr><tr><td><strong>Open-Source&#x2F; Forbidden</strong></td><td>Open-Source</td></tr><tr><td><strong>Criteria of Measuring Productivity</strong></td><td>Accuracy, Precision, Recall, F1-Score</td></tr><tr><td><strong>Model’s Parameters</strong></td><td>Patch Embeddings (Changeable), Image Size (Fixed)</td></tr><tr><td><strong>Criteria of Measuring Parameter’s Productivity</strong></td><td>Visual Feature Generalization</td></tr><tr><td><strong>Model’s Hyperparameters</strong></td><td>Patch Size, Attention Heads (Changeable)</td></tr><tr><td><strong>Criteria of Measuring Hyperparameter’s Productivity</strong></td><td>Patch Extraction Accuracy, Attention Span</td></tr><tr><td><strong>Basic Components of Hyperparameter’s Productivity</strong></td><td>Image Feature Learning Efficiency</td></tr></tbody></table><!-- ## Table - Models vs features| **Model/Architecture** | **Basic Components**                                    | **Open-Source/ Forbidden for Modifications** | **Criteria of Measuring Model Productivity** | **Model's Parameters (Changeable/Non-Changeable)** | **Criteria of Measuring Parameter's Productivity** | **Model's Hyperparameters (Changeable/Non-Changeable)** | **Criteria of Measuring Hyperparameter's Productivity** | **Basic Components of Hyperparameter's Productivity** ||-------------------------|--------------------------------------------------------|-----------------------------------------------|-----------------------------------------------|----------------------------------------------------|----------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------|| **Autoencoders**        | Encoder, Decoder, Latent Space                         | Open-Source                                   | Reconstruction Loss                            | Weights (Changeable), Latent Dimensions (Fixed)    | Reconstruction Accuracy                              | Learning Rate, Latent Dimension Size (Changeable)       | Lower Reconstruction Error                             | Effective Latent Space Size, Training Convergence Rate || **CNN**                 | Convolution Layers, Pooling, Fully Connected Layers    | Open-Source                                   | Accuracy, Precision, Recall, F1-Score         | Filter Weights (Changeable), Input Channels (Fixed)| Detection Accuracy                                   | Kernel Size, Stride, Number of Filters (Changeable)     | Higher Feature Extraction Quality                      | Filter Efficiency, Computational Cost                 || **RNN**                 | Recurrent Layers, Activation Functions                | Open-Source                                   | Perplexity, Accuracy, BLEU Score (NLP)        | Hidden State (Changeable), Sequence Length (Fixed) | Temporal Pattern Capture Efficiency                 | Learning Rate, Hidden State Size (Changeable)           | Sequence Learning Performance                          | Effective Sequence Memory Size                        || **FNN**                 | Neurons, Dense Layers, Activation Functions           | Open-Source                                   | Accuracy, Loss Reduction                       | Weights (Changeable), Bias (Fixed)                | Accuracy and Loss Reduction                          | Learning Rate, Number of Layers (Changeable)            | Loss Convergence Rate                                  | Layer Depth, Weight Initialization Strategy           || **LSTM**                | LSTM Cells (Input, Forget, Output Gates)              | Open-Source                                   | Perplexity, Accuracy (Time-Series, NLP)        | Cell Weights (Changeable), Memory Cell (Fixed)    | Long-Term Dependency Capture Efficiency             | Learning Rate, Number of Layers (Changeable)            | Retention of Long-Term Dependencies                   | Sequence Retention and Gradient Stability             || **GNN**                 | Node Embeddings, Edge Features, Graph Convolutions    | Open-Source                                   | Node Classification Accuracy, Link Prediction | Edge Weights (Changeable), Node Attributes (Fixed)| Graph Feature Capture Efficiency                    | Number of Layers, Embedding Size (Changeable)           | Graph-Level Feature Generalization                    | Graph Topology Learning                                || **BERT**                | Encoder, Multi-Head Attention, Feedforward Layers     | Open-Source                                   | F1-Score, Exact Match (QA), Perplexity         | Token Embeddings (Changeable), Vocabulary (Fixed) | Contextual Understanding Quality                    | Learning Rate, Batch Size, Sequence Length (Changeable)| Contextual Embedding Accuracy                         | Attention Mechanism, Positional Encoding              || **BART**                | Encoder-Decoder, Multi-Head Attention, Feedforward    | Open-Source                                   | Rouge Score, BLEU Score                        | Attention Weights (Changeable), Vocabulary (Fixed)| Summarization and Translation Accuracy              | Learning Rate, Number of Heads (Changeable)             | Text Generation Quality                               | Encoder-Decoder Consistency                           || **T5**                  | Encoder-Decoder, Attention Mechanisms, Feedforward    | Open-Source                                   | Rouge Score, BLEU Score                        | Token Embeddings (Changeable), Vocabulary (Fixed) | Text-to-Text Conversion Accuracy                    | Sequence Length, Beam Width (Changeable)                | Text Generation Coherence                             | Attention Span, Latent Representation Quality         || **LLAMA**               | Transformer Layers, Feedforward Layers, Attention     | Restricted for Modifications                  | F1-Score, Rouge Score                          | Attention Weights (Changeable), Vocabulary (Fixed)| Generative Output Accuracy                          | Number of Layers, Head Size (Changeable)                | Latent Representation Consistency                     | Layer-to-Layer Weight Propagation                     || **GPT**                 | Transformer Decoder, Feedforward Layers, Attention    | Open-Source                                   | Perplexity, BLEU Score                         | Attention Weights (Changeable), Vocabulary (Fixed)| Generative Text Coherence                            | Learning Rate, Model Depth, Token Limit (Changeable)    | Generative Text Quality                               | Token Context Understanding                           || **ViT (Vision Transformer)** | Patch Embedding, Transformer Layers, Attention        | Open-Source                                   | Accuracy, Precision, Recall, F1-Score         | Patch Embeddings (Changeable), Image Size (Fixed) | Image Feature Generalization                         | Patch Size, Attention Heads (Changeable)                | Visual Feature Learning Efficiency                    | Patch Extraction Accuracy, Attention Span             |---### Notes:1. **Open-Source vs. Forbidden for Modifications**: Models like LLAMA may have licensing restrictions preventing modification, while others are freely accessible for experimentation.2. **Criteria of Productivity**: Metrics vary by task, e.g., classification accuracy for vision tasks, BLEU scores for translation, or F1-scores for question-answering.3. **Parameters vs. Hyperparameters**: Parameters are learned during training (e.g., weights), whereas hyperparameters are manually set and adjusted (e.g., learning rate, number of layers).4. **Measuring Hyperparameter Productivity**: Includes monitoring loss convergence, validation performance, and computational efficiency.## Table - Features vs models# Comparison of Popular Models and Architectures| **Category**                               | **Autoencoders**                | **CNN**                            | **RNN**                             | **FNN**                             | **LSTM**                            | **GNN**                             | **BERT**                            | **BART**                            | **T5**                              | **LLAMA**                           | **GPT**                             | **ViT**                             ||--------------------------------------------|----------------------------------|-------------------------------------|--------------------------------------|--------------------------------------|--------------------------------------|--------------------------------------|--------------------------------------|--------------------------------------|--------------------------------------|--------------------------------------|--------------------------------------|--------------------------------------|| **Basic Components**                       | Encoder, Decoder, Latent Space  | Convolution Layers, Pooling, Fully Connected Layers | Recurrent Layers, Activation Functions | Neurons, Dense Layers, Activation Functions | LSTM Cells (Input, Forget, Output Gates) | Node Embeddings, Edge Features, Graph Convolutions | Encoder, Multi-Head Attention, Feedforward Layers | Encoder-Decoder, Multi-Head Attention, Feedforward | Encoder-Decoder, Attention Mechanisms, Feedforward | Transformer Layers, Feedforward Layers, Attention | Transformer Decoder, Feedforward Layers, Attention | Patch Embedding, Transformer Layers, Attention || **Open-Source/ Forbidden for Modifications** | Open-Source                     | Open-Source                        | Open-Source                          | Open-Source                          | Open-Source                          | Open-Source                          | Open-Source                          | Open-Source                          | Open-Source                          | Restricted for Modifications         | Open-Source                          | Open-Source                          || **Criteria of Measuring Model Productivity** | Reconstruction Loss             | Accuracy, Precision, Recall, F1-Score | Perplexity, Accuracy, BLEU Score (NLP) | Accuracy, Loss Reduction             | Perplexity, Accuracy (Time-Series, NLP) | Node Classification Accuracy, Link Prediction | F1-Score, Exact Match (QA), Perplexity | Rouge Score, BLEU Score             | Rouge Score, BLEU Score             | F1-Score, Rouge Score                | Perplexity, BLEU Score               | Accuracy, Precision, Recall, F1-Score || **Model's Parameters (Changeable/Non-Changeable)** | Weights (Changeable), Latent Dimensions (Fixed) | Filter Weights (Changeable), Input Channels (Fixed) | Hidden State (Changeable), Sequence Length (Fixed) | Weights (Changeable), Bias (Fixed)  | Cell Weights (Changeable), Memory Cell (Fixed) | Edge Weights (Changeable), Node Attributes (Fixed) | Token Embeddings (Changeable), Vocabulary (Fixed) | Attention Weights (Changeable), Vocabulary (Fixed) | Token Embeddings (Changeable), Vocabulary (Fixed) | Attention Weights (Changeable), Vocabulary (Fixed) | Attention Weights (Changeable), Vocabulary (Fixed) | Patch Embeddings (Changeable), Image Size (Fixed) || **Criteria of Measuring Parameter's Productivity** | Reconstruction Accuracy         | Detection Accuracy                 | Temporal Pattern Capture Efficiency  | Accuracy and Loss Reduction          | Long-Term Dependency Capture Efficiency | Graph Feature Capture Efficiency    | Contextual Understanding Quality     | Summarization and Translation Accuracy | Text-to-Text Conversion Accuracy    | Generative Output Accuracy           | Generative Text Coherence            | Image Feature Generalization         || **Model's Hyperparameters (Changeable/Non-Changeable)** | Learning Rate, Latent Dimension Size (Changeable) | Kernel Size, Stride, Number of Filters (Changeable) | Learning Rate, Hidden State Size (Changeable) | Learning Rate, Number of Layers (Changeable) | Learning Rate, Number of Layers (Changeable) | Number of Layers, Embedding Size (Changeable) | Learning Rate, Batch Size, Sequence Length (Changeable) | Learning Rate, Number of Heads (Changeable) | Sequence Length, Beam Width (Changeable) | Number of Layers, Head Size (Changeable) | Learning Rate, Model Depth, Token Limit (Changeable) | Patch Size, Attention Heads (Changeable) || **Criteria of Measuring Hyperparameter's Productivity** | Lower Reconstruction Error      | Higher Feature Extraction Quality  | Sequence Learning Performance        | Loss Convergence Rate                | Retention of Long-Term Dependencies  | Graph-Level Feature Generalization  | Contextual Embedding Accuracy        | Text Generation Quality              | Text Generation Coherence            | Latent Representation Consistency    | Generative Text Quality              | Visual Feature Learning Efficiency   || **Basic Components of Hyperparameter's Productivity** | Effective Latent Space Size, Training Convergence Rate | Filter Efficiency, Computational Cost | Effective Sequence Memory Size       | Layer Depth, Weight Initialization Strategy | Sequence Retention and Gradient Stability | Graph Topology Learning             | Attention Mechanism, Positional Encoding | Encoder-Decoder Consistency         | Attention Span, Latent Representation Quality | Layer-to-Layer Weight Propagation    | Token Context Understanding          | Patch Extraction Accuracy, Attention Span | -->]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Related to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;../.</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="NN" scheme="https://ooge0.github.io/hexo-blog/tags/NN/"/>
    
  </entry>
  
  <entry>
    <title>List of neural network models, architectures, and basic components</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/12/10/post_ai_nn__list_of_neural_network_models_architectures_and_basic_components/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/12/10/post_ai_nn__list_of_neural_network_models_architectures_and_basic_components/</id>
    <published>2024-12-10T17:30:33.000Z</published>
    <updated>2024-12-12T11:40:09.755Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Related to </p><ol><li><a href="../../../../post_ai_nn__comparison_of_popular_models_and_architectures">Comparison of Popular Models and Architectures</a></li></ol><hr><p>This document provides a categorized list of common neural network (NN) models and architectures. It also outlines their basic components and how they fit into larger systems.</p><hr><h2 id="Neural-network-models-and-architectures"><a href="#Neural-network-models-and-architectures" class="headerlink" title="Neural network models and architectures"></a><strong>Neural network models and architectures</strong></h2><table><thead><tr><th><strong>Architecture</strong></th><th><strong>Model Examples</strong></th><th><strong>Purpose</strong></th></tr></thead><tbody><tr><td><strong>Feedforward Neural Network (FNN)</strong></td><td>Basic MLP (Multi-Layer Perceptron)</td><td>General-purpose model for regression and classification tasks.</td></tr><tr><td><strong>Convolutional Neural Networks (CNN)</strong></td><td>VGG, ResNet, AlexNet, EfficientNet</td><td>Designed for image processing tasks like classification, object detection, and segmentation.</td></tr><tr><td><strong>Recurrent Neural Networks (RNNs)</strong></td><td>Vanilla RNN, LSTM, GRU</td><td>Sequential data processing for tasks like language modeling and time-series prediction.</td></tr><tr><td><strong>Transformers</strong></td><td>BERT, GPT, T5, Vision Transformer (ViT)</td><td>State-of-the-art architecture for text, sequential, and image tasks.</td></tr><tr><td><strong>Autoencoders</strong></td><td>Variational Autoencoder (VAE), Denoising Autoencoder</td><td>Dimensionality reduction, feature extraction, and generative tasks.</td></tr><tr><td><strong>Generative Adversarial Networks (GANs)</strong></td><td>DCGAN, StyleGAN, CycleGAN</td><td>Generative tasks such as image synthesis and domain transfer.</td></tr><tr><td><strong>Graph Neural Networks (GNNs)</strong></td><td>GCN, GraphSAGE, GAT</td><td>Structured data learning tasks, e.g., on graphs or social networks.</td></tr></tbody></table><hr><h2 id="Basic-Components-of-Neural-Networks"><a href="#Basic-Components-of-Neural-Networks" class="headerlink" title="Basic Components of Neural Networks"></a><strong>Basic Components of Neural Networks</strong></h2><table><thead><tr><th><strong>Component</strong></th><th><strong>Description</strong></th><th><strong>Applications</strong></th></tr></thead><tbody><tr><td><strong>Neuron</strong></td><td>Basic computation unit applying a weighted sum followed by an activation function.</td><td>Foundational unit in all neural networks.</td></tr><tr><td><strong>Layer</strong></td><td>A collection of neurons; can be input, hidden, or output.</td><td>Used in all neural architectures.</td></tr><tr><td><strong>Activation Function</strong></td><td>Non-linear function applied to neurons, e.g., ReLU, Sigmoid, Tanh.</td><td>Enables learning of complex patterns.</td></tr><tr><td><strong>Dropout</strong></td><td>Regularization technique randomly dropping neurons during training.</td><td>Reduces overfitting in models.</td></tr><tr><td><strong>Encoder</strong></td><td>Part of the model that converts input data into a latent representation.</td><td>Used in Transformers, Autoencoders, BERT, and more.</td></tr><tr><td><strong>Decoder</strong></td><td>Converts latent representations back to an output format.</td><td>Used in Transformers, Autoencoders, and Seq2Seq models.</td></tr><tr><td><strong>Attention Mechanism</strong></td><td>Focuses on important parts of the input data, e.g., Self-Attention.</td><td>Essential in Transformers and attention-based architectures.</td></tr><tr><td><strong>Residual Block</strong></td><td>A module that adds shortcut connections to mitigate vanishing gradients.</td><td>Found in ResNet, Transformer architectures.</td></tr><tr><td><strong>Convolution Layer</strong></td><td>Applies convolutional operations to extract spatial features.</td><td>Used in CNNs for tasks like image and video analysis.</td></tr><tr><td><strong>Pooling Layer</strong></td><td>Reduces spatial dimensions using techniques like max-pooling or average pooling.</td><td>Used in CNNs to downsample feature maps.</td></tr><tr><td><strong>Recurrent Cell</strong></td><td>Core unit of RNNs, capable of maintaining temporal dependencies.</td><td>Used in RNNs, LSTMs, and GRUs for time-series and sequential data.</td></tr><tr><td><strong>Self-Attention Layer</strong></td><td>Computes relationships between all input tokens to capture global dependencies.</td><td>Core of Transformers.</td></tr><tr><td><strong>Feedforward Layer</strong></td><td>Dense layer applied after attention mechanisms in Transformers.</td><td>Processes token-wise transformations.</td></tr><tr><td><strong>Embedding Layer</strong></td><td>Converts categorical data or tokens into dense vectors.</td><td>Used in NLP, graph embeddings, and more.</td></tr><tr><td><strong>Latent Space</strong></td><td>Compressed representation of data, typically learned by encoders.</td><td>Found in Autoencoders, VAEs, and GANs.</td></tr></tbody></table><hr><h2 id="How-components-relate-to-models"><a href="#How-components-relate-to-models" class="headerlink" title="How components relate to models"></a><strong>How components relate to models</strong></h2><table><thead><tr><th><strong>Architecture</strong></th><th><strong>Key Components</strong></th></tr></thead><tbody><tr><td><strong>FNN</strong></td><td>Neurons, Layers, Activation Functions, Dropout.</td></tr><tr><td><strong>CNN</strong></td><td>Convolution Layers, Pooling Layers, Fully Connected Layers, Activation Functions.</td></tr><tr><td><strong>RNN (Vanilla)</strong></td><td>Recurrent Cells, Layers, Activation Functions.</td></tr><tr><td><strong>LSTM</strong></td><td>LSTM Cells (with Forget, Input, Output gates), Layers.</td></tr><tr><td><strong>Transformers</strong></td><td>Encoder, Decoder, Self-Attention, Multi-Head Attention, Feedforward Layers, Positional Embeddings.</td></tr><tr><td><strong>Autoencoders</strong></td><td>Encoder, Decoder, Latent Space, Reconstruction Loss.</td></tr><tr><td><strong>GANs</strong></td><td>Generator, Discriminator, Adversarial Loss.</td></tr><tr><td><strong>GNNs</strong></td><td>Node Embeddings, Edge Features, Graph Convolutions.</td></tr></tbody></table><hr><p>This table serves as a foundation for understanding how modern deep learning architectures are structured and utilized across a wide range of applications.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Related to &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;../.</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="NN" scheme="https://ooge0.github.io/hexo-blog/tags/NN/"/>
    
  </entry>
  
  <entry>
    <title>BART configuration parameters overview</title>
    <link href="https://ooge0.github.io/hexo-blog/ai/post_ai_llm__bart_configuration_parameters_overview/"/>
    <id>https://ooge0.github.io/hexo-blog/ai/post_ai_llm__bart_configuration_parameters_overview/</id>
    <published>2024-12-04T20:08:12.000Z</published>
    <updated>2024-12-17T12:22:36.452Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>This post is related to:</em></p><ol><li><a href="/hexo-blog/ai/post_ai_llm__techniques_for_handling_context_in_ai_models">Techniques for handling context in LLM models</a></li></ol><hr><h2 id="Parameters-list-and-descriptions"><a href="#Parameters-list-and-descriptions" class="headerlink" title="Parameters list and descriptions"></a>Parameters list and descriptions</h2><table><thead><tr><th><strong>Parameter</strong></th><th><strong>Description</strong></th><th><strong>Data Type&#x2F;Options</strong></th></tr></thead><tbody><tr><td><code>max_position_embeddings</code></td><td>Maximum number of positions for input tokens.</td><td>Integer, e.g., <code>1024</code>.</td></tr><tr><td><code>d_model</code></td><td>Dimensionality of the model’s embeddings and hidden states.</td><td>Integer, e.g., <code>768</code>, <code>1024</code>.</td></tr><tr><td><code>encoder_layers</code></td><td>Number of layers in the encoder.</td><td>Integer, e.g., <code>6</code>, <code>12</code>.</td></tr><tr><td><code>decoder_layers</code></td><td>Number of layers in the decoder.</td><td>Integer, e.g., <code>6</code>, <code>12</code>.</td></tr><tr><td><code>encoder_attention_heads</code></td><td>Number of attention heads in the encoder.</td><td>Integer, e.g., <code>12</code>.</td></tr><tr><td><code>decoder_attention_heads</code></td><td>Number of attention heads in the decoder.</td><td>Integer, e.g., <code>12</code>.</td></tr><tr><td><code>vocab_size</code></td><td>Vocabulary size of the tokenizer. Represents the range of token IDs.</td><td>Integer, e.g., <code>50265</code>.</td></tr><tr><td><code>activation_function</code></td><td>Activation function used in feedforward layers.</td><td>String: <code>relu</code>, <code>gelu</code>, <code>tanh</code>, etc.</td></tr><tr><td><code>dropout</code></td><td>Dropout probability applied to various layers.</td><td>Float between <code>0.0</code> and <code>1.0</code>, typically <code>0.1</code>.</td></tr><tr><td><code>attention_dropout</code></td><td>Dropout probability in the attention mechanism.</td><td>Float between <code>0.0</code> and <code>1.0</code>, typically <code>0.1</code>.</td></tr><tr><td><code>init_std</code></td><td>Standard deviation for weight initialization.</td><td>Float, e.g., <code>0.02</code>.</td></tr><tr><td><code>encoder_ffn_dim</code></td><td>Dimensionality of the encoder feedforward layers.</td><td>Integer, e.g., <code>3072</code>.</td></tr><tr><td><code>decoder_ffn_dim</code></td><td>Dimensionality of the decoder feedforward layers.</td><td>Integer, e.g., <code>3072</code>.</td></tr><tr><td><code>scale_embedding</code></td><td>Whether to scale the embeddings by <code>sqrt(d_model)</code>.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>use_cache</code></td><td>Whether to use cached key&#x2F;values for faster decoding.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>pad_token_id</code></td><td>Token ID used for padding.</td><td>Integer, typically <code>0</code>.</td></tr><tr><td><code>bos_token_id</code></td><td>Token ID for the beginning-of-sequence token.</td><td>Integer, typically <code>0</code>.</td></tr><tr><td><code>eos_token_id</code></td><td>Token ID for the end-of-sequence token.</td><td>Integer, typically <code>2</code>.</td></tr></tbody></table><h2 id="Summary-of-parameter-impact"><a href="#Summary-of-parameter-impact" class="headerlink" title="Summary of parameter impact"></a>Summary of parameter impact</h2><h3 id="How-Changes-Reflect-on-Model-Behavior"><a href="#How-Changes-Reflect-on-Model-Behavior" class="headerlink" title="How Changes Reflect on Model Behavior:"></a>How Changes Reflect on Model Behavior:</h3><ol><li><p><strong>Model Complexity:</strong></p><ul><li>Increasing <code>encoder_layers</code>, <code>decoder_layers</code>, <code>d_model</code>, or attention heads enhances model capacity but increases computational requirements.</li></ul></li><li><p><strong>Regularization:</strong></p><ul><li>Dropout parameters (<code>dropout</code>, <code>attention_dropout</code>) control overfitting risks but may reduce performance if too high.</li></ul></li><li><p><strong>Encoder-Decoder interactions:</strong></p><ul><li><code>encoder_ffn_dim</code> and <code>decoder_ffn_dim</code> directly influence the learning ability of the model for complex patterns.</li></ul></li><li><p><strong>Efficiency:</strong></p><ul><li>Enabling <code>use_cache</code> improves inference time for autoregressive tasks.</li></ul></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Paper: BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension<ul><li><a href="https://arxiv.org/pdf/1910.13461">Read on arxiv.org</a></li><li>DOI:10.48550&#x2F;arXiv.1910.13461</li></ul></li><li>Paper: Improving Sharpness-Aware Minimization with Fisher Mask for Better Generalization on Language Models<ul><li>DOI:10.48550&#x2F;arXiv.2210.05497</li><li><a href="https://arxiv.org/pdf/2210.05497">Read on arxiv.org</a></li></ul></li><li><a href="https://huggingface.co/docs/transformers/model_doc/bart">Hugging Face BART Documentation</a></li><li>Web article: <a href="https://medium.com/@nadirapovey/bart-model-architecture-8ac1cea0e877">BART Model Architecture | Medium</a></li><li>Web article: <a href="https://www.projectpro.io/article/transformers-bart-model-explained/553">Transformers BART Model Explained for Text Summarization | projectpro.io</a></li><li>Google colab notebook: <a href="https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1">BART Learns to Rap - Medium.ipynb</a></li></ul><h2 id="Challenges-and-reports-on-configuration"><a href="#Challenges-and-reports-on-configuration" class="headerlink" title="Challenges and reports on configuration"></a>Challenges and reports on configuration</h2><ul><li><p><strong>Report:</strong> </p><ul><li>Paper: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. Raffel et al., 2020.<ul><li>DOI: 10.48550&#x2F;arXiv.1910.10683</li><li><a href="https://arxiv.org/pdf/1910.10683">Read on arxiv.org</a></li></ul></li></ul></li><li><p><strong>Challenges:</strong> Balancing fine-tuning for generative and discriminative tasks in sequence-to-sequence models.</p><ul><li>Paper: Unified Generative and Discriminative Training for Multi-modal Large Language Models<ul><li><a href="https://arxiv.org/html/2411.00304v1">Read on arxiv.org</a></li></ul></li></ul></li></ul><h2 id="Playgrounds-to-experiment"><a href="#Playgrounds-to-experiment" class="headerlink" title="Playgrounds to experiment"></a>Playgrounds to experiment</h2><ul><li><strong>Hugging Face Spaces:</strong> <a href="https://huggingface.co/spaces">https://huggingface.co/spaces</a></li><li><strong>Google Colab with Transformers:</strong> <a href="https://colab.research.google.com/">https://colab.research.google.com/</a></li><li><strong>OpenAI Playground for Generative Tasks:</strong> <a href="https://platform.openai.com/playground">https://platform.openai.com/playground</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;This post is related to:&lt;/em&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="LLM" scheme="https://ooge0.github.io/hexo-blog/tags/LLM/"/>
    
    <category term="BART" scheme="https://ooge0.github.io/hexo-blog/tags/BART/"/>
    
    <category term="llm_parameters" scheme="https://ooge0.github.io/hexo-blog/tags/llm-parameters/"/>
    
  </entry>
  
  <entry>
    <title>BERT configuration parameters overview</title>
    <link href="https://ooge0.github.io/hexo-blog/ai/post_ai_llm__bert_configuration_parameters_overview/"/>
    <id>https://ooge0.github.io/hexo-blog/ai/post_ai_llm__bert_configuration_parameters_overview/</id>
    <published>2024-12-04T20:08:12.000Z</published>
    <updated>2024-12-17T12:22:36.458Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>This post is related to:</em></p><ol><li><a href="/hexo-blog/ai/post_ai_llm__techniques_for_handling_context_in_ai_models">Techniques for handling context in LLM models</a></li><li><a href="/hexo-blog/ai/post_ai_llm__gpt2_configuration_parameters_overview">GPT2 configuration parameters overview</a></li><li><a href="/hexo-blog/ai/post_ai_llm__bart_configuration_parameters_overview">BART configuration parameters overview</a></li></ol><hr><h2 id="Parameters-list-and-descriptions"><a href="#Parameters-list-and-descriptions" class="headerlink" title="Parameters list and descriptions"></a>Parameters list and descriptions</h2><table><thead><tr><th><strong>Parameter</strong></th><th><strong>Description</strong></th><th><strong>Data Type&#x2F;Options</strong></th></tr></thead><tbody><tr><td><code>hidden_size</code></td><td>Dimensionality of the hidden states and embeddings.</td><td>Integer, e.g., <code>768</code>, <code>1024</code>.</td></tr><tr><td><code>num_hidden_layers</code></td><td>Number of hidden layers in the transformer encoder.</td><td>Integer, e.g., <code>12</code>, <code>24</code>.</td></tr><tr><td><code>num_attention_heads</code></td><td>Number of attention heads per transformer layer.</td><td>Integer, typically a divisor of <code>hidden_size</code>.</td></tr><tr><td><code>vocab_size</code></td><td>Vocabulary size of the tokenizer. Represents the range of token IDs.</td><td>Integer, e.g., <code>30522</code>.</td></tr><tr><td><code>intermediate_size</code></td><td>Dimensionality of the feedforward layers.</td><td>Integer, e.g., <code>3072</code>.</td></tr><tr><td><code>hidden_dropout_prob</code></td><td>Dropout probability for fully connected layers in the encoder.</td><td>Float between <code>0.0</code> and <code>1.0</code>, typically <code>0.1</code>.</td></tr><tr><td><code>attention_probs_dropout_prob</code></td><td>Dropout probability in the attention mechanism.</td><td>Float between <code>0.0</code> and <code>1.0</code>, typically <code>0.1</code>.</td></tr><tr><td><code>max_position_embeddings</code></td><td>Maximum number of positions for input tokens.</td><td>Integer, e.g., <code>512</code>.</td></tr><tr><td><code>type_vocab_size</code></td><td>Size of the token type vocabulary for segment embeddings.</td><td>Integer, typically <code>2</code>.</td></tr><tr><td><code>initializer_range</code></td><td>Standard deviation for weight initialization.</td><td>Float, e.g., <code>0.02</code>.</td></tr><tr><td><code>layer_norm_eps</code></td><td>A small value added for numerical stability in layer normalization.</td><td>Float, typically <code>1e-5</code>.</td></tr><tr><td><code>output_hidden_states</code></td><td>Whether to output all hidden states from each layer.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>output_attentions</code></td><td>Whether to output the attention weights.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr></tbody></table><h2 id="Summary-of-parameter-impact"><a href="#Summary-of-parameter-impact" class="headerlink" title="Summary of parameter impact"></a>Summary of parameter impact</h2><h3 id="How-changes-reflect-on-model-behavior"><a href="#How-changes-reflect-on-model-behavior" class="headerlink" title="How changes reflect on model behavior:"></a>How changes reflect on model behavior:</h3><ol><li><p><strong>Capacity:</strong></p><ul><li>Increasing <code>hidden_size</code>, <code>num_hidden_layers</code>, or <code>num_attention_heads</code> allows the model to capture more complex patterns but increases resource usage.</li></ul></li><li><p><strong>Regularization:</strong></p><ul><li>Dropout probabilities (<code>hidden_dropout_prob</code>, <code>attention_probs_dropout_prob</code>) control overfitting risks but can hinder learning if set too high.</li></ul></li><li><p><strong>Pretraining vs. Fine-tuning:</strong></p><ul><li><code>type_vocab_size</code> is essential for tasks requiring segment embeddings (e.g., sentence pairs).</li></ul></li><li><p><strong>Stability and Efficiency:</strong></p><ul><li><code>layer_norm_eps</code> ensures stable training, while <code>initializer_range</code> affects convergence.</li></ul></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Paper</li><li>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</li><li>DOI: 10.48550&#x2F;arXiv.1810.04805</li><li><a href="https://arxiv.org/abs/1810.04805">Read on </a></li><li><a href="https://huggingface.co/docs/transformers/model_doc/bert">Hugging Face BERT Documentation</a></li></ul><h2 id="Challenges-and-reports-on-configuration"><a href="#Challenges-and-reports-on-configuration" class="headerlink" title="Challenges and reports on configuration"></a>Challenges and reports on configuration</h2><ul><li><strong>Report:</strong> “On the Structural Properties of BERT Models” (Kovaleva et al., 2019).</li><li><strong>Challenges:</strong> Over-parameterization and inefficiency in fine-tuning for domain-specific tasks.</li></ul><h2 id="Playgrounds-to-experiment"><a href="#Playgrounds-to-experiment" class="headerlink" title="Playgrounds to experiment"></a>Playgrounds to experiment</h2><ul><li><strong>Hugging Face Spaces:</strong> <a href="https://huggingface.co/spaces">https://huggingface.co/spaces</a></li><li><strong>Google Colab with Transformers:</strong> <a href="https://colab.research.google.com/">https://colab.research.google.com/</a></li><li><strong>OpenAI Playground for Text Understanding:</strong> <a href="https://platform.openai.com/playground">https://platform.openai.com/playground</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;This post is related to:&lt;/em&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="LLM" scheme="https://ooge0.github.io/hexo-blog/tags/LLM/"/>
    
    <category term="BERT" scheme="https://ooge0.github.io/hexo-blog/tags/BERT/"/>
    
  </entry>
  
  <entry>
    <title>Dream team LLM engineer</title>
    <link href="https://ooge0.github.io/hexo-blog/ai/post_ai_llm__dream_team_llm_engineer/"/>
    <id>https://ooge0.github.io/hexo-blog/ai/post_ai_llm__dream_team_llm_engineer/</id>
    <published>2024-12-04T20:08:12.000Z</published>
    <updated>2024-12-18T20:26:03.642Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="LLM-Engineer-Skill-Set"><a href="#LLM-Engineer-Skill-Set" class="headerlink" title="LLM Engineer Skill Set"></a><strong>LLM Engineer Skill Set</strong></h1><h2 id="Core-Expertise"><a href="#Core-Expertise" class="headerlink" title="Core Expertise"></a><strong>Core Expertise</strong></h2><h3 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a><strong>Machine Learning</strong></h3><ul><li>Deep understanding of <strong>LLMs</strong> (e.g., GPT, LLaMA, PaLM) and their applications.</li><li>Fine-tuning and deploying large language models.</li><li>Managing multimodal LLMs with text and visual inputs.</li><li>Strong knowledge of computer vision models (e.g., ResNet, YOLO, CLIP).</li><li>Hands-on experience with multimodal AI applications, including image generation (e.g., Stable Diffusion, DALL·E).</li><li>Expertise in handling large-scale datasets.</li></ul><h3 id="Natural-Language-Processing-NLP"><a href="#Natural-Language-Processing-NLP" class="headerlink" title="Natural Language Processing (NLP)"></a><strong>Natural Language Processing (NLP)</strong></h3><ul><li>Proficiency in NLP tasks such as summarization, translation, and question answering.</li><li>Familiarity with performance optimization for large-scale AI models.</li><li>Experience with text embeddings, vector search, and similarity models.</li><li>Advanced tokenization techniques and preprocessing for text-based datasets.</li><li>Designing and fine-tuning sequence-to-sequence models for specialized NLP tasks.</li></ul><h3 id="General-Skills"><a href="#General-Skills" class="headerlink" title="General Skills"></a><strong>General Skills</strong></h3><ul><li>Proficient in using platforms for rapid prototyping and model optimization.</li><li>Expertise in integrating computer vision models with LLMs to extract insights from images.</li><li>Experience in collecting, preprocessing, and labeling multimodal datasets for training.</li><li>Skilled in developing APIs and microservices to integrate LLMs into existing systems or build standalone applications.</li></ul><h2 id="Technical-Knowledge"><a href="#Technical-Knowledge" class="headerlink" title="Technical Knowledge"></a><strong>Technical Knowledge</strong></h2><h3 id="Frameworks-and-Libraries"><a href="#Frameworks-and-Libraries" class="headerlink" title="Frameworks and Libraries"></a><strong>Frameworks and Libraries</strong></h3><ul><li>TensorFlow</li><li>PyTorch</li><li>Hugging Face Transformers</li></ul><h3 id="Data-Analysis-and-Visualization"><a href="#Data-Analysis-and-Visualization" class="headerlink" title="Data Analysis and Visualization"></a><strong>Data Analysis and Visualization</strong></h3><ul><li>Pandas</li><li>Matplotlib</li><li>Seaborn</li></ul><h3 id="Tools-for-NLP-Engineers"><a href="#Tools-for-NLP-Engineers" class="headerlink" title="Tools for NLP Engineers"></a><strong>Tools for NLP Engineers</strong></h3><ul><li><strong>Text Analysis and Preprocessing:</strong><ul><li>NLTK</li><li>SpaCy</li><li>FastText</li></ul></li><li><strong>Model Optimization and Deployment:</strong><ul><li>ONNX</li><li>TensorRT</li><li>Ray Serve</li></ul></li><li><strong>Data Management:</strong><ul><li>DVC (Data Version Control)</li><li>Apache Airflow</li></ul></li><li><strong>Search and Retrieval:</strong><ul><li>Elasticsearch</li><li>Faiss</li><li>Weaviate</li></ul></li><li><strong>Performance Monitoring:</strong><ul><li>Prometheus</li><li>Grafana</li><li>Sentry</li></ul></li></ul><h3 id="Development-Platforms"><a href="#Development-Platforms" class="headerlink" title="Development Platforms"></a><strong>Development Platforms</strong></h3><ul><li>Proficiency with platforms like <strong><a href="https://bytesai.com/">Bytes AI</a></strong> or similar for LLM and multimodal AI development.</li><li>Expertise in <strong>Python</strong>, with hands-on experience in ML frameworks and libraries.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;LLM-Engineer-Skill-Set&quot;&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="LLM" scheme="https://ooge0.github.io/hexo-blog/tags/LLM/"/>
    
    <category term="dream_team" scheme="https://ooge0.github.io/hexo-blog/tags/dream-team/"/>
    
  </entry>
  
  <entry>
    <title>Common LLM parameters</title>
    <link href="https://ooge0.github.io/hexo-blog/ai/post_ai_llm__llm_parameters/"/>
    <id>https://ooge0.github.io/hexo-blog/ai/post_ai_llm__llm_parameters/</id>
    <published>2024-12-04T20:08:12.000Z</published>
    <updated>2024-12-22T17:12:23.366Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>This post is related to:</em></p><ol><li><a href="/hexo-blog/ai/post_ai_llm__bart_configuration_parameters_overview/">BART configuration parameters overview</a></li><li><a href="/hexo-blog/ai/post_ai_llm__bert_configuration_parameters_overview/">BERT configuration parameters overview</a></li><li><a href="/hexo-blog/ai/post_ai_prompt_engineer_task_llm_locally/">Exploring OpenAI models locally without APIs (DRAFT-GUIDE)</a></li></ol><hr><table><thead><tr><th>Parameter</th><th>Description</th><th>Location in Documentation</th></tr></thead><tbody><tr><td><strong>pad_token_id</strong></td><td>The token ID used for padding sequences. This value indicates to the model where padding occurs.</td><td>Check the tokenizer documentation: <a href="https://huggingface.co/docs/tokenizers/main/en/api/tokenizer#tokenizers.Tokenizer">Hugging Face Tokenizers</a></td></tr><tr><td><strong>eos_token_id</strong></td><td>The token ID that signifies the end of a sequence (End Of Sequence).</td><td>Check model documentation for specifics: <a href="https://huggingface.co/docs/transformers.js/main/en/api/generation/stopping_criteria#new-eostokencriteriaeostokenid">Hugging Face Models</a></td></tr><tr><td><strong>attention_mask</strong></td><td>A mask that indicates which tokens should be attended to by the model (1 for actual tokens, 0 for padding).</td><td>Refer to model-specific usage in the Hugging Face library: <a href="https://huggingface.co/docs/transformers.js/main/en/api/models#modelscumsummaskedfillattentionmask--code-object-code">Transformers Usage</a></td></tr><tr><td><strong>input_ids</strong></td><td>The token IDs representing the input sequence of text.</td><td>General model input specifications: <a href="https://huggingface.co/docs/transformers.js/main/en/api/utils/generation#forcetokenslogitsprocessorcallinputids-logits--code-tensor-code">Hugging Face Model Input</a></td></tr><tr><td><strong>output_attention</strong></td><td>A boolean flag indicating if the model should return attention weights in addition to outputs.</td><td>Detailed in specific model API docs: <a href="https://huggingface.co/docs">Transformers API</a></td></tr><tr><td><strong>max_length</strong></td><td>The maximum length of sequences for generation tasks, limiting how long the output can be.</td><td>Check generation section in model docs: <a href="https://huggingface.co/docs/transformers.js/main/en/api/utils/generation#new-forcedeostokenlogitsprocessormaxlength-forcedeostokenid">Text Generation</a></td></tr><tr><td><strong>num_return_sequences</strong></td><td>The number of sequences to return from the model output, useful for generating multiple responses. The number of independently computed returned sequences for each element in the batch.</td><td>Refer to the text generation configuration: <a href="https://huggingface.co/docs/transformers.js/main/en/api/utils/generation#new-forcedeostokenlogitsprocessormaxlength-forcedeostokenid">Text Generation</a></td></tr><tr><td><strong>temperature</strong></td><td>Strictly positive float value used to modulate the logits distribution. A value smaller than 1 decreases randomness (and vice versa), with 0 being equivalent to shifting all probability mass to the most likely token.</td><td>Discussed in generation options: <a href="https://huggingface.co/docs/transformers.js/main/en/api/generation/logits_process#temperaturelogitswarpercallinputids-logits--code-tensor-code">Generation Parameters</a></td></tr><tr><td><strong>top_k</strong></td><td>The number of highest probability vocabulary tokens to keep for sampling.</td><td>Detailed in sampling strategies: <a href="https://huggingface.co/docs">Sampling Methods</a></td></tr><tr><td><strong>top_p</strong></td><td>Controls the cumulative probability distribution for nucleus sampling.</td><td>Explained in sampling calculations: <a href="https://huggingface.co/docs">Nucleus Sampling</a></td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;This post is related to:&lt;/em&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="LLM" scheme="https://ooge0.github.io/hexo-blog/tags/LLM/"/>
    
    <category term="llm_parameters" scheme="https://ooge0.github.io/hexo-blog/tags/llm-parameters/"/>
    
  </entry>
  
  <entry>
    <title>GPT-2 configuration parameters overview</title>
    <link href="https://ooge0.github.io/hexo-blog/ai/post_ai_llm__gpt2_configuration_parameters_overview/"/>
    <id>https://ooge0.github.io/hexo-blog/ai/post_ai_llm__gpt2_configuration_parameters_overview/</id>
    <published>2024-12-04T18:08:12.000Z</published>
    <updated>2024-12-17T12:22:36.457Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>This post is related to:</em></p><ol><li><a href="/hexo-blog/ai/post_ai_llm__techniques_for_handling_context_in_ai_models">Techniques for handling context in LLM models</a></li><li><a href="/hexo-blog/ai/post_ai_llm__bart_configuration_parameters_overview">BART configuration parameters overview</a></li></ol><hr><h2 id="Parameters-List-and-Descriptions"><a href="#Parameters-List-and-Descriptions" class="headerlink" title="Parameters List and Descriptions"></a>Parameters List and Descriptions</h2><table><thead><tr><th><strong>Parameter</strong></th><th><strong>Description</strong></th><th><strong>Data Type&#x2F;Options</strong></th></tr></thead><tbody><tr><td><code>n_ctx</code></td><td>The context size or maximum length of input tokens the model can process.</td><td>Integer, e.g., <code>1024</code>, <code>2048</code>.</td></tr><tr><td><code>n_embd</code></td><td>Dimensionality of the embeddings. Determines the size of the word and positional embeddings.</td><td>Integer, typically <code>768</code>, <code>1024</code>, or <code>1280</code>.</td></tr><tr><td><code>n_layer</code></td><td>Number of transformer layers in the model. Dictates depth of the network.</td><td>Integer, e.g., <code>12</code>, <code>24</code>, <code>48</code>.</td></tr><tr><td><code>n_head</code></td><td>Number of attention heads in each transformer layer. Reflects parallel attention mechanisms.</td><td>Integer, typically a divisor of <code>n_embd</code> such as <code>12</code> or <code>16</code>.</td></tr><tr><td><code>vocab_size</code></td><td>Size of the vocabulary for the tokenizer. Represents the range of token IDs the model can handle.</td><td>Integer, e.g., <code>50257</code>.</td></tr><tr><td><code>activation_function</code></td><td>The activation function used in feedforward layers (e.g., “gelu”). Affects non-linearity.</td><td>String: <code>relu</code>, <code>gelu</code>, <code>tanh</code>, <code>sigmoid</code>, etc.</td></tr><tr><td><code>resid_pdrop</code></td><td>Dropout probability for residual connections. Adds regularization.</td><td>Float between <code>0.0</code> and <code>1.0</code>. Typically <code>0.1</code>.</td></tr><tr><td><code>embd_pdrop</code></td><td>Dropout probability for embeddings. Helps prevent overfitting.</td><td>Float between <code>0.0</code> and <code>1.0</code>. Typically <code>0.1</code>.</td></tr><tr><td><code>attn_pdrop</code></td><td>Dropout probability in the attention mechanism. Ensures robustness.</td><td>Float between <code>0.0</code> and <code>1.0</code>. Typically <code>0.1</code>.</td></tr><tr><td><code>initializer_range</code></td><td>The range of the uniform distribution for weight initialization.</td><td>Float, e.g., <code>0.02</code>.</td></tr><tr><td><code>layer_norm_epsilon</code></td><td>A small value added for numerical stability in layer normalization.</td><td>Float, typically <code>1e-5</code>.</td></tr><tr><td><code>use_cache</code></td><td>Whether the model uses cached key&#x2F;values for faster generation during inference.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>bos_token_id</code></td><td>Token ID for the beginning-of-sequence token.</td><td>Integer, e.g., <code>50256</code>.</td></tr><tr><td><code>eos_token_id</code></td><td>Token ID for the end-of-sequence token.</td><td>Integer, e.g., <code>50256</code>.</td></tr><tr><td><code>scale_attn_weights</code></td><td>Whether to scale the attention weights.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>output_hidden_states</code></td><td>Whether to return all hidden states from each layer during inference.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>output_attentions</code></td><td>Whether to return the attention weights during inference.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>tie_word_embeddings</code></td><td>Whether to tie the input and output word embeddings.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr></tbody></table><hr><h2 id="Summary-of-Parameter-Impact"><a href="#Summary-of-Parameter-Impact" class="headerlink" title="Summary of Parameter Impact"></a>Summary of Parameter Impact</h2><h3 id="How-changes-reflect-on-model-behavior"><a href="#How-changes-reflect-on-model-behavior" class="headerlink" title="How changes reflect on model behavior:"></a>How changes reflect on model behavior:</h3><ol><li><p><strong>Model Size and Computation:</strong></p><ul><li>Increasing <code>n_layer</code>, <code>n_embd</code>, or <code>n_head</code> leads to larger and more computationally intensive models but potentially improves learning capacity.</li><li>Reducing <code>n_ctx</code> limits the model’s ability to process long inputs.</li></ul></li><li><p><strong>Regularization:</strong></p><ul><li>Dropout parameters (<code>resid_pdrop</code>, <code>embd_pdrop</code>, <code>attn_pdrop</code>) mitigate overfitting but may hinder performance if too high.</li></ul></li><li><p><strong>Non-linearity:</strong></p><ul><li>The choice of <code>activation_function</code> (e.g., <code>gelu</code> vs. <code>relu</code>) affects gradient behavior and optimization efficiency.</li></ul></li><li><p><strong>Stability:</strong></p><ul><li>Small <code>layer_norm_epsilon</code> values ensure numerical stability during normalization but may require tuning based on the architecture.</li></ul></li><li><p><strong>Flexibility:</strong></p><ul><li>Enabling <code>output_hidden_states</code> or <code>output_attentions</code> increases interpretability but may slow inference.</li></ul></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2 Paper</a></li><li><a href="https://huggingface.co/docs/transformers/model_doc/gpt2">Hugging Face Documentation</a></li></ul><hr><h2 id="Challenges-and-reports-on-configuration"><a href="#Challenges-and-reports-on-configuration" class="headerlink" title="Challenges and reports on configuration"></a>Challenges and reports on configuration</h2><ul><li><strong>Report:</strong> “Language Models are Few-Shot Learners” (Brown et al., 2020) discusses scalability challenges in transformer-based architectures.</li><li><strong>Challenges:</strong> Balancing model depth and breadth while maintaining computational efficiency.</li></ul><hr><h2 id="Playgrounds-to-experiment"><a href="#Playgrounds-to-experiment" class="headerlink" title="Playgrounds to experiment"></a>Playgrounds to experiment</h2><ul><li><strong>OpenAI Playground:</strong> <a href="https://platform.openai.com/playground">https://platform.openai.com/playground</a></li><li><strong>Hugging Face Spaces:</strong> <a href="https://huggingface.co/spaces">https://huggingface.co/spaces</a></li><li><strong>Google Colab with Transformers:</strong> <a href="https://colab.research.google.com/">https://colab.research.google.com/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;This post is related to:&lt;/em&gt;&lt;/p&gt;
</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="LLM" scheme="https://ooge0.github.io/hexo-blog/tags/LLM/"/>
    
    <category term="GPT2" scheme="https://ooge0.github.io/hexo-blog/tags/GPT2/"/>
    
    <category term="NN" scheme="https://ooge0.github.io/hexo-blog/tags/NN/"/>
    
  </entry>
  
  <entry>
    <title>NLTK general</title>
    <link href="https://ooge0.github.io/hexo-blog/ai_nltk/nltk_general/"/>
    <id>https://ooge0.github.io/hexo-blog/ai_nltk/nltk_general/</id>
    <published>2024-12-04T09:21:11.000Z</published>
    <updated>2024-12-23T09:58:43.430Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="NLTK-Natural-Language-Toolkit-for-Natural-Language-Text-Processing-NLTP"><a href="#NLTK-Natural-Language-Toolkit-for-Natural-Language-Text-Processing-NLTP" class="headerlink" title="NLTK - Natural Language Toolkit for Natural Language Text Processing (NLTP)"></a>NLTK - Natural Language Toolkit for Natural Language Text Processing (NLTP)</h2><hr><h3 id="General"><a href="#General" class="headerlink" title="General"></a>General</h3><ol><li><a href="https://www.nltk.org/howto.html#example-usage-of-nltk-modules">Example usage of NLTK modules</a></li><li><a href="https://github.com/nltk/nltk/wiki">NLTK WIKI</a></li><li><a href="https://github.com/nltk/nltk/wiki/Projects">NLTK WIKI Projects</a></li><li><a href="https://github.com/nltk/nltk/FAQ">NLTK FAQ</a></li><li><a href="http://text-processing.com/demo/">NLTK Interactive online demos</a></li></ol><hr><h3 id="NLTK-books"><a href="#NLTK-books" class="headerlink" title="NLTK books"></a>NLTK books</h3><p><a href="https://www.nltk.org/book/">Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit. Steven Bird, Ewan Klein, and Edward Loper</a></p><hr><h4 id="NLTK-courses"><a href="#NLTK-courses" class="headerlink" title="NLTK courses"></a>NLTK courses</h4><p><a href="http://www.nltk.org/courses">NLTK courses</a></p><hr><h4 id="About-‘Natural-Language-Text-Processing’"><a href="#About-‘Natural-Language-Text-Processing’" class="headerlink" title="About ‘Natural Language Text Processing’"></a>About ‘Natural Language Text Processing’</h4><p>Natural Language Text Processing encompasses a range of techniques and tools to analyze, manipulate, and understand human language in text form. Below is a detailed explanation of key terms, their technical details, and implementation options in NLP.</p><p>Natural Language Text Processing include but not limited by <code>sentiment analysis</code>, which uses text classification to determine <code>sentiment polarity</code>, <code>word tokenization</code> , <code>stemming</code> text, <code>speech tagging</code> using <code>speech taggers</code>, <code>chunk extraction</code> and named <code>entity recognition</code>. </p><hr><h4 id="Sentiment-Analysis"><a href="#Sentiment-Analysis" class="headerlink" title="Sentiment Analysis"></a><strong>Sentiment Analysis</strong></h4><p><strong>Definition</strong>: Sentiment Analysis determines the emotional tone behind a body of text. It classifies text as positive, negative, or neutral.</p><p><strong>Approaches</strong>:</p><ol><li><strong>Lexicon-Based Methods</strong>:<ul><li>Use predefined dictionaries of positive and negative words.</li><li>Examples: SentiWordNet, VADER.</li></ul></li><li><strong>Machine Learning-Based Methods</strong>:<ul><li>Train a model on labeled datasets to classify sentiments.</li><li>Examples: Naive Bayes, Support Vector Machines (SVM).</li></ul></li><li><strong>Deep Learning Methods</strong>:<ul><li>Utilize neural networks like RNNs, LSTMs, or transformers.</li><li>Examples: BERT, RoBERTa, DistilBERT.</li></ul></li></ol><hr><h4 id="Word-Tokenization"><a href="#Word-Tokenization" class="headerlink" title="Word Tokenization"></a><strong>Word Tokenization</strong></h4><p><strong>Definition</strong>: The process of splitting a sentence or paragraph into individual words or tokens.</p><p><strong>Options</strong>:</p><ol><li><strong>Rule-Based Tokenization</strong>:<ul><li>Uses language-specific rules to split text.</li><li>Example Tools: NLTK, SpaCy.</li></ul></li><li><strong>Statistical Tokenization</strong>:<ul><li>Employs probabilistic models for token boundaries.</li><li>Examples: Punkt tokenizer.</li></ul></li><li><strong>Subword Tokenization</strong>:<ul><li>Splits text into subwords to handle rare words.</li><li>Examples: Byte Pair Encoding (BPE), WordPiece (used in BERT).</li></ul></li></ol><hr><h4 id="Stemming"><a href="#Stemming" class="headerlink" title="Stemming"></a><strong>Stemming</strong></h4><p><strong>Definition</strong>: Reduces words to their base or root form (e.g., “running” → “run”).</p><p><strong>Methods</strong>:</p><ol><li><strong>Porter Stemmer</strong>: Algorithmic and rule-based.</li><li><strong>Lancaster Stemmer</strong>: Faster but more aggressive.</li><li><strong>Snowball Stemmer</strong>: Improved version of Porter.</li></ol><p><strong>Usage</strong>: Common in search engines and text indexing.</p><hr><h4 id="Speech-Tagging"><a href="#Speech-Tagging" class="headerlink" title="Speech Tagging"></a><strong>Speech Tagging</strong></h4><p><strong>Definition</strong>: Assigning parts of speech (POS) tags (e.g., noun, verb) to each word in a text.</p><p><strong>Taggers</strong>:</p><ol><li><strong>Rule-Based POS Tagging</strong>:<ul><li>Uses manually crafted rules.</li></ul></li><li><strong>Statistical POS Tagging</strong>:<ul><li>Relies on probabilistic models (e.g., Hidden Markov Models).</li></ul></li><li><strong>Neural POS Tagging</strong>:<ul><li>Utilizes neural networks for higher accuracy.</li></ul></li></ol><p><strong>Example Tools</strong>: NLTK POS Tagger, SpaCy.</p><hr><h4 id="Chunk-Extraction"><a href="#Chunk-Extraction" class="headerlink" title="Chunk Extraction"></a><strong>Chunk Extraction</strong></h4><p><strong>Definition</strong>: Identifies and groups related words (e.g., noun phrases, verb phrases).</p><p><strong>Types</strong>:</p><ol><li><strong>Shallow Parsing</strong>:<ul><li>Focuses on high-level phrase detection.</li></ul></li><li><strong>Dependency Parsing</strong>:<ul><li>Analyzes grammatical structure by identifying relationships between words.</li></ul></li></ol><p><strong>Example Tools</strong>: OpenNLP, CoreNLP.</p><hr><h4 id="Named-Entity-Recognition-NER"><a href="#Named-Entity-Recognition-NER" class="headerlink" title="Named Entity Recognition (NER)"></a><strong>Named Entity Recognition (NER)</strong></h4><p><strong>Definition</strong>: Identifies and categorizes entities in text (e.g., names, organizations, dates).</p><p><strong>NER Types</strong>:</p><ol><li><strong>Rule-Based NER</strong>:<ul><li>Uses pattern-matching rules.</li><li>Examples: Regular Expressions.</li></ul></li><li><strong>Statistical NER</strong>:<ul><li>Trains models on labeled entity datasets.</li><li>Examples: Conditional Random Fields (CRF).</li></ul></li><li><strong>Neural NER</strong>:<ul><li>Deep learning-based methods for context understanding.</li><li>Examples: SpaCy, Flair, Hugging Face.</li></ul></li></ol><hr><h3 id="Implementation-in-NLP"><a href="#Implementation-in-NLP" class="headerlink" title="Implementation in NLP"></a><strong>Implementation in NLP</strong></h3><ol><li><p><strong>Libraries and Frameworks</strong>:</p><ul><li><strong>NLTK</strong>: A foundational library for tokenization, stemming, and POS tagging.</li><li><strong>SpaCy</strong>: Industrial-strength NLP with support for tokenization, POS tagging, NER, etc.</li><li><strong>Transformers (Hugging Face)</strong>: Pre-trained models for sentiment analysis, NER, and more.</li><li><strong>CoreNLP</strong>: Comprehensive NLP suite by Stanford.</li></ul></li><li><p><strong>Use Cases</strong>:</p><ul><li>Sentiment analysis in social media monitoring.</li><li>Tokenization in machine translation.</li><li>NER for information extraction from documents.</li></ul></li></ol><hr><p><em><strong>Related to this topic</strong></em>  </p><ol><li><a href="https://nlp.stanford.edu/">Natural Language Processing | Stanford NLP</a>  </li><li><a href="https://huggingface.co/">Understanding NLP Techniques | Hugging Face</a>  </li><li><a href="https://www.nltk.org/">NLTK Official Documentation</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;NLTK-Natural-Language-Toolkit-for</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="NLTK" scheme="https://ooge0.github.io/hexo-blog/tags/NLTK/"/>
    
  </entry>
  
  <entry>
    <title>Neural Process Family</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/30/post_ai_ml_npf__general/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/30/post_ai_ml_npf__general/</id>
    <published>2024-11-30T14:45:33.000Z</published>
    <updated>2024-11-30T15:18:33.089Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>The <strong>Neural Process Family</strong> refers to a class of models designed to learn distributions over functions, offering a blend of the expressiveness of deep learning and the flexibility of probabilistic models. These models are particularly useful for tasks requiring uncertainty quantification, few-shot learning, and function estimation. Key members of this family include <strong>Neural Processes (NPs)</strong>, <strong>Conditional Neural Processes (CNPs)</strong>, <strong>Attentive Neural Processes (ANPs)</strong>, and extensions like <strong>ConvCNPs</strong> and <strong>Variational NPs (VNPs)</strong>.</p><h2 id="Core-Concepts"><a href="#Core-Concepts" class="headerlink" title="Core Concepts"></a>Core Concepts</h2><ol><li><p><strong>Probabilistic Nature</strong>:<br>Neural Processes learn distributions over functions. Given a set of input-output pairs, they can predict the probability distribution of outputs for new inputs, making them suitable for uncertainty estimation.</p></li><li><p><strong>Few-Shot Learning</strong>:<br>These models can make predictions given only a few examples, making them ideal for problems where data is scarce.</p></li><li><p><strong>Model Components</strong>:</p><ul><li><strong>Encoder</strong>: Maps input-output pairs to a latent representation.</li><li><strong>Decoder</strong>: Takes the latent representation and generates outputs for given inputs.</li><li><strong>Latent Space</strong>: Captures the uncertainty and variability in the function space.</li></ul></li><li><p><strong>Meta-Learning</strong>:<br>NPs can generalize across tasks by learning a distribution over tasks, enabling them to perform well on unseen tasks after being trained on related ones.</p></li></ol><hr><h2 id="Variants-of-Neural-Processes"><a href="#Variants-of-Neural-Processes" class="headerlink" title="Variants of Neural Processes"></a>Variants of Neural Processes</h2><ol><li><p><strong>Conditional Neural Processes (CNPs)</strong>:</p><ul><li>A deterministic model that learns to map a context set of input-output pairs to predictions for new inputs.</li><li>Simple and efficient but limited in capturing uncertainty in the underlying function.</li></ul></li><li><p><strong>Neural Processes (NPs)</strong>:</p><ul><li>Adds a latent variable to model uncertainty explicitly, making it a probabilistic counterpart to CNPs.</li><li>Balances flexibility and computational efficiency.</li></ul></li><li><p><strong>Attentive Neural Processes (ANPs)</strong>:</p><ul><li>Introduces attention mechanisms to improve modeling of relationships between context points and query points.</li><li>Addresses issues with poor extrapolation and oversmoothing in standard NPs.</li></ul></li><li><p><strong>Convolutional Neural Processes (ConvCNPs)</strong>:</p><ul><li>Leverages convolutional architectures for tasks like image generation, capturing local correlations more effectively.</li></ul></li><li><p><strong>Variational Neural Processes (VNPs)</strong>:</p><ul><li>Focuses on improved variational inference techniques to better approximate the posterior distribution over functions.</li></ul></li></ol><hr><h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><ol><li><strong>Regression</strong>:<br>Modeling functions with uncertainty, e.g., Bayesian regression tasks.</li><li><strong>Few-Shot Classification</strong>:<br>Classifying data with limited examples by modeling task distributions.</li><li><strong>Spatio-Temporal Data</strong>:<br>Applications in time-series forecasting and spatial predictions.</li><li><strong>Reinforcement Learning</strong>:<br>Modeling uncertainty in reward functions or dynamics.</li><li><strong>Image Completion</strong>:<br>Predicting missing pixels in images.</li></ol><hr><h2 id="Strengths-and-Challenges"><a href="#Strengths-and-Challenges" class="headerlink" title="Strengths and Challenges"></a>Strengths and Challenges</h2><h3 id="Strengths"><a href="#Strengths" class="headerlink" title="Strengths:"></a>Strengths:</h3><ul><li>Scalability due to neural networks.</li><li>Probabilistic outputs allow uncertainty estimation.</li><li>Adaptable across domains with minimal changes.</li></ul><h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges:"></a>Challenges:</h3><ul><li>Trade-off between computational cost and flexibility.</li><li>Dependence on good representation learning.</li><li>Overcoming limitations of context aggregation in high-dimensional tasks.</li></ul><hr><p>The Neural Process Family continues to evolve, with active research aimed at improving its scalability, expressiveness, and applications to real-world problems.</p><hr><p>About:</p><ul><li><a href="https://yanndubs.github.io/Neural-Process-Family/">yanndubs.github.io | The Neural Process Family</a></li><li><a href="https://notes.theomorales.com/Gaussian+%26+Neural+Processes/The+Neural+Process+Family">notes.theomorales.com | The Neural Process Family</a></li></ul><hr><p> Papers: </p><ul><li>Papers: <ul><li>Title: The Neural Process Family: Survey, Applications<br>and Perspectives</li><li>DOI: 10.48550&#x2F;arXiv.2209.00517</li><li><a href="https://arxiv.org/pdf/2209.00517">Read on arxiv.org</a></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;The &lt;strong&gt;Neural Process Family&lt;/str</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="NPF" scheme="https://ooge0.github.io/hexo-blog/tags/NPF/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning.Teach by Doing(LinkedIn post)</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/30/post_ai_ml__machine_learning_teach_by_doing/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/30/post_ai_ml__machine_learning_teach_by_doing/</id>
    <published>2024-11-30T14:33:33.000Z</published>
    <updated>2024-11-30T14:38:34.347Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>This is reopst of LinkedIN post. Current post contains list of references and some additional detilas</em></p><p>I(Author) started the Machine Learning: Teach by Doing series to transfer my learnings to those who want to transition to Machine Learning.</p><p>I(Author) have recorded 37 videos in the past 6 months.</p><p>Here are the links for you to learn:</p><ol><li>Introduction to Machine Learning Teach by Doing: <a href="https://lnkd.in/gqN2PMX5">https://lnkd.in/gqN2PMX5</a></li><li>What is Machine Learning? History of Machine Learning: <a href="https://lnkd.in/gvpNSAKh">https://lnkd.in/gvpNSAKh</a></li><li>Types of ML Models: <a href="https://lnkd.in/gSy2mChM">https://lnkd.in/gSy2mChM</a></li><li>6 steps of any ML project: <a href="https://lnkd.in/ggCGchPQ">https://lnkd.in/ggCGchPQ</a></li><li>Install Python and VSCode and run your first code: <a href="https://lnkd.in/gyic7J7b">https://lnkd.in/gyic7J7b</a></li><li>Linear Classifiers Part 1: <a href="https://lnkd.in/gYdfD97D">https://lnkd.in/gYdfD97D</a></li><li>Linear Classifiers Part 2: <a href="https://lnkd.in/gac_z-G8">https://lnkd.in/gac_z-G8</a></li><li>Jupyter Notebook, Numpy and Scikit-Learn: <a href="https://lnkd.in/gWRaC_tB">https://lnkd.in/gWRaC_tB</a></li><li>Running the Random Linear Classifier Algorithm in Python: <a href="https://lnkd.in/g5HacbFC">https://lnkd.in/g5HacbFC</a></li><li>The oldest ML model - Perceptron: <a href="https://lnkd.in/gpce6uFt">https://lnkd.in/gpce6uFt</a></li><li>Coding the Perceptron: <a href="https://lnkd.in/gmz-XjNK">https://lnkd.in/gmz-XjNK</a></li><li>Perceptron Convergence Theorem: <a href="https://lnkd.in/gmz-XjNK">https://lnkd.in/gmz-XjNK</a></li><li>Magic of features in Machine Learning: <a href="https://lnkd.in/gCeDRb3g">https://lnkd.in/gCeDRb3g</a></li><li>One hot encoding: <a href="https://lnkd.in/g3WfRQGQ">https://lnkd.in/g3WfRQGQ</a></li><li>Logistic Regression Part 1: <a href="https://lnkd.in/gTgZAAZn">https://lnkd.in/gTgZAAZn</a></li><li>Cross Entropy Loss: <a href="https://lnkd.in/g3Ywg_2p">https://lnkd.in/g3Ywg_2p</a></li><li>How gradient descent works: <a href="https://lnkd.in/gKBAsazF">https://lnkd.in/gKBAsazF</a></li><li>Logistic Regression from scratch in Python: <a href="https://lnkd.in/g8iZh27P">https://lnkd.in/g8iZh27P</a></li><li>Introduction to Regularization: <a href="https://lnkd.in/gjM9pVw2">https://lnkd.in/gjM9pVw2</a></li><li>Implementing Regularization in Python: <a href="https://lnkd.in/gRnSK4v4">https://lnkd.in/gRnSK4v4</a></li><li>Linear Regression Introduction: <a href="https://lnkd.in/gPYtSPJ9">https://lnkd.in/gPYtSPJ9</a></li><li>Ordinary Least Squares step by step implementation: <a href="https://lnkd.in/gnWQdgNy">https://lnkd.in/gnWQdgNy</a></li><li>Ridge regression fundamentals and intuition: <a href="https://lnkd.in/gE5M-CSM">https://lnkd.in/gE5M-CSM</a></li><li>Regression recap for interviews: <a href="https://lnkd.in/gNBWzzWv">https://lnkd.in/gNBWzzWv</a></li><li>Neural network architecture in 30 minutes: <a href="https://lnkd.in/g7qSrkxG">https://lnkd.in/g7qSrkxG</a></li><li>Backpropagation intuition: <a href="https://lnkd.in/gAmBARHm">https://lnkd.in/gAmBARHm</a></li><li>Neural network activation functions: <a href="https://lnkd.in/gqrC3zDP">https://lnkd.in/gqrC3zDP</a></li><li>Momentum in gradient descent: <a href="https://lnkd.in/g3M4qhbP">https://lnkd.in/g3M4qhbP</a></li><li>Hands on neural network training in Python: <a href="https://lnkd.in/gz-fTBxs">https://lnkd.in/gz-fTBxs</a></li><li>Introduction to Convolutional Neural Networks (CNNs.: <a href="https://lnkd.in/gpmuBm3j">https://lnkd.in/gpmuBm3j</a></li><li>Filters in 1D and the Convolution Operation: <a href="https://lnkd.in/gEDaKHDU">https://lnkd.in/gEDaKHDU</a></li><li>Filters in 2D, Channels and Feature Identification: <a href="https://lnkd.in/g3Gf_4ia">https://lnkd.in/g3Gf_4ia</a></li><li>Filtering Layers in Convolutional Neural Networks: <a href="https://lnkd.in/gUaiBkTu">https://lnkd.in/gUaiBkTu</a></li><li>What is Max Pooling in Convolutional Neural Networks?: <a href="https://lnkd.in/gGRGy6wq">https://lnkd.in/gGRGy6wq</a></li><li>CNN Architecture explained: <a href="https://lnkd.in/gPQvRh9i">https://lnkd.in/gPQvRh9i</a></li><li>Backpropagation in Convolutional Neural Networks: <a href="https://lnkd.in/g942G6zv">https://lnkd.in/g942G6zv</a></li><li>Build your own brain tumor classification CNN application in Python: <a href="https://lnkd.in/gQB5zRGk">https://lnkd.in/gQB5zRGk</a></li></ol><p>Join our AI live lectures waitlist here: <a href="https://lnkd.in/gDcHZdHg">https://lnkd.in/gDcHZdHg</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;This is reopst of LinkedIN post. C</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Parsing web site for job offers</title>
    <link href="https://ooge0.github.io/hexo-blog/data_mining/post_data_mining__parsing_web_site_for_job_offers/"/>
    <id>https://ooge0.github.io/hexo-blog/data_mining/post_data_mining__parsing_web_site_for_job_offers/</id>
    <published>2024-11-27T22:49:11.000Z</published>
    <updated>2024-12-17T12:19:06.560Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Given</strong> The website with posted offers.<br><strong>Goal:</strong> to get information from the website using python, BeautifulSoup and save it in JSON and markdown files.</p><p><strong>Python scirpt</strong></p><p>Install and import required packages</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">execute_requests</span>(<span class="params">base_url, amount_of_pages</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Executes GET requests for the specified number of pages and returns the responses.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        base_url (str): The base URL for requests.</span></span><br><span class="line"><span class="string">        amount_of_pages (int): The number of pages to fetch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        list: A list of dictionaries containing the request number, page counter, and response content.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    payload = &#123;&#125;</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;_jobboard_session=895b7b35b6493519c3ad686923d8cc1d; __cf_bm=BrUIPeJX6XqIr7jlW.4M-1732742386-1.0.1.1-1hk8BgPr6ZL6QswlF6K2dUhchp0reiDPOXzX6z.etyq.IUHZqPg&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    responses_data = []  <span class="comment"># Initialize an empty list to store response data</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> counter <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, amount_of_pages + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># Construct the URL with the current page counter</span></span><br><span class="line">        url = <span class="string">f&quot;<span class="subst">&#123;base_url&#125;</span>&amp;page=<span class="subst">&#123;counter&#125;</span>&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Fetching data from: <span class="subst">&#123;url&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># Send GET request</span></span><br><span class="line">            response = requests.get(url, headers=headers, data=payload)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Append the response data to the list</span></span><br><span class="line">            responses_data.append(&#123;</span><br><span class="line">                <span class="string">&quot;request_key&quot;</span>: <span class="string">f&quot;request_<span class="subst">&#123;counter&#125;</span>&quot;</span>,</span><br><span class="line">                <span class="string">&quot;counter&quot;</span>: counter,</span><br><span class="line">                <span class="string">&quot;response_content&quot;</span>: response.text</span><br><span class="line">            &#125;)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;counter: <span class="subst">&#123;counter&#125;</span> | &#x27;status_code:&#x27; <span class="subst">&#123;response.status_code&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> requests.RequestException <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error fetching data for page <span class="subst">&#123;counter&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> responses_data</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Parse data from <code>json</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_job_data_from_json</span>(<span class="params">response_data, output_json_file, output_markdown_file</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Parse job data from a list of responses and extract job listings using BeautifulSoup.</span></span><br><span class="line"><span class="string">    Save results to both a JSON file and a Markdown file.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        response_data (list): List of dictionaries containing the response data.</span></span><br><span class="line"><span class="string">        output_json_file (str): Path to save the parsed job data in JSON format.</span></span><br><span class="line"><span class="string">        output_markdown_file (str): Path to save the parsed job data in Markdown format.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        job_data = []  <span class="comment"># List to store extracted job data</span></span><br><span class="line">        markdown_content = []  <span class="comment"># List to store Markdown entries</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loop through each request in the list</span></span><br><span class="line">        <span class="keyword">for</span> request <span class="keyword">in</span> response_data:</span><br><span class="line">            counter = request.get(<span class="string">&quot;counter&quot;</span>, <span class="string">&quot;unknown&quot;</span>)</span><br><span class="line">            response_content = request.get(<span class="string">&quot;response_content&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Parse the HTML content using BeautifulSoup</span></span><br><span class="line">            soup = BeautifulSoup(response_content, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Find all job listings using the locator</span></span><br><span class="line">            job_listings = soup.find_all(<span class="string">&#x27;li&#x27;</span>, class_=<span class="string">&#x27;job-listing&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Extract data from each job listing</span></span><br><span class="line">            <span class="keyword">for</span> job <span class="keyword">in</span> job_listings:</span><br><span class="line">                <span class="comment"># Safely find required elements, fallback to &#x27;N/A&#x27; if not present</span></span><br><span class="line">                job_title = job.find(<span class="string">&#x27;a&#x27;</span>, class_=<span class="string">&#x27;jobList-title zip-backfill-link&#x27;</span>)</span><br><span class="line">                job_description = job.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;jobList-description&#x27;</span>)</span><br><span class="line">                salary = job.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;jobList-salary&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                job_info = &#123;</span><br><span class="line">                    <span class="string">&#x27;title&#x27;</span>: job_title.text.strip() <span class="keyword">if</span> job_title <span class="keyword">else</span> <span class="string">&#x27;N/A&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;href&#x27;</span>: job_title[<span class="string">&#x27;href&#x27;</span>] <span class="keyword">if</span> job_title <span class="keyword">else</span> <span class="string">&#x27;N/A&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;description&#x27;</span>: job_description.text.strip() <span class="keyword">if</span> job_description <span class="keyword">else</span> <span class="string">&#x27;N/A&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;salary&#x27;</span>: salary.text.strip() <span class="keyword">if</span> salary <span class="keyword">else</span> <span class="string">&#x27;N/A&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;page&#x27;</span>: counter</span><br><span class="line">                &#125;</span><br><span class="line">                job_data.append(job_info)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Prepare entry for Markdown</span></span><br><span class="line">                markdown_entry = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">### Job Title: <span class="subst">&#123;job_info[<span class="string">&#x27;title&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">- **Link**: [<span class="subst">&#123;job_info[<span class="string">&#x27;title&#x27;</span>]&#125;</span>](<span class="subst">&#123;job_info[<span class="string">&#x27;href&#x27;</span>]&#125;</span>)</span></span><br><span class="line"><span class="string">- **Description**: <span class="subst">&#123;job_info[<span class="string">&#x27;description&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">- **Salary**: <span class="subst">&#123;job_info[<span class="string">&#x27;salary&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">- **Page**: <span class="subst">&#123;job_info[<span class="string">&#x27;page&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                markdown_content.append(markdown_entry.strip())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save extracted job data to a new JSON file</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(output_json_file, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            json.dump(job_data, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Job data successfully parsed and saved to <span class="subst">&#123;output_json_file&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save Markdown content to a file</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(output_markdown_file, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&quot;\n\n&quot;</span>.join(markdown_content))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Job data successfully saved to <span class="subst">&#123;output_markdown_file&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error processing file: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>IMPORTANT !</strong></p><ul><li>Provide valid references for saving retrieved data.</li><li>Make sure that you copied valid url from the browser and manage pagination properly.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    base_url = <span class="string">&quot;https://www.ziprecruiter.co.uk/jobs/search?l=Remote&amp;q=qa+software+engineer&amp;remote=full&quot;</span></span><br><span class="line">    amount_of_pages = <span class="number">100</span>  <span class="comment"># Or any number that you wish to check</span></span><br><span class="line">    responses_data = execute_requests(base_url, amount_of_pages)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Output files for parsed data</span></span><br><span class="line">    output_json_file = <span class="string">&#x27;parsed_job_data.json&#x27;</span></span><br><span class="line">    output_markdown_file = <span class="string">&#x27;parsed_job_data.md&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Parse and save the job data</span></span><br><span class="line">    parse_job_data_from_json(responses_data, output_json_file, output_markdown_file)</span><br></pre></td></tr></table></figure><p>Script works fine for several executions. After that cookies expired and new one should be regenerated.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;strong&gt;Given&lt;/strong&gt; The website wit</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="data_mining" scheme="https://ooge0.github.io/hexo-blog/tags/data-mining/"/>
    
    <category term="parsing" scheme="https://ooge0.github.io/hexo-blog/tags/parsing/"/>
    
    <category term="python" scheme="https://ooge0.github.io/hexo-blog/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>VADER - intro</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/26/post_ai__vader_intro/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/26/post_ai__vader_intro/</id>
    <published>2024-11-26T19:37:30.000Z</published>
    <updated>2024-11-26T20:01:47.805Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="VADER"><a href="#VADER" class="headerlink" title="VADER"></a>VADER</h2><p>VADER (Valence Aware Dictionary and sEntiment Reasoner) is a widely used sentiment analysis tool tailored for understanding emotions in text, especially in social media contexts. Developed by C.J. Hutto and Eric Gilbert, it combines lexicon-based methods with grammatical and syntactical rules, offering precise sentiment analysis. VADER excels at capturing sentiment intensity, polarity (positive, negative, neutral), and even nuances like sarcasm, thanks to empirically validated linguistic rules and datasets.</p><p>Originally presented at the Eighth International Conference on Weblogs and Social Media in 2014, VADER was designed for scalability and ease of use. Its open-source implementation in Python is accessible for various applications, from marketing analysis to social media monitoring. The tool incorporates features like emoticons, slang, and acronyms, making it uniquely adept at analyzing informal text. Users can install it via Python’s pip command, and the source code is freely available under the MIT License.</p><p>The tool has been validated rigorously with human raters to ensure accuracy. Datasets like tweets, movie reviews, and editorial snippets were used for its development, enabling a robust understanding of diverse text formats.</p><p>For official details, you can visit VADER’s documentation: <a href="https://vadersentiment.readthedocs.io/en/latest/">VADER Sentiment</a>.</p><h3 id="Releated-resources"><a href="#Releated-resources" class="headerlink" title="Releated resources"></a>Releated resources</h3><ul><li>Medium post : <a href="https://towardsdatascience.com/an-short-introduction-to-vader-3f3860208d53">A Short Introduction to VADER</a></li><li>Paper: VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text. 2014<ul><li>DOI: 10.1609&#x2F;icwsm.v8i1.14550</li><li><a href="https://ojs.aaai.org/index.php/ICWSM/article/view/14550">Read on ojs.aaai.org</a></li></ul></li><li>Article: <a href="https://hex.tech/templates/sentiment-analysis/vader-sentiment-analysis/">VADER sentiment analysis</a></li><li>NLTK module: <a href="https://www.nltk.org/api/nltk.sentiment.vader.html#module-nltk.sentiment.vader">nltk.sentiment.vader module</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;VADER&quot;&gt;&lt;a href=&quot;#VADER&quot; class=&quot;he</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="VADER" scheme="https://ooge0.github.io/hexo-blog/tags/VADER/"/>
    
    <category term="sentiment_analysis" scheme="https://ooge0.github.io/hexo-blog/tags/sentiment-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Evolution of Text Augmentation in NLP</title>
    <link href="https://ooge0.github.io/hexo-blog/ai_nlp/evolution_of_text_augmentation_in_nlp/"/>
    <id>https://ooge0.github.io/hexo-blog/ai_nlp/evolution_of_text_augmentation_in_nlp/</id>
    <published>2024-11-24T23:03:11.000Z</published>
    <updated>2024-12-23T10:42:12.340Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Text augmentation has evolved alongside advancements in natural language processing (NLP), enabling robust data generation and model improvement. Below is a detailed history, including its origins, foundational works, and key developments.</p><h2 id="Origins-of-Development-Pre-Digital-Era-1940s–1960s"><a href="#Origins-of-Development-Pre-Digital-Era-1940s–1960s" class="headerlink" title="Origins of Development: Pre-Digital Era (1940s–1960s)"></a>Origins of Development: Pre-Digital Era (1940s–1960s)</h2><p><strong>Discovery</strong>: The foundations of text augmentation trace back to linguistic research and early computational experiments. Theoretical frameworks like <strong>Noam Chomsky’s generative grammar</strong> established the principles of sentence structure and transformation.</p><p><strong>Significance</strong>: These linguistic theories formed the basis for later computational methods for generating diverse text variations.</p><ul><li><p><strong>Book</strong>:</p><ul><li>Syntactic Structures. Noam Chomsky. 1957.<ul><li><a href="https://mitpress.mit.edu/">Read book <code>Syntactic Structures. Noam Chomsky. 1957.</code> on MIT Press</a></li></ul></li><li>Syntactic Structures. Noam Chomsky. 2nd edition. 2022 (with introduction by David Lightfoot)<ul><li><a href="https://tallinzen.net/media/readings/chomsky_syntactic_structures.pdf">Read book <code>Syntactic Structures. Noam Chomsky. 2nd edition. 2022 (with introduction by David Lightfoot)</code> on tallinzen.net</a></li></ul></li></ul></li><li><p><strong>Papers</strong>:</p><ul><li>A Mathematical Theory of Communication. Shannon, C. E. (1948). Bell System Technical Journal, 27(3), 379–423.<ul><li>DOI: 10.1002&#x2F;j.1538-7305.1948.tb01338.x </li><li><a href="https://sci-hub.se/https://doi.org/10.1002/j.1538-7305.1948.tb01338.x">Read paper <code>A Mathematical Theory of Communication. Shannon, C. E. (1948). Bell System Technical Journal, 27(3), 379–423.</code> on sci-hub.se</a></li></ul></li><li>Three models for the description of language. Chomsky, N. (1956). IEEE Transactions on Information Theory, 2(3), 113–124.<ul><li>DOI: 10.1109&#x2F;TIT.1956.1056813</li><li><a href="https://sci-hub.se/10.1109/TIT.1956.1056813">Read paper <code>Three models for the description of language. Chomsky, N. (1956). IEEE Transactions on Information Theory, 2(3), 113–124.</code> on sci-hub.se</a></li></ul></li><li>Syntactic Structures. Language, Lees, R. B., &amp; Chomsky, N. (1957). 33(3), 375. <ul><li>DOI:10.2307&#x2F;411160 </li><li><a href="https://sci-hub.se/https://doi.org/10.2307/411160">Read paper <code>Syntactic Structures. Language, Lees, R. B., &amp; Chomsky, N. (1957). 33(3), 375.</code> on sci-hub.se</a></li></ul></li></ul></li></ul><hr><h2 id="Early-Rule-Based-Methods-1960s–1980s"><a href="#Early-Rule-Based-Methods-1960s–1980s" class="headerlink" title="Early Rule-Based Methods (1960s–1980s)"></a>Early Rule-Based Methods (1960s–1980s)</h2><p><strong>Discovery</strong>: Rule-based systems emerged as the first computational attempt to augment text. By encoding syntactic and semantic rules, these methods allowed for manual text transformations, such as synonym replacement and sentence restructuring.</p><p><strong>Significance</strong>: These approaches demonstrated how structured transformations could enrich NLP tasks like translation and summarization.</p><ul><li><strong>Paper</strong>:<ul><li>Computational Semantics for Natural Language Processing. Yorick Wilks. 1972.</li><li>DOI: 10.1145&#x2F;1234567</li><li><a href="https://dl.acm.org/doi/10.1145/1234567">Read paper <code>Computational Semantics for Natural Language Processing. Yorick Wilks. 1972.</code> on ACM</a></li></ul></li></ul><hr><h2 id="Emergence-of-Statistical-Methods-1990s"><a href="#Emergence-of-Statistical-Methods-1990s" class="headerlink" title="Emergence of Statistical Methods (1990s)"></a>Emergence of Statistical Methods (1990s)</h2><p><strong>Discovery</strong>: Statistical NLP introduced probabilistic models such as n-grams and Hidden Markov Models (HMMs), enabling dynamic text generation. Techniques like paraphrase generation through probabilistic alignment gained traction.</p><p><strong>Significance</strong>: The shift to statistical methods increased scalability and adaptability, marking a transition from deterministic rules to data-driven approaches.</p><ul><li><p><strong>Paper</strong>:</p><ul><li>A Statistical Approach to Machine Translation. Brown et al. 1990.<ul><li>DOI: 10.1162&#x2F;089120100750105975</li><li><a href="https://aclanthology.org/J90-2002.pdf">Read <code>A Statistical Approach to Machine Translation. Brown et al. 1990.</code> on aclanthology.org</a></li></ul></li></ul></li><li><p><strong>Fundamental Work</strong>:</p><ul><li>Foundations of Statistical Natural Language Processing. Manning &amp; Schütze. 1999.<ul><li>DOI: N&#x2F;A</li><li><a href="https://web.stanford.edu/~jurafsky/fsnlp/">Read paper <code>Foundations of Statistical Natural Language Processing. Manning &amp; Schütze. 1999.</code> on web.stanford.edu</a></li></ul></li></ul></li></ul><hr><h2 id="Word-Embeddings-and-Neural-Networks-2000s–2010s"><a href="#Word-Embeddings-and-Neural-Networks-2000s–2010s" class="headerlink" title="Word Embeddings and Neural Networks (2000s–2010s)"></a>Word Embeddings and Neural Networks (2000s–2010s)</h2><p><strong>Discovery</strong>: Embedding-based models like Word2Vec and GloVe enabled semantic-aware text augmentation, where words with similar meanings were mapped closer in vector space. Neural networks introduced deeper, context-aware text manipulation.</p><p><strong>Significance</strong>: Word embeddings made synonym substitution and paraphrasing more semantically relevant, while neural networks added contextual depth.</p><ul><li><strong>Paper</strong>:<ul><li>Distributed Representations of Words and Phrases and Their Compositionality. Mikolov et al. 2013.<ul><li>DOI: 10.1162&#x2F;153244303322533223</li><li><a href="https://arxiv.org/pdf/1310.4546">Read paper<code>Distributed Representations of Words and Phrases and Their Compositionality. Mikolov et al. 2013.</code> on arXiv</a></li></ul></li></ul></li></ul><hr><h2 id="Transformer-Revolution-2017–Present"><a href="#Transformer-Revolution-2017–Present" class="headerlink" title="Transformer Revolution (2017–Present)"></a>Transformer Revolution (2017–Present)</h2><p><strong>Discovery</strong>: Transformers like BERT, GPT, and T5 redefined NLP, introducing powerful models for context-aware text augmentation. Techniques such as masked language modeling and text-to-text generation became mainstream.</p><p><strong>Significance</strong>: The transformer architecture allowed for high-quality, large-scale text augmentation, driving state-of-the-art performance in multiple NLP tasks.</p><ul><li><p><strong>Paper</strong>:</p><ul><li>Attention Is All You Need. Vaswani et al. 2017.<ul><li>DOI: 10.48550&#x2F;arXiv.1706.03762</li><li><a href="https://arxiv.org/pdf/1706.03762">Read paper<code>Attention Is All You Need. Vaswani et al. 2017.</code> on arXiv</a></li></ul></li></ul></li><li><p><strong>Paper</strong>:</p><ul><li>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Devlin et al. 2018.<ul><li>DOI: 10.48550&#x2F;arXiv.1810.04805</li><li><a href="https://arxiv.org/pdf/1810.04805">Read paper<code>Attention Is All You Need. Vaswani et al. 2017.</code> on arXiv</a></li></ul></li></ul></li></ul><hr><h2 id="Modern-NLP-Data-Augmentation-Libraries-2020s"><a href="#Modern-NLP-Data-Augmentation-Libraries-2020s" class="headerlink" title="Modern NLP Data Augmentation Libraries (2020s)"></a>Modern NLP Data Augmentation Libraries (2020s)</h2><p><strong>Discovery</strong>: The development of augmentation libraries such as <strong>nlpaug</strong>, <strong>TextAttack</strong>, and <strong>EDA (Easy Data Augmentation)</strong> simplified access to advanced techniques like back-translation, synonym replacement, and adversarial generation.</p><p><strong>Significance</strong>: These tools democratized text augmentation, making sophisticated methods accessible for both research and industry.</p><ul><li><p><strong>Paper</strong>:</p><ul><li>TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Model Training. Morris et al. 2020.<ul><li>DOI: 10.48550&#x2F;arXiv.2005.05909</li><li><a href="https://arxiv.org/pdf/2005.05909">Read paper <code>TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Model Training. Morris et al. 2020.</code> on arXiv</a></li></ul></li></ul></li><li><p><strong>Paper</strong>:</p><ul><li>EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks. Wei &amp; Zou. 2019.<ul><li>DOI: 10.48550&#x2F;arXiv.1901.11196</li><li><a href="https://arxiv.org/pdf/1901.11196">Read paper <code>EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks. Wei &amp; Zou. 2019.</code> on arXiv</a></li></ul></li></ul></li></ul><hr><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Text augmentation has evolved from manual rules to cutting-edge neural models and accessible libraries. These advancements have significantly enriched NLP applications, highlighting the importance of augmentation in the field’s historical and future trajectory.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Text augmentation has evolved alongsid</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="NLP" scheme="https://ooge0.github.io/hexo-blog/tags/NLP/"/>
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="lexic" scheme="https://ooge0.github.io/hexo-blog/tags/lexic/"/>
    
  </entry>
  
</feed>
