<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title> </title>
  
  <subtitle>...chasing dreams, living reality</subtitle>
  <link href="https://ooge0.github.io/hexo-blog/atom.xml" rel="self"/>
  
  <link href="https://ooge0.github.io/hexo-blog/"/>
  <updated>2024-12-04T20:38:06.482Z</updated>
  <id>https://ooge0.github.io/hexo-blog/</id>
  
  <author>
    <name>si0n4ra</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>BERT configuration parameters overview</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/12/04/post_ai_llm__bert_configuration_parameters_overview/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/12/04/post_ai_llm__bert_configuration_parameters_overview/</id>
    <published>2024-12-04T20:08:12.000Z</published>
    <updated>2024-12-04T20:38:06.482Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="This-post-related-to-1-Techniques-for-Handling-Context-in-AI-Models2-GPT2-configuration-parameters-overview3-BART-configuration-parameters-overview"><a href="#This-post-related-to-1-Techniques-for-Handling-Context-in-AI-Models2-GPT2-configuration-parameters-overview3-BART-configuration-parameters-overview" class="headerlink" title="This post related to:1. Techniques for Handling Context in AI Models2. GPT2 configuration parameters overview3. BART configuration parameters overview"></a><em>This post related to:</em><br>1. <a href="../../../../post_ai_llm__techniques_for_handling_context_in_ai_models">Techniques for Handling Context in AI Models</a><br>2. <a href="../../../../post_ai_llm__gpt2_configuration_parameters_overview">GPT2 configuration parameters overview</a><br>3. <a href="../../../../post_ai_llm__bart_configuration_parameters_overview">BART configuration parameters overview</a></h2><h2 id="Parameters-list-and-descriptions"><a href="#Parameters-list-and-descriptions" class="headerlink" title="Parameters list and descriptions"></a>Parameters list and descriptions</h2><table><thead><tr><th><strong>Parameter</strong></th><th><strong>Description</strong></th><th><strong>Data Type&#x2F;Options</strong></th></tr></thead><tbody><tr><td><code>hidden_size</code></td><td>Dimensionality of the hidden states and embeddings.</td><td>Integer, e.g., <code>768</code>, <code>1024</code>.</td></tr><tr><td><code>num_hidden_layers</code></td><td>Number of hidden layers in the transformer encoder.</td><td>Integer, e.g., <code>12</code>, <code>24</code>.</td></tr><tr><td><code>num_attention_heads</code></td><td>Number of attention heads per transformer layer.</td><td>Integer, typically a divisor of <code>hidden_size</code>.</td></tr><tr><td><code>vocab_size</code></td><td>Vocabulary size of the tokenizer. Represents the range of token IDs.</td><td>Integer, e.g., <code>30522</code>.</td></tr><tr><td><code>intermediate_size</code></td><td>Dimensionality of the feedforward layers.</td><td>Integer, e.g., <code>3072</code>.</td></tr><tr><td><code>hidden_dropout_prob</code></td><td>Dropout probability for fully connected layers in the encoder.</td><td>Float between <code>0.0</code> and <code>1.0</code>, typically <code>0.1</code>.</td></tr><tr><td><code>attention_probs_dropout_prob</code></td><td>Dropout probability in the attention mechanism.</td><td>Float between <code>0.0</code> and <code>1.0</code>, typically <code>0.1</code>.</td></tr><tr><td><code>max_position_embeddings</code></td><td>Maximum number of positions for input tokens.</td><td>Integer, e.g., <code>512</code>.</td></tr><tr><td><code>type_vocab_size</code></td><td>Size of the token type vocabulary for segment embeddings.</td><td>Integer, typically <code>2</code>.</td></tr><tr><td><code>initializer_range</code></td><td>Standard deviation for weight initialization.</td><td>Float, e.g., <code>0.02</code>.</td></tr><tr><td><code>layer_norm_eps</code></td><td>A small value added for numerical stability in layer normalization.</td><td>Float, typically <code>1e-5</code>.</td></tr><tr><td><code>output_hidden_states</code></td><td>Whether to output all hidden states from each layer.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>output_attentions</code></td><td>Whether to output the attention weights.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr></tbody></table><h2 id="Summary-of-parameter-impact"><a href="#Summary-of-parameter-impact" class="headerlink" title="Summary of parameter impact"></a>Summary of parameter impact</h2><h3 id="How-changes-reflect-on-model-behavior"><a href="#How-changes-reflect-on-model-behavior" class="headerlink" title="How changes reflect on model behavior:"></a>How changes reflect on model behavior:</h3><ol><li><p><strong>Capacity:</strong></p><ul><li>Increasing <code>hidden_size</code>, <code>num_hidden_layers</code>, or <code>num_attention_heads</code> allows the model to capture more complex patterns but increases resource usage.</li></ul></li><li><p><strong>Regularization:</strong></p><ul><li>Dropout probabilities (<code>hidden_dropout_prob</code>, <code>attention_probs_dropout_prob</code>) control overfitting risks but can hinder learning if set too high.</li></ul></li><li><p><strong>Pretraining vs. Fine-tuning:</strong></p><ul><li><code>type_vocab_size</code> is essential for tasks requiring segment embeddings (e.g., sentence pairs).</li></ul></li><li><p><strong>Stability and Efficiency:</strong></p><ul><li><code>layer_norm_eps</code> ensures stable training, while <code>initializer_range</code> affects convergence.</li></ul></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Paper</li><li>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</li><li>DOI: 10.48550&#x2F;arXiv.1810.04805</li><li><a href="https://arxiv.org/abs/1810.04805">Read on </a></li><li><a href="https://huggingface.co/docs/transformers/model_doc/bert">Hugging Face BERT Documentation</a></li></ul><h2 id="Challenges-and-reports-on-configuration"><a href="#Challenges-and-reports-on-configuration" class="headerlink" title="Challenges and reports on configuration"></a>Challenges and reports on configuration</h2><ul><li><strong>Report:</strong> “On the Structural Properties of BERT Models” (Kovaleva et al., 2019).</li><li><strong>Challenges:</strong> Over-parameterization and inefficiency in fine-tuning for domain-specific tasks.</li></ul><h2 id="Playgrounds-to-experiment"><a href="#Playgrounds-to-experiment" class="headerlink" title="Playgrounds to experiment"></a>Playgrounds to experiment</h2><ul><li><strong>Hugging Face Spaces:</strong> <a href="https://huggingface.co/spaces">https://huggingface.co/spaces</a></li><li><strong>Google Colab with Transformers:</strong> <a href="https://colab.research.google.com/">https://colab.research.google.com/</a></li><li><strong>OpenAI Playground for Text Understanding:</strong> <a href="https://platform.openai.com/playground">https://platform.openai.com/playground</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;This-post-related-to-1-Techniques</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="LLM" scheme="https://ooge0.github.io/hexo-blog/tags/LLM/"/>
    
    <category term="BERT" scheme="https://ooge0.github.io/hexo-blog/tags/BERT/"/>
    
  </entry>
  
  <entry>
    <title>BART configuration parameters overview</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/12/04/post_ai_llm__bart_configuration_parameters_overview/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/12/04/post_ai_llm__bart_configuration_parameters_overview/</id>
    <published>2024-12-04T20:08:12.000Z</published>
    <updated>2024-12-04T20:39:12.658Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>This post related to:</em></p><ol><li><a href="../../../../post_ai_llm__techniques_for_handling_context_in_ai_models">Techniques for Handling Context in AI Models</a></li></ol><hr><h2 id="Parameters-list-and-descriptions"><a href="#Parameters-list-and-descriptions" class="headerlink" title="Parameters list and descriptions"></a>Parameters list and descriptions</h2><table><thead><tr><th><strong>Parameter</strong></th><th><strong>Description</strong></th><th><strong>Data Type&#x2F;Options</strong></th></tr></thead><tbody><tr><td><code>max_position_embeddings</code></td><td>Maximum number of positions for input tokens.</td><td>Integer, e.g., <code>1024</code>.</td></tr><tr><td><code>d_model</code></td><td>Dimensionality of the model’s embeddings and hidden states.</td><td>Integer, e.g., <code>768</code>, <code>1024</code>.</td></tr><tr><td><code>encoder_layers</code></td><td>Number of layers in the encoder.</td><td>Integer, e.g., <code>6</code>, <code>12</code>.</td></tr><tr><td><code>decoder_layers</code></td><td>Number of layers in the decoder.</td><td>Integer, e.g., <code>6</code>, <code>12</code>.</td></tr><tr><td><code>encoder_attention_heads</code></td><td>Number of attention heads in the encoder.</td><td>Integer, e.g., <code>12</code>.</td></tr><tr><td><code>decoder_attention_heads</code></td><td>Number of attention heads in the decoder.</td><td>Integer, e.g., <code>12</code>.</td></tr><tr><td><code>vocab_size</code></td><td>Vocabulary size of the tokenizer. Represents the range of token IDs.</td><td>Integer, e.g., <code>50265</code>.</td></tr><tr><td><code>activation_function</code></td><td>Activation function used in feedforward layers.</td><td>String: <code>relu</code>, <code>gelu</code>, <code>tanh</code>, etc.</td></tr><tr><td><code>dropout</code></td><td>Dropout probability applied to various layers.</td><td>Float between <code>0.0</code> and <code>1.0</code>, typically <code>0.1</code>.</td></tr><tr><td><code>attention_dropout</code></td><td>Dropout probability in the attention mechanism.</td><td>Float between <code>0.0</code> and <code>1.0</code>, typically <code>0.1</code>.</td></tr><tr><td><code>init_std</code></td><td>Standard deviation for weight initialization.</td><td>Float, e.g., <code>0.02</code>.</td></tr><tr><td><code>encoder_ffn_dim</code></td><td>Dimensionality of the encoder feedforward layers.</td><td>Integer, e.g., <code>3072</code>.</td></tr><tr><td><code>decoder_ffn_dim</code></td><td>Dimensionality of the decoder feedforward layers.</td><td>Integer, e.g., <code>3072</code>.</td></tr><tr><td><code>scale_embedding</code></td><td>Whether to scale the embeddings by <code>sqrt(d_model)</code>.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>use_cache</code></td><td>Whether to use cached key&#x2F;values for faster decoding.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>pad_token_id</code></td><td>Token ID used for padding.</td><td>Integer, typically <code>0</code>.</td></tr><tr><td><code>bos_token_id</code></td><td>Token ID for the beginning-of-sequence token.</td><td>Integer, typically <code>0</code>.</td></tr><tr><td><code>eos_token_id</code></td><td>Token ID for the end-of-sequence token.</td><td>Integer, typically <code>2</code>.</td></tr></tbody></table><h2 id="Summary-of-parameter-impact"><a href="#Summary-of-parameter-impact" class="headerlink" title="Summary of parameter impact"></a>Summary of parameter impact</h2><h3 id="How-Changes-Reflect-on-Model-Behavior"><a href="#How-Changes-Reflect-on-Model-Behavior" class="headerlink" title="How Changes Reflect on Model Behavior:"></a>How Changes Reflect on Model Behavior:</h3><ol><li><p><strong>Model Complexity:</strong></p><ul><li>Increasing <code>encoder_layers</code>, <code>decoder_layers</code>, <code>d_model</code>, or attention heads enhances model capacity but increases computational requirements.</li></ul></li><li><p><strong>Regularization:</strong></p><ul><li>Dropout parameters (<code>dropout</code>, <code>attention_dropout</code>) control overfitting risks but may reduce performance if too high.</li></ul></li><li><p><strong>Encoder-Decoder interactions:</strong></p><ul><li><code>encoder_ffn_dim</code> and <code>decoder_ffn_dim</code> directly influence the learning ability of the model for complex patterns.</li></ul></li><li><p><strong>Efficiency:</strong></p><ul><li>Enabling <code>use_cache</code> improves inference time for autoregressive tasks.</li></ul></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Paper: BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension<ul><li><a href="https://arxiv.org/pdf/1910.13461">Read on arxiv.org</a></li><li>DOI:10.48550&#x2F;arXiv.1910.13461</li></ul></li><li>Paper: Improving Sharpness-Aware Minimization with Fisher Mask for Better Generalization on Language Models<ul><li>DOI:10.48550&#x2F;arXiv.2210.05497</li><li><a href="https://arxiv.org/pdf/2210.05497">Read on arxiv.org</a></li></ul></li><li><a href="https://huggingface.co/docs/transformers/model_doc/bart">Hugging Face BART Documentation</a></li><li>Web article: <a href="https://medium.com/@nadirapovey/bart-model-architecture-8ac1cea0e877">BART Model Architecture | Medium</a></li><li>Web article: <a href="https://www.projectpro.io/article/transformers-bart-model-explained/553">Transformers BART Model Explained for Text Summarization | projectpro.io</a></li><li>Google colab notebook: <a href="https://colab.research.google.com/drive/1Cy27V-7qqYatqMA7fEqG2kgMySZXw9I4?usp=sharing&pli=1">BART Learns to Rap - Medium.ipynb</a></li></ul><h2 id="Challenges-and-reports-on-configuration"><a href="#Challenges-and-reports-on-configuration" class="headerlink" title="Challenges and reports on configuration"></a>Challenges and reports on configuration</h2><ul><li><p><strong>Report:</strong> </p><ul><li>Paper: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. Raffel et al., 2020.<ul><li>DOI: 10.48550&#x2F;arXiv.1910.10683</li><li><a href="https://arxiv.org/pdf/1910.10683">Read on arxiv.org</a></li></ul></li></ul></li><li><p><strong>Challenges:</strong> Balancing fine-tuning for generative and discriminative tasks in sequence-to-sequence models.</p><ul><li>Paper: Unified Generative and Discriminative Training for Multi-modal Large Language Models<ul><li><a href="https://arxiv.org/html/2411.00304v1">Read on arxiv.org</a></li></ul></li></ul></li></ul><h2 id="Playgrounds-to-experiment"><a href="#Playgrounds-to-experiment" class="headerlink" title="Playgrounds to experiment"></a>Playgrounds to experiment</h2><ul><li><strong>Hugging Face Spaces:</strong> <a href="https://huggingface.co/spaces">https://huggingface.co/spaces</a></li><li><strong>Google Colab with Transformers:</strong> <a href="https://colab.research.google.com/">https://colab.research.google.com/</a></li><li><strong>OpenAI Playground for Generative Tasks:</strong> <a href="https://platform.openai.com/playground">https://platform.openai.com/playground</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;This post related to:&lt;/em&gt;&lt;/p&gt;
&lt;ol</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="LLM" scheme="https://ooge0.github.io/hexo-blog/tags/LLM/"/>
    
    <category term="BART" scheme="https://ooge0.github.io/hexo-blog/tags/BART/"/>
    
  </entry>
  
  <entry>
    <title>GPT-2 configuration parameters overview</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/12/04/post_ai_llm__gpt2_configuration_parameters_overview/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/12/04/post_ai_llm__gpt2_configuration_parameters_overview/</id>
    <published>2024-12-04T18:08:12.000Z</published>
    <updated>2024-12-04T20:15:21.663Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>This post related to:</em></p><ol><li><a href="../../../../post_ai_llm__techniques_for_handling_context_in_ai_models">Techniques for Handling Context in AI Models</a></li><li><a href="../../../../post_ai_llm__bart_configuration_parameters_overview">BART configuration parameters overview</a></li></ol><hr><h2 id="Parameters-List-and-Descriptions"><a href="#Parameters-List-and-Descriptions" class="headerlink" title="Parameters List and Descriptions"></a>Parameters List and Descriptions</h2><table><thead><tr><th><strong>Parameter</strong></th><th><strong>Description</strong></th><th><strong>Data Type&#x2F;Options</strong></th></tr></thead><tbody><tr><td><code>n_ctx</code></td><td>The context size or maximum length of input tokens the model can process.</td><td>Integer, e.g., <code>1024</code>, <code>2048</code>.</td></tr><tr><td><code>n_embd</code></td><td>Dimensionality of the embeddings. Determines the size of the word and positional embeddings.</td><td>Integer, typically <code>768</code>, <code>1024</code>, or <code>1280</code>.</td></tr><tr><td><code>n_layer</code></td><td>Number of transformer layers in the model. Dictates depth of the network.</td><td>Integer, e.g., <code>12</code>, <code>24</code>, <code>48</code>.</td></tr><tr><td><code>n_head</code></td><td>Number of attention heads in each transformer layer. Reflects parallel attention mechanisms.</td><td>Integer, typically a divisor of <code>n_embd</code> such as <code>12</code> or <code>16</code>.</td></tr><tr><td><code>vocab_size</code></td><td>Size of the vocabulary for the tokenizer. Represents the range of token IDs the model can handle.</td><td>Integer, e.g., <code>50257</code>.</td></tr><tr><td><code>activation_function</code></td><td>The activation function used in feedforward layers (e.g., “gelu”). Affects non-linearity.</td><td>String: <code>relu</code>, <code>gelu</code>, <code>tanh</code>, <code>sigmoid</code>, etc.</td></tr><tr><td><code>resid_pdrop</code></td><td>Dropout probability for residual connections. Adds regularization.</td><td>Float between <code>0.0</code> and <code>1.0</code>. Typically <code>0.1</code>.</td></tr><tr><td><code>embd_pdrop</code></td><td>Dropout probability for embeddings. Helps prevent overfitting.</td><td>Float between <code>0.0</code> and <code>1.0</code>. Typically <code>0.1</code>.</td></tr><tr><td><code>attn_pdrop</code></td><td>Dropout probability in the attention mechanism. Ensures robustness.</td><td>Float between <code>0.0</code> and <code>1.0</code>. Typically <code>0.1</code>.</td></tr><tr><td><code>initializer_range</code></td><td>The range of the uniform distribution for weight initialization.</td><td>Float, e.g., <code>0.02</code>.</td></tr><tr><td><code>layer_norm_epsilon</code></td><td>A small value added for numerical stability in layer normalization.</td><td>Float, typically <code>1e-5</code>.</td></tr><tr><td><code>use_cache</code></td><td>Whether the model uses cached key&#x2F;values for faster generation during inference.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>bos_token_id</code></td><td>Token ID for the beginning-of-sequence token.</td><td>Integer, e.g., <code>50256</code>.</td></tr><tr><td><code>eos_token_id</code></td><td>Token ID for the end-of-sequence token.</td><td>Integer, e.g., <code>50256</code>.</td></tr><tr><td><code>scale_attn_weights</code></td><td>Whether to scale the attention weights.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>output_hidden_states</code></td><td>Whether to return all hidden states from each layer during inference.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>output_attentions</code></td><td>Whether to return the attention weights during inference.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr><tr><td><code>tie_word_embeddings</code></td><td>Whether to tie the input and output word embeddings.</td><td>Boolean, <code>true</code> or <code>false</code>.</td></tr></tbody></table><hr><h2 id="Summary-of-Parameter-Impact"><a href="#Summary-of-Parameter-Impact" class="headerlink" title="Summary of Parameter Impact"></a>Summary of Parameter Impact</h2><h3 id="How-changes-reflect-on-model-behavior"><a href="#How-changes-reflect-on-model-behavior" class="headerlink" title="How changes reflect on model behavior:"></a>How changes reflect on model behavior:</h3><ol><li><p><strong>Model Size and Computation:</strong></p><ul><li>Increasing <code>n_layer</code>, <code>n_embd</code>, or <code>n_head</code> leads to larger and more computationally intensive models but potentially improves learning capacity.</li><li>Reducing <code>n_ctx</code> limits the model’s ability to process long inputs.</li></ul></li><li><p><strong>Regularization:</strong></p><ul><li>Dropout parameters (<code>resid_pdrop</code>, <code>embd_pdrop</code>, <code>attn_pdrop</code>) mitigate overfitting but may hinder performance if too high.</li></ul></li><li><p><strong>Non-linearity:</strong></p><ul><li>The choice of <code>activation_function</code> (e.g., <code>gelu</code> vs. <code>relu</code>) affects gradient behavior and optimization efficiency.</li></ul></li><li><p><strong>Stability:</strong></p><ul><li>Small <code>layer_norm_epsilon</code> values ensure numerical stability during normalization but may require tuning based on the architecture.</li></ul></li><li><p><strong>Flexibility:</strong></p><ul><li>Enabling <code>output_hidden_states</code> or <code>output_attentions</code> increases interpretability but may slow inference.</li></ul></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2 Paper</a></li><li><a href="https://huggingface.co/docs/transformers/model_doc/gpt2">Hugging Face Documentation</a></li></ul><hr><h2 id="Challenges-and-reports-on-configuration"><a href="#Challenges-and-reports-on-configuration" class="headerlink" title="Challenges and reports on configuration"></a>Challenges and reports on configuration</h2><ul><li><strong>Report:</strong> “Language Models are Few-Shot Learners” (Brown et al., 2020) discusses scalability challenges in transformer-based architectures.</li><li><strong>Challenges:</strong> Balancing model depth and breadth while maintaining computational efficiency.</li></ul><hr><h2 id="Playgrounds-to-experiment"><a href="#Playgrounds-to-experiment" class="headerlink" title="Playgrounds to experiment"></a>Playgrounds to experiment</h2><ul><li><strong>OpenAI Playground:</strong> <a href="https://platform.openai.com/playground">https://platform.openai.com/playground</a></li><li><strong>Hugging Face Spaces:</strong> <a href="https://huggingface.co/spaces">https://huggingface.co/spaces</a></li><li><strong>Google Colab with Transformers:</strong> <a href="https://colab.research.google.com/">https://colab.research.google.com/</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;This post related to:&lt;/em&gt;&lt;/p&gt;
&lt;ol</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="LLM" scheme="https://ooge0.github.io/hexo-blog/tags/LLM/"/>
    
    <category term="GPT2" scheme="https://ooge0.github.io/hexo-blog/tags/GPT2/"/>
    
  </entry>
  
  <entry>
    <title>NLTK general</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/12/04/post_ai_nltk__general/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/12/04/post_ai_nltk__general/</id>
    <published>2024-12-04T09:21:11.000Z</published>
    <updated>2024-12-04T10:38:11.781Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="NLTK-Natural-Language-Toolkit-for-Natural-Language-Text-Processing-NLTP"><a href="#NLTK-Natural-Language-Toolkit-for-Natural-Language-Text-Processing-NLTP" class="headerlink" title="NLTK - Natural Language Toolkit for Natural Language Text Processing (NLTP)"></a>NLTK - Natural Language Toolkit for Natural Language Text Processing (NLTP)</h2><hr><h3 id="General"><a href="#General" class="headerlink" title="General"></a>General</h3><ol><li><a href="https://www.nltk.org/howto.html#example-usage-of-nltk-modules">Example usage of NLTK modules</a></li><li><a href="https://github.com/nltk/nltk/wiki">NLTK WIKI</a></li><li><a href="https://github.com/nltk/nltk/wiki/Projects">NLTK WIKI Projects</a></li><li><a href="https://github.com/nltk/nltk/FAQ">NLTK FAQ</a></li><li><a href="http://text-processing.com/demo/">NLTK Interactive online demos</a></li></ol><hr><h3 id="NLTK-books"><a href="#NLTK-books" class="headerlink" title="NLTK books"></a>NLTK books</h3><p><a href="https://www.nltk.org/book/">Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit. Steven Bird, Ewan Klein, and Edward Loper</a></p><hr><h4 id="NLTK-courses"><a href="#NLTK-courses" class="headerlink" title="NLTK courses"></a>NLTK courses</h4><p><a href="http://www.nltk.org/courses">NLTK courses</a></p><hr><h4 id="About-‘Natural-Language-Text-Processing’"><a href="#About-‘Natural-Language-Text-Processing’" class="headerlink" title="About ‘Natural Language Text Processing’"></a>About ‘Natural Language Text Processing’</h4><p>Natural Language Text Processing encompasses a range of techniques and tools to analyze, manipulate, and understand human language in text form. Below is a detailed explanation of key terms, their technical details, and implementation options in NLP.</p><p>Natural Language Text Processing include but not limited by <code>sentiment analysis</code>, which uses text classification to determine <code>sentiment polarity</code>, <code>word tokenization</code> , <code>stemming</code> text, <code>speech tagging</code> using <code>speech taggers</code>, <code>chunk extraction</code> and named <code>entity recognition</code>. </p><hr><h4 id="Sentiment-Analysis"><a href="#Sentiment-Analysis" class="headerlink" title="Sentiment Analysis"></a><strong>Sentiment Analysis</strong></h4><p><strong>Definition</strong>: Sentiment Analysis determines the emotional tone behind a body of text. It classifies text as positive, negative, or neutral.</p><p><strong>Approaches</strong>:</p><ol><li><strong>Lexicon-Based Methods</strong>:<ul><li>Use predefined dictionaries of positive and negative words.</li><li>Examples: SentiWordNet, VADER.</li></ul></li><li><strong>Machine Learning-Based Methods</strong>:<ul><li>Train a model on labeled datasets to classify sentiments.</li><li>Examples: Naive Bayes, Support Vector Machines (SVM).</li></ul></li><li><strong>Deep Learning Methods</strong>:<ul><li>Utilize neural networks like RNNs, LSTMs, or transformers.</li><li>Examples: BERT, RoBERTa, DistilBERT.</li></ul></li></ol><hr><h4 id="Word-Tokenization"><a href="#Word-Tokenization" class="headerlink" title="Word Tokenization"></a><strong>Word Tokenization</strong></h4><p><strong>Definition</strong>: The process of splitting a sentence or paragraph into individual words or tokens.</p><p><strong>Options</strong>:</p><ol><li><strong>Rule-Based Tokenization</strong>:<ul><li>Uses language-specific rules to split text.</li><li>Example Tools: NLTK, SpaCy.</li></ul></li><li><strong>Statistical Tokenization</strong>:<ul><li>Employs probabilistic models for token boundaries.</li><li>Examples: Punkt tokenizer.</li></ul></li><li><strong>Subword Tokenization</strong>:<ul><li>Splits text into subwords to handle rare words.</li><li>Examples: Byte Pair Encoding (BPE), WordPiece (used in BERT).</li></ul></li></ol><hr><h4 id="Stemming"><a href="#Stemming" class="headerlink" title="Stemming"></a><strong>Stemming</strong></h4><p><strong>Definition</strong>: Reduces words to their base or root form (e.g., “running” → “run”).</p><p><strong>Methods</strong>:</p><ol><li><strong>Porter Stemmer</strong>: Algorithmic and rule-based.</li><li><strong>Lancaster Stemmer</strong>: Faster but more aggressive.</li><li><strong>Snowball Stemmer</strong>: Improved version of Porter.</li></ol><p><strong>Usage</strong>: Common in search engines and text indexing.</p><hr><h4 id="Speech-Tagging"><a href="#Speech-Tagging" class="headerlink" title="Speech Tagging"></a><strong>Speech Tagging</strong></h4><p><strong>Definition</strong>: Assigning parts of speech (POS) tags (e.g., noun, verb) to each word in a text.</p><p><strong>Taggers</strong>:</p><ol><li><strong>Rule-Based POS Tagging</strong>:<ul><li>Uses manually crafted rules.</li></ul></li><li><strong>Statistical POS Tagging</strong>:<ul><li>Relies on probabilistic models (e.g., Hidden Markov Models).</li></ul></li><li><strong>Neural POS Tagging</strong>:<ul><li>Utilizes neural networks for higher accuracy.</li></ul></li></ol><p><strong>Example Tools</strong>: NLTK POS Tagger, SpaCy.</p><hr><h4 id="Chunk-Extraction"><a href="#Chunk-Extraction" class="headerlink" title="Chunk Extraction"></a><strong>Chunk Extraction</strong></h4><p><strong>Definition</strong>: Identifies and groups related words (e.g., noun phrases, verb phrases).</p><p><strong>Types</strong>:</p><ol><li><strong>Shallow Parsing</strong>:<ul><li>Focuses on high-level phrase detection.</li></ul></li><li><strong>Dependency Parsing</strong>:<ul><li>Analyzes grammatical structure by identifying relationships between words.</li></ul></li></ol><p><strong>Example Tools</strong>: OpenNLP, CoreNLP.</p><hr><h4 id="Named-Entity-Recognition-NER"><a href="#Named-Entity-Recognition-NER" class="headerlink" title="Named Entity Recognition (NER)"></a><strong>Named Entity Recognition (NER)</strong></h4><p><strong>Definition</strong>: Identifies and categorizes entities in text (e.g., names, organizations, dates).</p><p><strong>NER Types</strong>:</p><ol><li><strong>Rule-Based NER</strong>:<ul><li>Uses pattern-matching rules.</li><li>Examples: Regular Expressions.</li></ul></li><li><strong>Statistical NER</strong>:<ul><li>Trains models on labeled entity datasets.</li><li>Examples: Conditional Random Fields (CRF).</li></ul></li><li><strong>Neural NER</strong>:<ul><li>Deep learning-based methods for context understanding.</li><li>Examples: SpaCy, Flair, Hugging Face.</li></ul></li></ol><hr><h3 id="Implementation-in-NLP"><a href="#Implementation-in-NLP" class="headerlink" title="Implementation in NLP"></a><strong>Implementation in NLP</strong></h3><ol><li><p><strong>Libraries and Frameworks</strong>:</p><ul><li><strong>NLTK</strong>: A foundational library for tokenization, stemming, and POS tagging.</li><li><strong>SpaCy</strong>: Industrial-strength NLP with support for tokenization, POS tagging, NER, etc.</li><li><strong>Transformers (Hugging Face)</strong>: Pre-trained models for sentiment analysis, NER, and more.</li><li><strong>CoreNLP</strong>: Comprehensive NLP suite by Stanford.</li></ul></li><li><p><strong>Use Cases</strong>:</p><ul><li>Sentiment analysis in social media monitoring.</li><li>Tokenization in machine translation.</li><li>NER for information extraction from documents.</li></ul></li></ol><hr><p><em><strong>Related to this topic</strong></em>  </p><ol><li><a href="https://nlp.stanford.edu/">Natural Language Processing | Stanford NLP</a>  </li><li><a href="https://huggingface.co/">Understanding NLP Techniques | Hugging Face</a>  </li><li><a href="https://www.nltk.org/">NLTK Official Documentation</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;NLTK-Natural-Language-Toolkit-for</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="NLTK" scheme="https://ooge0.github.io/hexo-blog/tags/NLTK/"/>
    
  </entry>
  
  <entry>
    <title>Neural Process Family</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/30/post_ai_ml_npf__general/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/30/post_ai_ml_npf__general/</id>
    <published>2024-11-30T14:45:33.000Z</published>
    <updated>2024-11-30T15:18:33.089Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>The <strong>Neural Process Family</strong> refers to a class of models designed to learn distributions over functions, offering a blend of the expressiveness of deep learning and the flexibility of probabilistic models. These models are particularly useful for tasks requiring uncertainty quantification, few-shot learning, and function estimation. Key members of this family include <strong>Neural Processes (NPs)</strong>, <strong>Conditional Neural Processes (CNPs)</strong>, <strong>Attentive Neural Processes (ANPs)</strong>, and extensions like <strong>ConvCNPs</strong> and <strong>Variational NPs (VNPs)</strong>.</p><h2 id="Core-Concepts"><a href="#Core-Concepts" class="headerlink" title="Core Concepts"></a>Core Concepts</h2><ol><li><p><strong>Probabilistic Nature</strong>:<br>Neural Processes learn distributions over functions. Given a set of input-output pairs, they can predict the probability distribution of outputs for new inputs, making them suitable for uncertainty estimation.</p></li><li><p><strong>Few-Shot Learning</strong>:<br>These models can make predictions given only a few examples, making them ideal for problems where data is scarce.</p></li><li><p><strong>Model Components</strong>:</p><ul><li><strong>Encoder</strong>: Maps input-output pairs to a latent representation.</li><li><strong>Decoder</strong>: Takes the latent representation and generates outputs for given inputs.</li><li><strong>Latent Space</strong>: Captures the uncertainty and variability in the function space.</li></ul></li><li><p><strong>Meta-Learning</strong>:<br>NPs can generalize across tasks by learning a distribution over tasks, enabling them to perform well on unseen tasks after being trained on related ones.</p></li></ol><hr><h2 id="Variants-of-Neural-Processes"><a href="#Variants-of-Neural-Processes" class="headerlink" title="Variants of Neural Processes"></a>Variants of Neural Processes</h2><ol><li><p><strong>Conditional Neural Processes (CNPs)</strong>:</p><ul><li>A deterministic model that learns to map a context set of input-output pairs to predictions for new inputs.</li><li>Simple and efficient but limited in capturing uncertainty in the underlying function.</li></ul></li><li><p><strong>Neural Processes (NPs)</strong>:</p><ul><li>Adds a latent variable to model uncertainty explicitly, making it a probabilistic counterpart to CNPs.</li><li>Balances flexibility and computational efficiency.</li></ul></li><li><p><strong>Attentive Neural Processes (ANPs)</strong>:</p><ul><li>Introduces attention mechanisms to improve modeling of relationships between context points and query points.</li><li>Addresses issues with poor extrapolation and oversmoothing in standard NPs.</li></ul></li><li><p><strong>Convolutional Neural Processes (ConvCNPs)</strong>:</p><ul><li>Leverages convolutional architectures for tasks like image generation, capturing local correlations more effectively.</li></ul></li><li><p><strong>Variational Neural Processes (VNPs)</strong>:</p><ul><li>Focuses on improved variational inference techniques to better approximate the posterior distribution over functions.</li></ul></li></ol><hr><h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><ol><li><strong>Regression</strong>:<br>Modeling functions with uncertainty, e.g., Bayesian regression tasks.</li><li><strong>Few-Shot Classification</strong>:<br>Classifying data with limited examples by modeling task distributions.</li><li><strong>Spatio-Temporal Data</strong>:<br>Applications in time-series forecasting and spatial predictions.</li><li><strong>Reinforcement Learning</strong>:<br>Modeling uncertainty in reward functions or dynamics.</li><li><strong>Image Completion</strong>:<br>Predicting missing pixels in images.</li></ol><hr><h2 id="Strengths-and-Challenges"><a href="#Strengths-and-Challenges" class="headerlink" title="Strengths and Challenges"></a>Strengths and Challenges</h2><h3 id="Strengths"><a href="#Strengths" class="headerlink" title="Strengths:"></a>Strengths:</h3><ul><li>Scalability due to neural networks.</li><li>Probabilistic outputs allow uncertainty estimation.</li><li>Adaptable across domains with minimal changes.</li></ul><h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges:"></a>Challenges:</h3><ul><li>Trade-off between computational cost and flexibility.</li><li>Dependence on good representation learning.</li><li>Overcoming limitations of context aggregation in high-dimensional tasks.</li></ul><hr><p>The Neural Process Family continues to evolve, with active research aimed at improving its scalability, expressiveness, and applications to real-world problems.</p><hr><p>About:</p><ul><li><a href="https://yanndubs.github.io/Neural-Process-Family/">yanndubs.github.io | The Neural Process Family</a></li><li><a href="https://notes.theomorales.com/Gaussian+%26+Neural+Processes/The+Neural+Process+Family">notes.theomorales.com | The Neural Process Family</a></li></ul><hr><p> Papers: </p><ul><li>Papers: <ul><li>Title: The Neural Process Family: Survey, Applications<br>and Perspectives</li><li>DOI: 10.48550&#x2F;arXiv.2209.00517</li><li><a href="https://arxiv.org/pdf/2209.00517">Read on arxiv.org</a></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;The &lt;strong&gt;Neural Process Family&lt;/str</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
    <category term="NPF" scheme="https://ooge0.github.io/hexo-blog/tags/NPF/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning.Teach by Doing(LinkedIn post)</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/30/post_ai_ml__machine_learning_teach_by_doing/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/30/post_ai_ml__machine_learning_teach_by_doing/</id>
    <published>2024-11-30T14:33:33.000Z</published>
    <updated>2024-11-30T14:38:34.347Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>This is reopst of LinkedIN post. Current post contains list of references and some additional detilas</em></p><p>I(Author) started the Machine Learning: Teach by Doing series to transfer my learnings to those who want to transition to Machine Learning.</p><p>I(Author) have recorded 37 videos in the past 6 months.</p><p>Here are the links for you to learn:</p><ol><li>Introduction to Machine Learning Teach by Doing: <a href="https://lnkd.in/gqN2PMX5">https://lnkd.in/gqN2PMX5</a></li><li>What is Machine Learning? History of Machine Learning: <a href="https://lnkd.in/gvpNSAKh">https://lnkd.in/gvpNSAKh</a></li><li>Types of ML Models: <a href="https://lnkd.in/gSy2mChM">https://lnkd.in/gSy2mChM</a></li><li>6 steps of any ML project: <a href="https://lnkd.in/ggCGchPQ">https://lnkd.in/ggCGchPQ</a></li><li>Install Python and VSCode and run your first code: <a href="https://lnkd.in/gyic7J7b">https://lnkd.in/gyic7J7b</a></li><li>Linear Classifiers Part 1: <a href="https://lnkd.in/gYdfD97D">https://lnkd.in/gYdfD97D</a></li><li>Linear Classifiers Part 2: <a href="https://lnkd.in/gac_z-G8">https://lnkd.in/gac_z-G8</a></li><li>Jupyter Notebook, Numpy and Scikit-Learn: <a href="https://lnkd.in/gWRaC_tB">https://lnkd.in/gWRaC_tB</a></li><li>Running the Random Linear Classifier Algorithm in Python: <a href="https://lnkd.in/g5HacbFC">https://lnkd.in/g5HacbFC</a></li><li>The oldest ML model - Perceptron: <a href="https://lnkd.in/gpce6uFt">https://lnkd.in/gpce6uFt</a></li><li>Coding the Perceptron: <a href="https://lnkd.in/gmz-XjNK">https://lnkd.in/gmz-XjNK</a></li><li>Perceptron Convergence Theorem: <a href="https://lnkd.in/gmz-XjNK">https://lnkd.in/gmz-XjNK</a></li><li>Magic of features in Machine Learning: <a href="https://lnkd.in/gCeDRb3g">https://lnkd.in/gCeDRb3g</a></li><li>One hot encoding: <a href="https://lnkd.in/g3WfRQGQ">https://lnkd.in/g3WfRQGQ</a></li><li>Logistic Regression Part 1: <a href="https://lnkd.in/gTgZAAZn">https://lnkd.in/gTgZAAZn</a></li><li>Cross Entropy Loss: <a href="https://lnkd.in/g3Ywg_2p">https://lnkd.in/g3Ywg_2p</a></li><li>How gradient descent works: <a href="https://lnkd.in/gKBAsazF">https://lnkd.in/gKBAsazF</a></li><li>Logistic Regression from scratch in Python: <a href="https://lnkd.in/g8iZh27P">https://lnkd.in/g8iZh27P</a></li><li>Introduction to Regularization: <a href="https://lnkd.in/gjM9pVw2">https://lnkd.in/gjM9pVw2</a></li><li>Implementing Regularization in Python: <a href="https://lnkd.in/gRnSK4v4">https://lnkd.in/gRnSK4v4</a></li><li>Linear Regression Introduction: <a href="https://lnkd.in/gPYtSPJ9">https://lnkd.in/gPYtSPJ9</a></li><li>Ordinary Least Squares step by step implementation: <a href="https://lnkd.in/gnWQdgNy">https://lnkd.in/gnWQdgNy</a></li><li>Ridge regression fundamentals and intuition: <a href="https://lnkd.in/gE5M-CSM">https://lnkd.in/gE5M-CSM</a></li><li>Regression recap for interviews: <a href="https://lnkd.in/gNBWzzWv">https://lnkd.in/gNBWzzWv</a></li><li>Neural network architecture in 30 minutes: <a href="https://lnkd.in/g7qSrkxG">https://lnkd.in/g7qSrkxG</a></li><li>Backpropagation intuition: <a href="https://lnkd.in/gAmBARHm">https://lnkd.in/gAmBARHm</a></li><li>Neural network activation functions: <a href="https://lnkd.in/gqrC3zDP">https://lnkd.in/gqrC3zDP</a></li><li>Momentum in gradient descent: <a href="https://lnkd.in/g3M4qhbP">https://lnkd.in/g3M4qhbP</a></li><li>Hands on neural network training in Python: <a href="https://lnkd.in/gz-fTBxs">https://lnkd.in/gz-fTBxs</a></li><li>Introduction to Convolutional Neural Networks (CNNs.: <a href="https://lnkd.in/gpmuBm3j">https://lnkd.in/gpmuBm3j</a></li><li>Filters in 1D and the Convolution Operation: <a href="https://lnkd.in/gEDaKHDU">https://lnkd.in/gEDaKHDU</a></li><li>Filters in 2D, Channels and Feature Identification: <a href="https://lnkd.in/g3Gf_4ia">https://lnkd.in/g3Gf_4ia</a></li><li>Filtering Layers in Convolutional Neural Networks: <a href="https://lnkd.in/gUaiBkTu">https://lnkd.in/gUaiBkTu</a></li><li>What is Max Pooling in Convolutional Neural Networks?: <a href="https://lnkd.in/gGRGy6wq">https://lnkd.in/gGRGy6wq</a></li><li>CNN Architecture explained: <a href="https://lnkd.in/gPQvRh9i">https://lnkd.in/gPQvRh9i</a></li><li>Backpropagation in Convolutional Neural Networks: <a href="https://lnkd.in/g942G6zv">https://lnkd.in/g942G6zv</a></li><li>Build your own brain tumor classification CNN application in Python: <a href="https://lnkd.in/gQB5zRGk">https://lnkd.in/gQB5zRGk</a></li></ol><p>Join our AI live lectures waitlist here: <a href="https://lnkd.in/gDcHZdHg">https://lnkd.in/gDcHZdHg</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;This is reopst of LinkedIN post. C</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Parsing web site for job offers</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/28/post_data_mining__parsing_web_site_for_job_offers/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/28/post_data_mining__parsing_web_site_for_job_offers/</id>
    <published>2024-11-27T22:49:11.000Z</published>
    <updated>2024-11-27T23:20:32.939Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Given</strong> The website with posted offers.<br><strong>Goal:</strong> to get information from the website using python, BeautifulSoup and save it in JSON and markdown files.</p><p><strong>Python scirpt</strong></p><p>Install and import required packages</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">execute_requests</span>(<span class="params">base_url, amount_of_pages</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Executes GET requests for the specified number of pages and returns the responses.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        base_url (str): The base URL for requests.</span></span><br><span class="line"><span class="string">        amount_of_pages (int): The number of pages to fetch.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        list: A list of dictionaries containing the request number, page counter, and response content.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    payload = &#123;&#125;</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;_jobboard_session=895b7b35b6493519c3ad686923d8cc1d; __cf_bm=BrUISN3QZXOQ1BPeJXOvNpqBAcT8YXS6XqIr7jlW.4M-1732742386-1.0.1.1-1hk8BgPrEcPEO6ZLFO6W6W6e8MNhcmQswlF6K2dUhchBp0px3reiDJPOuXnzX6z.etyzZq.Q9BIUEYJ1dHZqP75g&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    responses_data = []  <span class="comment"># Initialize an empty list to store response data</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> counter <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, amount_of_pages + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># Construct the URL with the current page counter</span></span><br><span class="line">        url = <span class="string">f&quot;<span class="subst">&#123;base_url&#125;</span>&amp;page=<span class="subst">&#123;counter&#125;</span>&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Fetching data from: <span class="subst">&#123;url&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># Send GET request</span></span><br><span class="line">            response = requests.get(url, headers=headers, data=payload)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Append the response data to the list</span></span><br><span class="line">            responses_data.append(&#123;</span><br><span class="line">                <span class="string">&quot;request_key&quot;</span>: <span class="string">f&quot;request_<span class="subst">&#123;counter&#125;</span>&quot;</span>,</span><br><span class="line">                <span class="string">&quot;counter&quot;</span>: counter,</span><br><span class="line">                <span class="string">&quot;response_content&quot;</span>: response.text</span><br><span class="line">            &#125;)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;counter: <span class="subst">&#123;counter&#125;</span> | &#x27;status_code:&#x27; <span class="subst">&#123;response.status_code&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> requests.RequestException <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Error fetching data for page <span class="subst">&#123;counter&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> responses_data</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Parse data from <code>json</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_job_data_from_json</span>(<span class="params">response_data, output_json_file, output_markdown_file</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Parse job data from a list of responses and extract job listings using BeautifulSoup.</span></span><br><span class="line"><span class="string">    Save results to both a JSON file and a Markdown file.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        response_data (list): List of dictionaries containing the response data.</span></span><br><span class="line"><span class="string">        output_json_file (str): Path to save the parsed job data in JSON format.</span></span><br><span class="line"><span class="string">        output_markdown_file (str): Path to save the parsed job data in Markdown format.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        job_data = []  <span class="comment"># List to store extracted job data</span></span><br><span class="line">        markdown_content = []  <span class="comment"># List to store Markdown entries</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Loop through each request in the list</span></span><br><span class="line">        <span class="keyword">for</span> request <span class="keyword">in</span> response_data:</span><br><span class="line">            counter = request.get(<span class="string">&quot;counter&quot;</span>, <span class="string">&quot;unknown&quot;</span>)</span><br><span class="line">            response_content = request.get(<span class="string">&quot;response_content&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Parse the HTML content using BeautifulSoup</span></span><br><span class="line">            soup = BeautifulSoup(response_content, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Find all job listings using the locator</span></span><br><span class="line">            job_listings = soup.find_all(<span class="string">&#x27;li&#x27;</span>, class_=<span class="string">&#x27;job-listing&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Extract data from each job listing</span></span><br><span class="line">            <span class="keyword">for</span> job <span class="keyword">in</span> job_listings:</span><br><span class="line">                <span class="comment"># Safely find required elements, fallback to &#x27;N/A&#x27; if not present</span></span><br><span class="line">                job_title = job.find(<span class="string">&#x27;a&#x27;</span>, class_=<span class="string">&#x27;jobList-title zip-backfill-link&#x27;</span>)</span><br><span class="line">                job_description = job.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;jobList-description&#x27;</span>)</span><br><span class="line">                salary = job.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;jobList-salary&#x27;</span>)</span><br><span class="line"></span><br><span class="line">                job_info = &#123;</span><br><span class="line">                    <span class="string">&#x27;title&#x27;</span>: job_title.text.strip() <span class="keyword">if</span> job_title <span class="keyword">else</span> <span class="string">&#x27;N/A&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;href&#x27;</span>: job_title[<span class="string">&#x27;href&#x27;</span>] <span class="keyword">if</span> job_title <span class="keyword">else</span> <span class="string">&#x27;N/A&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;description&#x27;</span>: job_description.text.strip() <span class="keyword">if</span> job_description <span class="keyword">else</span> <span class="string">&#x27;N/A&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;salary&#x27;</span>: salary.text.strip() <span class="keyword">if</span> salary <span class="keyword">else</span> <span class="string">&#x27;N/A&#x27;</span>,</span><br><span class="line">                    <span class="string">&#x27;page&#x27;</span>: counter</span><br><span class="line">                &#125;</span><br><span class="line">                job_data.append(job_info)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Prepare entry for Markdown</span></span><br><span class="line">                markdown_entry = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">### Job Title: <span class="subst">&#123;job_info[<span class="string">&#x27;title&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">- **Link**: [<span class="subst">&#123;job_info[<span class="string">&#x27;title&#x27;</span>]&#125;</span>](<span class="subst">&#123;job_info[<span class="string">&#x27;href&#x27;</span>]&#125;</span>)</span></span><br><span class="line"><span class="string">- **Description**: <span class="subst">&#123;job_info[<span class="string">&#x27;description&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">- **Salary**: <span class="subst">&#123;job_info[<span class="string">&#x27;salary&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">- **Page**: <span class="subst">&#123;job_info[<span class="string">&#x27;page&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">                markdown_content.append(markdown_entry.strip())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save extracted job data to a new JSON file</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(output_json_file, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            json.dump(job_data, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Job data successfully parsed and saved to <span class="subst">&#123;output_json_file&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save Markdown content to a file</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(output_markdown_file, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&quot;\n\n&quot;</span>.join(markdown_content))</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Job data successfully saved to <span class="subst">&#123;output_markdown_file&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error processing file: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>IMPORTANT !</strong></p><ul><li>Provide valid references for saving retrieved data.</li><li>Make sure that you copied valid url from the browser and manage pagination properly.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    base_url = <span class="string">&quot;https://www.ziprecruiter.co.uk/jobs/search?l=Remote&amp;q=qa+software+engineer&amp;remote=full&quot;</span></span><br><span class="line">    amount_of_pages = <span class="number">100</span>  <span class="comment"># Or any number that you wish to check</span></span><br><span class="line">    responses_data = execute_requests(base_url, amount_of_pages)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Output files for parsed data</span></span><br><span class="line">    output_json_file = <span class="string">&#x27;parsed_job_data.json&#x27;</span></span><br><span class="line">    output_markdown_file = <span class="string">&#x27;parsed_job_data.md&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Parse and save the job data</span></span><br><span class="line">    parse_job_data_from_json(responses_data, output_json_file, output_markdown_file)</span><br></pre></td></tr></table></figure><p>Script works fine for several executions. After that cookies expired and new one should be regenerated.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;strong&gt;Given&lt;/strong&gt; The website wit</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="data_mining" scheme="https://ooge0.github.io/hexo-blog/tags/data-mining/"/>
    
    <category term="parsing" scheme="https://ooge0.github.io/hexo-blog/tags/parsing/"/>
    
    <category term="python" scheme="https://ooge0.github.io/hexo-blog/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>VADER - intro</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/26/post_ai__vader_intro/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/26/post_ai__vader_intro/</id>
    <published>2024-11-26T19:37:30.000Z</published>
    <updated>2024-11-26T20:01:47.805Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="VADER"><a href="#VADER" class="headerlink" title="VADER"></a>VADER</h2><p>VADER (Valence Aware Dictionary and sEntiment Reasoner) is a widely used sentiment analysis tool tailored for understanding emotions in text, especially in social media contexts. Developed by C.J. Hutto and Eric Gilbert, it combines lexicon-based methods with grammatical and syntactical rules, offering precise sentiment analysis. VADER excels at capturing sentiment intensity, polarity (positive, negative, neutral), and even nuances like sarcasm, thanks to empirically validated linguistic rules and datasets.</p><p>Originally presented at the Eighth International Conference on Weblogs and Social Media in 2014, VADER was designed for scalability and ease of use. Its open-source implementation in Python is accessible for various applications, from marketing analysis to social media monitoring. The tool incorporates features like emoticons, slang, and acronyms, making it uniquely adept at analyzing informal text. Users can install it via Python’s pip command, and the source code is freely available under the MIT License.</p><p>The tool has been validated rigorously with human raters to ensure accuracy. Datasets like tweets, movie reviews, and editorial snippets were used for its development, enabling a robust understanding of diverse text formats.</p><p>For official details, you can visit VADER’s documentation: <a href="https://vadersentiment.readthedocs.io/en/latest/">VADER Sentiment</a>.</p><h3 id="Releated-resources"><a href="#Releated-resources" class="headerlink" title="Releated resources"></a>Releated resources</h3><ul><li>Medium post : <a href="https://towardsdatascience.com/an-short-introduction-to-vader-3f3860208d53">A Short Introduction to VADER</a></li><li>Paper: VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text. 2014<ul><li>DOI: 10.1609&#x2F;icwsm.v8i1.14550</li><li><a href="https://ojs.aaai.org/index.php/ICWSM/article/view/14550">Read on ojs.aaai.org</a></li></ul></li><li>Article: <a href="https://hex.tech/templates/sentiment-analysis/vader-sentiment-analysis/">VADER sentiment analysis</a></li><li>NLTK module: <a href="https://www.nltk.org/api/nltk.sentiment.vader.html#module-nltk.sentiment.vader">nltk.sentiment.vader module</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;VADER&quot;&gt;&lt;a href=&quot;#VADER&quot; class=&quot;he</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="VADER" scheme="https://ooge0.github.io/hexo-blog/tags/VADER/"/>
    
    <category term="sentiment_analysis" scheme="https://ooge0.github.io/hexo-blog/tags/sentiment-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Evolution of Text Augmentation in NLP</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/25/post_ai_nlp__evolution_of_text_augmentation_in_nlp/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/25/post_ai_nlp__evolution_of_text_augmentation_in_nlp/</id>
    <published>2024-11-24T23:03:11.000Z</published>
    <updated>2024-11-25T10:28:07.976Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Text augmentation has evolved alongside advancements in natural language processing (NLP), enabling robust data generation and model improvement. Below is a detailed history, including its origins, foundational works, and key developments.</p><h2 id="Origins-of-Development-Pre-Digital-Era-1940s–1960s"><a href="#Origins-of-Development-Pre-Digital-Era-1940s–1960s" class="headerlink" title="Origins of Development: Pre-Digital Era (1940s–1960s)"></a>Origins of Development: Pre-Digital Era (1940s–1960s)</h2><p><strong>Discovery</strong>: The foundations of text augmentation trace back to linguistic research and early computational experiments. Theoretical frameworks like <strong>Noam Chomsky’s generative grammar</strong> established the principles of sentence structure and transformation.</p><p><strong>Significance</strong>: These linguistic theories formed the basis for later computational methods for generating diverse text variations.</p><ul><li><p><strong>Book</strong>:</p><ul><li>Syntactic Structures. Noam Chomsky. 1957.<ul><li><a href="https://mitpress.mit.edu/">Read on MIT Press</a></li></ul></li><li>Syntactic Structures. Noam Chomsky. 2nd edition. 2022 (with introduction by David Lightfoot)<ul><li><a href="https://tallinzen.net/media/readings/chomsky_syntactic_structures.pdf">Read on tallinzen.net</a></li></ul></li></ul></li><li><p><strong>Papers</strong>:</p><ul><li>A Mathematical Theory of Communication. Shannon, C. E. (1948). Bell System Technical Journal, 27(3), 379–423.<ul><li>DOI: 10.1002&#x2F;j.1538-7305.1948.tb01338.x </li><li><a href="https://sci-hub.se/https://doi.org/10.1002/j.1538-7305.1948.tb01338.x">Read on sci-hub.se</a></li></ul></li><li>Three models for the description of language. Chomsky, N. (1956). IEEE Transactions on Information Theory, 2(3), 113–124.<ul><li>DOI: 10.1109&#x2F;TIT.1956.1056813</li><li><a href="https://sci-hub.se/10.1109/TIT.1956.1056813">Read on sci-hub.se</a></li></ul></li><li>Syntactic Structures. Language, Lees, R. B., &amp; Chomsky, N. (1957). 33(3), 375. <ul><li>DOI:10.2307&#x2F;411160 </li><li><a href="https://sci-hub.se/https://doi.org/10.2307/411160">Read on sci-hub.se</a></li></ul></li></ul></li></ul><hr><h2 id="Early-Rule-Based-Methods-1960s–1980s"><a href="#Early-Rule-Based-Methods-1960s–1980s" class="headerlink" title="Early Rule-Based Methods (1960s–1980s)"></a>Early Rule-Based Methods (1960s–1980s)</h2><p><strong>Discovery</strong>: Rule-based systems emerged as the first computational attempt to augment text. By encoding syntactic and semantic rules, these methods allowed for manual text transformations, such as synonym replacement and sentence restructuring.</p><p><strong>Significance</strong>: These approaches demonstrated how structured transformations could enrich NLP tasks like translation and summarization.</p><ul><li><strong>Paper</strong>:<ul><li>Computational Semantics for Natural Language Processing. Yorick Wilks. 1972.</li><li>DOI: 10.1145&#x2F;1234567</li><li><a href="https://dl.acm.org/doi/10.1145/1234567">Read on ACM</a></li></ul></li></ul><hr><h2 id="Emergence-of-Statistical-Methods-1990s"><a href="#Emergence-of-Statistical-Methods-1990s" class="headerlink" title="Emergence of Statistical Methods (1990s)"></a>Emergence of Statistical Methods (1990s)</h2><p><strong>Discovery</strong>: Statistical NLP introduced probabilistic models such as n-grams and Hidden Markov Models (HMMs), enabling dynamic text generation. Techniques like paraphrase generation through probabilistic alignment gained traction.</p><p><strong>Significance</strong>: The shift to statistical methods increased scalability and adaptability, marking a transition from deterministic rules to data-driven approaches.</p><ul><li><p><strong>Paper</strong>:</p><ul><li>A Statistical Approach to Machine Translation. Brown et al. 1990.<ul><li>DOI: 10.1162&#x2F;089120100750105975</li><li><a href="https://aclanthology.org/J90-2002.pdf">Read on aclanthology.org</a></li></ul></li></ul></li><li><p><strong>Fundamental Work</strong>:</p><ul><li>Foundations of Statistical Natural Language Processing. Manning &amp; Schütze. 1999.<ul><li>DOI: N&#x2F;A</li><li><a href="https://web.stanford.edu/~jurafsky/fsnlp/">Read on web.stanford.edu</a></li></ul></li></ul></li></ul><hr><h2 id="Word-Embeddings-and-Neural-Networks-2000s–2010s"><a href="#Word-Embeddings-and-Neural-Networks-2000s–2010s" class="headerlink" title="Word Embeddings and Neural Networks (2000s–2010s)"></a>Word Embeddings and Neural Networks (2000s–2010s)</h2><p><strong>Discovery</strong>: Embedding-based models like Word2Vec and GloVe enabled semantic-aware text augmentation, where words with similar meanings were mapped closer in vector space. Neural networks introduced deeper, context-aware text manipulation.</p><p><strong>Significance</strong>: Word embeddings made synonym substitution and paraphrasing more semantically relevant, while neural networks added contextual depth.</p><ul><li><strong>Paper</strong>:<ul><li>Distributed Representations of Words and Phrases and Their Compositionality. Mikolov et al. 2013.<ul><li>DOI: 10.1162&#x2F;153244303322533223</li><li><a href="https://arxiv.org/pdf/1310.4546">Read on arXiv</a></li></ul></li></ul></li></ul><hr><h2 id="Transformer-Revolution-2017–Present"><a href="#Transformer-Revolution-2017–Present" class="headerlink" title="Transformer Revolution (2017–Present)"></a>Transformer Revolution (2017–Present)</h2><p><strong>Discovery</strong>: Transformers like BERT, GPT, and T5 redefined NLP, introducing powerful models for context-aware text augmentation. Techniques such as masked language modeling and text-to-text generation became mainstream.</p><p><strong>Significance</strong>: The transformer architecture allowed for high-quality, large-scale text augmentation, driving state-of-the-art performance in multiple NLP tasks.</p><ul><li><p><strong>Paper</strong>:</p><ul><li>Attention Is All You Need. Vaswani et al. 2017.<ul><li>DOI: 10.48550&#x2F;arXiv.1706.03762</li><li><a href="https://arxiv.org/pdf/1706.03762">Read on arXiv</a></li></ul></li></ul></li><li><p><strong>Paper</strong>:</p><ul><li>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Devlin et al. 2018.<ul><li>DOI: 10.48550&#x2F;arXiv.1810.04805</li><li><a href="https://arxiv.org/pdf/1810.04805">Read on arXiv</a></li></ul></li></ul></li></ul><hr><h2 id="Modern-NLP-Data-Augmentation-Libraries-2020s"><a href="#Modern-NLP-Data-Augmentation-Libraries-2020s" class="headerlink" title="Modern NLP Data Augmentation Libraries (2020s)"></a>Modern NLP Data Augmentation Libraries (2020s)</h2><p><strong>Discovery</strong>: The development of augmentation libraries such as <strong>nlpaug</strong>, <strong>TextAttack</strong>, and <strong>EDA (Easy Data Augmentation)</strong> simplified access to advanced techniques like back-translation, synonym replacement, and adversarial generation.</p><p><strong>Significance</strong>: These tools democratized text augmentation, making sophisticated methods accessible for both research and industry.</p><ul><li><p><strong>Paper</strong>:</p><ul><li>TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Model Training. Morris et al. 2020.<ul><li>DOI: 10.48550&#x2F;arXiv.2005.05909</li><li><a href="https://arxiv.org/pdf/2005.05909">Read on arXiv</a></li></ul></li></ul></li><li><p><strong>Paper</strong>:</p><ul><li>EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks. Wei &amp; Zou. 2019.<ul><li>DOI: 10.48550&#x2F;arXiv.1901.11196</li><li><a href="https://arxiv.org/pdf/1901.11196">Read on arXiv</a></li></ul></li></ul></li></ul><hr><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Text augmentation has evolved from manual rules to cutting-edge neural models and accessible libraries. These advancements have significantly enriched NLP applications, highlighting the importance of augmentation in the field’s historical and future trajectory.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Text augmentation has evolved alongsid</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="NLP" scheme="https://ooge0.github.io/hexo-blog/tags/NLP/"/>
    
    <category term="lexic" scheme="https://ooge0.github.io/hexo-blog/tags/lexic/"/>
    
  </entry>
  
  <entry>
    <title>NLP lexical resources</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/25/post_ai_nlp__nlp_lexical_resources/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/25/post_ai_nlp__nlp_lexical_resources/</id>
    <published>2024-11-24T23:03:11.000Z</published>
    <updated>2024-11-24T23:15:07.116Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="WordNet"><a href="#WordNet" class="headerlink" title="WordNet"></a>WordNet</h2><p>Resource: <a href="https://wordnet.princeton.edu/">https://wordnet.princeton.edu/</a><br>WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations. The resulting network of meaningfully related words and concepts can be navigated with the browser(Link is external). WordNet is also freely and publicly available for <a href="https://wordnet.princeton.edu/node/5">download</a>. WordNet’s structure makes it a useful tool for computational linguistics and natural language processing.</p><h2 id="Glitch-Text-Generator"><a href="#Glitch-Text-Generator" class="headerlink" title="Glitch Text Generator"></a>Glitch Text Generator</h2><p>Resource: <a href="https://glyphy.io/font-generator/glitch-text">https://glyphy.io/font-generator/glitch-text</a><br>Use our glitch text generator to design creepy text for your social media accounts. Copy and paste these cursed fonts to add some weirdness to your profiles!</p><h2 id="Corrupted-Text-Python-Library"><a href="#Corrupted-Text-Python-Library" class="headerlink" title="Corrupted-Text Python Library"></a>Corrupted-Text Python Library</h2><p>A python library to generate out-of-distribution text datasets. Specifically, the library applies model-independent, commonplace corruptions (not model-specific, worst-case adversarial corruptions). We thus aim to allow benchmark-studies regarding robustness against realistic outliers.<br><a href="https://pypi.org/project/corrupted-text/">PIP</a><br><code>pip install corrupted-text</code><br><a href="https://www.geeksforgeeks.org/text-augmentation-using-corrupted-text-python-library/">Article: Text Augmentation Using Corrupted-Text Python Library</a></p><h2 id="TensorFlow-Data-Augmentation-API"><a href="#TensorFlow-Data-Augmentation-API" class="headerlink" title="TensorFlow Data Augmentation API"></a>TensorFlow Data Augmentation API</h2><p><a href="https://www.tensorflow.org/tutorials/text">Guide: Text and natural language processing with TensorFlow</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;WordNet&quot;&gt;&lt;a href=&quot;#WordNet&quot; class</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="NLP" scheme="https://ooge0.github.io/hexo-blog/tags/NLP/"/>
    
    <category term="lexic" scheme="https://ooge0.github.io/hexo-blog/tags/lexic/"/>
    
  </entry>
  
  <entry>
    <title>Sentiment analysis framework</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/25/post_ai_nlp__sentiment_analysis_framework/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/25/post_ai_nlp__sentiment_analysis_framework/</id>
    <published>2024-11-24T23:03:11.000Z</published>
    <updated>2024-11-27T23:26:07.554Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="INTRO"><a href="#INTRO" class="headerlink" title="INTRO"></a>INTRO</h2><ul><li>Here is a draft structure of  Python-based project with an OOP design. </li><li>It focuses on sentiment analysis for text files stored in a nested directory. </li><li>The design incorporates multiple sentiment analysis frameworks and flexible configurations for each, while storing results in a JSON file.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABC, abstractmethod</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConfigManager</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Responsible for loading and managing configuration files for different sentiment analysis frameworks.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config_dir: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.config_dir = config_dir</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_config</span>(<span class="params">self, framework_name: <span class="built_in">str</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Loads configuration for the specified framework.</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        :param framework_name: Name of the sentiment analysis framework.</span></span><br><span class="line"><span class="string">        :return: Dictionary with configuration parameters.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Placeholder for loading configuration logic</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TextFileProcessor</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Handles discovery and reading of text files from the nested directory.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, base_dir: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.base_dir = base_dir</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_text_files</span>(<span class="params">self</span>) -&gt; <span class="built_in">list</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Recursively fetches all text files in the nested directory.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: List of file paths.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Placeholder for file discovery logic</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_file</span>(<span class="params">self, file_path: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Reads the content of a text file.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param file_path: Path to the text file.</span></span><br><span class="line"><span class="string">        :return: File content as a string.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Placeholder for file reading logic</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SentimentAnalyzer</span>(<span class="title class_ inherited__">ABC</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Abstract base class for all sentiment analysis frameworks.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config: <span class="built_in">dict</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.config = config</span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">analyze</span>(<span class="params">self, text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Analyzes the sentiment of the provided text.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param text: Input text for sentiment analysis.</span></span><br><span class="line"><span class="string">        :return: Dictionary containing analysis metrics.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FrameworkAAnalyzer</span>(<span class="title class_ inherited__">SentimentAnalyzer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implements sentiment analysis using Framework A.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">analyze</span>(<span class="params">self, text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Uses Framework A to analyze sentiment.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param text: Input text for sentiment analysis.</span></span><br><span class="line"><span class="string">        :return: Dictionary with metrics from Framework A.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Placeholder for sentiment analysis logic</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FrameworkBAnalyzer</span>(<span class="title class_ inherited__">SentimentAnalyzer</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Implements sentiment analysis using Framework B.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">analyze</span>(<span class="params">self, text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Uses Framework B to analyze sentiment.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param text: Input text for sentiment analysis.</span></span><br><span class="line"><span class="string">        :return: Dictionary with metrics from Framework B.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Placeholder for sentiment analysis logic</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AnalysisManager</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Coordinates the sentiment analysis process.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, config_manager: ConfigManager, text_processor: TextFileProcessor</span>):</span><br><span class="line">        <span class="variable language_">self</span>.config_manager = config_manager</span><br><span class="line">        <span class="variable language_">self</span>.text_processor = text_processor</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">analyze_files</span>(<span class="params">self, frameworks: <span class="built_in">list</span></span>) -&gt; <span class="built_in">list</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Analyzes all text files using specified frameworks.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param frameworks: List of framework analyzer instances.</span></span><br><span class="line"><span class="string">        :return: List of results containing file names and analysis metrics.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        results = []</span><br><span class="line">        text_files = <span class="variable language_">self</span>.text_processor.get_text_files()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> file_path <span class="keyword">in</span> text_files:</span><br><span class="line">            content = <span class="variable language_">self</span>.text_processor.read_file(file_path)</span><br><span class="line">            metrics = []</span><br><span class="line">            <span class="keyword">for</span> framework <span class="keyword">in</span> frameworks:</span><br><span class="line">                metrics.append(framework.analyze(content))</span><br><span class="line"></span><br><span class="line">            results.append(&#123;</span><br><span class="line">                <span class="string">&quot;file_name&quot;</span>: os.path.basename(file_path),</span><br><span class="line">                <span class="string">&quot;description&quot;</span>: <span class="string">&quot;Sentiment analysis results&quot;</span>,</span><br><span class="line">                <span class="string">&quot;metrics&quot;</span>: metrics</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResultSaver</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Saves the analysis results to a JSON file.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_to_json</span>(<span class="params">self, results: <span class="built_in">list</span>, output_file: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Writes results to a JSON file.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param results: List of analysis results.</span></span><br><span class="line"><span class="string">        :param output_file: Path to the output JSON file.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Placeholder for JSON writing logic</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Main</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Entry point for the sentiment analysis project.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, base_dir: <span class="built_in">str</span>, config_dir: <span class="built_in">str</span>, output_file: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.base_dir = base_dir</span><br><span class="line">        <span class="variable language_">self</span>.config_dir = config_dir</span><br><span class="line">        <span class="variable language_">self</span>.output_file = output_file</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Executes the sentiment analysis pipeline.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Initialize components</span></span><br><span class="line">        config_manager = ConfigManager(<span class="variable language_">self</span>.config_dir)</span><br><span class="line">        text_processor = TextFileProcessor(<span class="variable language_">self</span>.base_dir)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load configurations and instantiate frameworks</span></span><br><span class="line">        frameworks = [</span><br><span class="line">            FrameworkAAnalyzer(config_manager.load_config(<span class="string">&quot;FrameworkA&quot;</span>)),</span><br><span class="line">            FrameworkBAnalyzer(config_manager.load_config(<span class="string">&quot;FrameworkB&quot;</span>))</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Perform analysis</span></span><br><span class="line">        analysis_manager = AnalysisManager(config_manager, text_processor)</span><br><span class="line">        results = analysis_manager.analyze_files(frameworks)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save results</span></span><br><span class="line">        saver = ResultSaver()</span><br><span class="line">        saver.save_to_json(results, <span class="variable language_">self</span>.output_file)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>All implementations and improvements will be presented in separate posts.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;INTRO&quot;&gt;&lt;a href=&quot;#INTRO&quot; class=&quot;he</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="NLP" scheme="https://ooge0.github.io/hexo-blog/tags/NLP/"/>
    
    <category term="sentiment_analysis" scheme="https://ooge0.github.io/hexo-blog/tags/sentiment-analysis/"/>
    
  </entry>
  
  <entry>
    <title>Types of sentiment analysis techniques in NLP</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_nlp__types_of_sentiment_analysis_techniques_in_nlp/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_nlp__types_of_sentiment_analysis_techniques_in_nlp/</id>
    <published>2024-11-21T18:01:11.000Z</published>
    <updated>2024-11-26T20:11:53.601Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><em>related to : <a href="/hexo-blog/ai_ml__llm_system_prompts/">LLM system prompts</a></em></p><p><strong>Types of Sentiment Analysis Techniques for NLP (with DOI Papers)</strong><br><em>This post summarizes various sentiment analysis techniques, from lexicon-based methods to advanced deep learning approaches, along with DOI references to explore these concepts further.</em></p><hr><h2 id="1-Lexicon-Based-Sentiment-Analysis"><a href="#1-Lexicon-Based-Sentiment-Analysis" class="headerlink" title="1. Lexicon-Based Sentiment Analysis"></a><strong>1. Lexicon-Based Sentiment Analysis</strong></h2><ul><li><strong>Description</strong>: Relies on predefined sentiment lexicons (dictionaries of positive, negative, and neutral words). Sentiment scores are calculated based on the presence and frequency of words.</li><li><strong>Applications</strong>: Basic polarity detection, customer feedback analysis.</li><li><strong>Key Paper</strong>:<br>Liu, B. (2012). <strong>Sentiment Analysis and Opinion Mining</strong>. <em>Synthesis Lectures on Human Language Technologies, 5</em>(1), 1–167.<br>DOI: <a href="https://doi.org/10.2200/S00416ED1V01Y201204HLT016">10.2200&#x2F;S00416ED1V01Y201204HLT016</a><br><a href="https://www.cs.uic.edu/~liub/FBS/SentimentAnalysis-and-OpinionMining.pdf">Read on www.cs.uic.edu</a></li></ul><hr><h2 id="2-Rule-Based-Sentiment-Analysis"><a href="#2-Rule-Based-Sentiment-Analysis" class="headerlink" title="2. Rule-Based Sentiment Analysis"></a><strong>2. Rule-Based Sentiment Analysis</strong></h2><ul><li><strong>Description</strong>: Combines sentiment lexicons with linguistic rules (e.g., negation handling, intensifiers). Example: “not good” &#x3D; negative, “very bad” &#x3D; strongly negative.</li><li><strong>Applications</strong>: Sentiment classification for rule-governed domains.</li><li><strong>Key Paper</strong>:<br>Hutto, C., &amp; Gilbert, E. (2014). <strong>VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text</strong>. <em>Proceedings of the Eighth International AAAI Conference on Weblogs and Social Media</em>.<br>DOI: <a href="https://doi.org/10.1609/icwsm.v8i1.14550">10.1609&#x2F;icwsm.v8i1.14550</a><br><a href="https://ojs.aaai.org/index.php/ICWSM/article/view/14550/14399">Read on ojs.aaai.org</a></li></ul><hr><h2 id="3-Machine-Learning-Based-Sentiment-Analysis"><a href="#3-Machine-Learning-Based-Sentiment-Analysis" class="headerlink" title="3. Machine Learning-Based Sentiment Analysis"></a><strong>3. Machine Learning-Based Sentiment Analysis</strong></h2><ul><li><strong>Description</strong>: Uses ML models like Naive Bayes, SVM, or Decision Trees trained on labeled sentiment datasets.</li><li><strong>Applications</strong>: News sentiment analysis, customer reviews, product recommendations.</li><li><strong>Key Paper</strong>:<br>Pang, B., &amp; Lee, L. (2002). <strong>Thumbs Up? Sentiment Classification Using Machine Learning Techniques</strong>. <em>Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 10, 79–86.<br>DOI: <a href="https://doi.org/10.3115/1118693.1118704">10.3115&#x2F;1118693.1118704</a><br><a href="https://dl.acm.org/doi/pdf/10.3115/1118693.1118704">Read on dl.acm.org</a></li></ul><hr><h2 id="4-Deep-Learning-Based-Sentiment-Analysis"><a href="#4-Deep-Learning-Based-Sentiment-Analysis" class="headerlink" title="4. Deep Learning-Based Sentiment Analysis"></a><strong>4. Deep Learning-Based Sentiment Analysis</strong></h2><ul><li><strong>Description</strong>: Uses neural networks (CNNs, RNNs, LSTMs, Transformers) to analyze sentiment from raw text.</li><li><strong>Applications</strong>: Social media analysis, multilingual sentiment detection.</li><li><strong>Key Papers</strong>:  <ul><li>Socher, R., et al. (2013). <strong>Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</strong>. <em>Proceedings of EMNLP 2013</em>.<br><a href="https://nlp.stanford.edu/pubs/SocherEtAl_EMNLP2013.pdf">Read on nlp.stanford.edu</a></li><li>Vaswani, A., et al. (2017). <strong>Attention Is All You Need</strong>. <em>Advances in Neural Information Processing Systems (NeurIPS)</em>.<br>DOI: <a href="https://doi.org/10.48550/arXiv.1706.03762">10.48550&#x2F;arXiv.1706.03762</a><br><a href="https://arxiv.org/pdf/1706.03762">Read on arxiv.org</a></li></ul></li></ul><hr><h2 id="5-Aspect-Based-Sentiment-Analysis-ABSA"><a href="#5-Aspect-Based-Sentiment-Analysis-ABSA" class="headerlink" title="5. Aspect-Based Sentiment Analysis (ABSA)"></a><strong>5. Aspect-Based Sentiment Analysis (ABSA)</strong></h2><ul><li><strong>Description</strong>: Focuses on sentiment specific to aspects of a product or service (e.g., food, service in restaurant reviews).</li><li><strong>Applications</strong>: E-commerce reviews, detailed product feedback.</li><li><strong>Key Paper</strong>:<br>Pontiki, M., et al. (2014). <strong>SemEval-2014 Task 4: Aspect-Based Sentiment Analysis</strong>. <em>Proceedings of SemEval 2014</em>.<br>DOI: <a href="https://doi.org/10.3115/v1/S14-2004">10.3115&#x2F;v1&#x2F;S14-2004</a><br><a href="https://aclanthology.org/S14-2004.pdf">Read on aclanthology.org</a></li></ul><hr><h2 id="6-Emotion-Detection"><a href="#6-Emotion-Detection" class="headerlink" title="6. Emotion Detection"></a><strong>6. Emotion Detection</strong></h2><img src="/hexo-blog/images/img__racknitz_-_the_turk_3.jpg" style="width: 80%; max-width: 200px; border: 1px solid #ccc; padding: 11px; border-radius: 8px; float: left; margin-right: 22px" /><ul><li><strong>Description</strong>: Detects specific emotions (e.g., happiness, anger, fear) rather than just positive or negative sentiment.</li><li><strong>Applications</strong>: Crisis management, psychological studies.</li><li><strong>Key Paper</strong>:<br>Mohammad, S. M., &amp; Turney, P. D. (2013). <strong>Crowdsourcing a Word–Emotion Association Lexicon</strong>. <em>Computational Intelligence, 29</em>(3), 436–465.<br>DOI: <a href="https://doi.org/10.1111/j.1467-8640.2012.00460.x">10.1111&#x2F;j.1467-8640.2012.00460.x</a><br><a href="https://sci-hub.se/https://doi.org/10.1111/j.1467-8640.2012.00460.x">Read on sci-hub.se</a></li></ul><br><hr><h2 id="7-Multimodal-Sentiment-Analysis"><a href="#7-Multimodal-Sentiment-Analysis" class="headerlink" title="7. Multimodal Sentiment Analysis"></a><strong>7. Multimodal Sentiment Analysis</strong></h2><ul><li><strong>Description</strong>: Combines multiple data sources (e.g., text, audio, video) for sentiment analysis.</li><li><strong>Applications</strong>: Video sentiment analysis, call center analytics.</li><li><strong>Key Paper</strong>:<br>Zadeh, A., et al. (2017). <strong>Tensor Fusion Network for Multimodal Sentiment Analysis</strong>. <em>Proceedings of EMNLP 2017</em>.<br>DOI: <a href="https://doi.org/10.48550/arXiv.1707.07250">10.48550&#x2F;arXiv.1707.07250</a><br><a href="https://arxiv.org/pdf/1707.07250">Read on arxiv.org</a></li></ul><hr><h2 id="8-Hybrid-Sentiment-Analysis"><a href="#8-Hybrid-Sentiment-Analysis" class="headerlink" title="8. Hybrid Sentiment Analysis"></a><strong>8. Hybrid Sentiment Analysis</strong></h2><ul><li><strong>Description</strong>: Combines lexicon-based, rule-based, and machine learning techniques for robust and accurate sentiment detection.</li><li><strong>Applications</strong>: Industry-specific sentiment analysis.</li><li><strong>Key Paper</strong>:<br>Cambria, E., et al. (2013). <strong>New Avenues in Opinion Mining and Sentiment Analysis</strong>. <em>IEEE Intelligent Systems, 28</em>(2), 15–21.<br>DOI: <a href="https://doi.org/10.1109/MIS.2013.30">10.1109&#x2F;MIS.2013.30</a><br><a href="https://sci-hub.se/10.1109/MIS.2013.30">Read on sci-hub.se</a></li></ul><hr><h2 id="9-Transfer-Learning-for-Sentiment-Analysis"><a href="#9-Transfer-Learning-for-Sentiment-Analysis" class="headerlink" title="9. Transfer Learning for Sentiment Analysis"></a><strong>9. Transfer Learning for Sentiment Analysis</strong></h2><ul><li><strong>Description</strong>: Fine-tunes pre-trained models (e.g., BERT, RoBERTa, GPT) for sentiment classification tasks.</li><li><strong>Applications</strong>: Multilingual sentiment analysis, specialized domains.</li><li><strong>Key Paper</strong>:<br>Devlin, J., et al. (2019). <strong>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</strong>. <em>Proceedings of NAACL 2019</em>.<br>DOI: <a href="https://doi.org/10.48550/arXiv.1810.04805">10.48550&#x2F;arXiv.1810.04805</a><br><a href="https://arxiv.org/pdf/1810.04805">Read on arxiv.org</a></li></ul><hr><h2 id="10-Fine-Grained-Sentiment-Analysis"><a href="#10-Fine-Grained-Sentiment-Analysis" class="headerlink" title="10. Fine-Grained Sentiment Analysis"></a><strong>10. Fine-Grained Sentiment Analysis</strong></h2><ul><li><strong>Description</strong>: Assigns sentiment scores on a fine-grained scale (e.g., star ratings from 1 to 5).</li><li><strong>Applications</strong>: Detailed product reviews, star-rating predictions.</li><li><strong>Key Paper</strong>:<br>Yang, B., et al. (2016). <strong>Hierarchical Attention Networks for Document Classification</strong>. <em>Proceedings of NAACL 2016</em>.<br>DOI: <a href="https://doi.org/10.18653/v1/N16-1174">10.18653&#x2F;v1&#x2F;N16-1174</a></li></ul><hr><h2 id="Other-resources"><a href="#Other-resources" class="headerlink" title="Other resources"></a>Other resources</h2><ol><li><a href="https://www.nice.com/info/top-sentiment-analysis-tools-and-techniques">https://www.nice.com/info/top-sentiment-analysis-tools-and-techniques</a> </li><li>Article: Opinion Mining and Sentiment Analysis. January 2008. Foundations and Trends® in Information Retrieval 2(1–2):1-135<ul><li>DOI:10.1561&#x2F;1500000011</li><li><a href="https://www.cs.cornell.edu/home/llee/omsa/omsa.pdf">Read on cs.cornell.edu</a></li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;em&gt;related to : &lt;a href=&quot;/hexo-blog/a</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="NLP" scheme="https://ooge0.github.io/hexo-blog/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>NLP in pictures</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_nlp__nlp_in_pictures_1/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_nlp__nlp_in_pictures_1/</id>
    <published>2024-11-21T17:21:11.000Z</published>
    <updated>2024-11-21T17:52:01.459Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="NLP-extracting-information-flow"><a href="#NLP-extracting-information-flow" class="headerlink" title="NLP extracting information flow"></a>NLP extracting information flow</h2><h3 id="Desired-logical-processes"><a href="#Desired-logical-processes" class="headerlink" title="Desired (logical processes)"></a>Desired (logical processes)</h3><p>Morphological analysis &gt;&gt; Syntax analysis  &gt;&gt; Semantic analysis  &gt;&gt; Extracting information</p><hr><h3 id="NLP-text-processing-pipeline-imagination-in-some-AI-ML-engineers-heads"><a href="#NLP-text-processing-pipeline-imagination-in-some-AI-ML-engineers-heads" class="headerlink" title="NLP text processing pipeline (imagination in some AI&#x2F;ML engineers heads)"></a>NLP text processing pipeline (imagination in some AI&#x2F;ML engineers heads)</h3><p><img src="/hexo-blog/images/nlp__text_processing_pipeline_ex_1_1.png" alt="NLP text processing pipeline" title="NLP text processing pipeline" style="width: 80%; max-width: 600px; border: 1px solid #ccc; padding: 5px; border-radius: 8px;" /></p></p><p><img src="/hexo-blog/images/nlp__text_processing_pipeline_ex_1.png" alt="NLP text processing pipeline - 2" title="NLP text processing pipeline - 2" style="width: 80%; max-width: 600px; border: 1px solid #ccc; padding: 5px; border-radius: 8px;" /></p></p><hr><h3 id="Megaputer-representation"><a href="#Megaputer-representation" class="headerlink" title="Megaputer representation"></a>Megaputer representation</h3><p>Megaputer </p><ul><li><a href="https://youtu.be/D8nXgHnPcB0">YouTube: Большая языковая модель MegaGPT + лингвистические правила: гибридный подход для анализа текстов</a>   </li><li>Презентация доступна по <a href="https://disk.yandex.ru/i/IVwBA2Oa2vzyCg">ссылке.</a>  </li><li><a href="https://www.megaputer.ru/">Сайт Мегапьютер</a>  </li><li><a href="https://www.megaputer.ru/project-gallery/">Галерея проектов</a>, разработанных в PolyAnalyst<br><img src="/hexo-blog/images/extracting_information_diagram_megaputer.png" alt="Megaputer diagramm-1" title="Megaputer diagramm-1" style="width: 80%; max-width: 600px; border: 1px solid #ccc; padding: 5px; border-radius: 8px;" /></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;NLP-extracting-information-flow&quot;&gt;</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
    <category term="NLP" scheme="https://ooge0.github.io/hexo-blog/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>AI - Machine Learning + emotions</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_ml__emotions/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_ml__emotions/</id>
    <published>2024-11-21T00:08:12.000Z</published>
    <updated>2024-11-21T22:00:11.516Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ol><li><p>Paper: <em>InstructERC: Reforming Emotion Recognition in Conversation with a Multi-task Retrieval-based LLMs Framework</em></p><ul><li>DOI:10.48550&#x2F;arXiv.2406.18088</li><li><a href="https://openreview.net/pdf/2c4c4157e9917665bbf110ffb8a87c3eba3ebed4.pdf">Read on openreview.net</a></li></ul></li><li><p>Paper: <em>InstructERC: Reforming Emotion Recognition in Conversation with Multi-task Retrieval-Augmented Large Language Models, 2024</em></p><ul><li>DOI: 10.48550&#x2F;arXiv.2309.11911</li><li><a href="https://arxiv.org/pdf/2309.11911">Read on arxiv.org</a></li></ul></li></ol><hr><h2 id="Other-resources-papers-books"><a href="#Other-resources-papers-books" class="headerlink" title="Other resources&#x2F;papers&#x2F;books"></a>Other resources&#x2F;papers&#x2F;books</h2><ol><li><p>Book: <em>Zinker J. Creative process in gestalt therapy. Vintage books. Random House, 1978</em></p></li><li><p>Book: <em>The Expressions of the Emotions in Man and Animals. Darwin. 1872</em></p><ul><li><a href="https://darwin-online.org.uk/content/frameset?viewtype=text&itemID=F1142&pageseq=1">Read book on darwin-online.org.uk</a></li><li><a href="https://archive.org/details/expressionofemot1872darw/">✰✰✰✰✰ Read book on archive.org </a></li><li><a href="https://web.seducoahuila.gob.mx/biblioweb/upload/the_expression_of_the_emotions_in_man_and_animals.pdf">✰ Read book on web.seducoahuila.gob.mx</a></li></ul></li><li><p>Paper: PyPlutchik: Visualising and comparing emotion-annotated corpora. 2021.</p><ul><li>DOI:10.1371&#x2F;journal.pone.0256503</li><li><a href="https://www.researchgate.net/publication/354295491_PyPlutchik_Visualising_and_comparing_emotion-annotated_corpora">✰✰✰✰✰ Read on researchgate.net</a><img src="/hexo-blog/images/plutchik_s_wheel_of_emotions.jpg" alt="Plutchik's wheel of emotions" title="Plutchik's wheel of emotions" href = "https://en.wikipedia.org/wiki/Robert_Plutchik#/media/File:Plutchik-wheel.svg" style="width: 20%; max-width: 1000px; border: 1px solid #ccc; padding: 5px; border-radius: 8px;" /></li></ul></li><li><p>Paper: <em>The Feeling Wheel.Willcox,G.(1982).Transactional Analysis Journal, 12(4), 274–276.</em></p><ul><li>DOI:10.1177&#x2F;036215378201200411</li><li><a href="https://sci-hub.se/10.1177/036215378201200411">Read on sc-hub.se</a><img src="/hexo-blog/images/feeling_wheel_willcox_g_1982.jpg" alt="The Feeling Wheel.Willcox,G.(1982).Transactional Analysis Journal, 12(4), 274–276." title="The Feeling Wheel.Willcox,G.(1982).Transactional Analysis Journal, 12(4), 274–276." style="width: 40%; max-width: 1300px; border: 1px solid #ccc; padding: 5px; border-radius: 8px;" /></li></ul> <img src="/hexo-blog/images/feeling_wheel_willcox_g_1982_ru.jpg" alt="The Feeling Wheel.Willcox,G _ru" title="The Feeling Wheel.Willcox,G _ru" style="width: 20%; max-width: 1000px; border: 1px solid #ccc; padding: 5px; border-radius: 8px;" /></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Paper: &lt;em&gt;InstructERC: Refor</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
    <category term="emotions" scheme="https://ooge0.github.io/hexo-blog/tags/emotions/"/>
    
  </entry>
  
  <entry>
    <title>Fine-tuning vs. Feature-based Approaches</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_ml__finetuning_vs_feature_based_approaches/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_ml__finetuning_vs_feature_based_approaches/</id>
    <published>2024-11-21T00:08:12.000Z</published>
    <updated>2024-12-04T09:35:50.869Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Fine-tuning and feature-based approaches are two common techniques in transfer learning, a machine learning method where a pre-trained model is reused as a starting point for a new task.</p><p><strong>Fine-tuning</strong> involves adjusting the weights of a pre-trained model on a new dataset. This method is more computationally intensive but can lead to better performance, especially when the new task is similar to the original task.</p><p><strong>Feature-based</strong> approaches, on the other hand, extract features from a pre-trained model and use them as input for a new model. This method is less computationally intensive and can be effective when the new task is different from the original task.</p><p><strong>Key Differences:</strong></p><table><thead><tr><th>Feature</th><th>Fine-tuning</th><th>Feature-based</th></tr></thead><tbody><tr><td>Model Modification</td><td>Adjusts weights of pre-trained model</td><td>Extracts features, trains new model</td></tr><tr><td>Computational Cost</td><td>Higher</td><td>Lower</td></tr><tr><td>Task Similarity</td><td>Best for similar tasks</td><td>Can be used for diverse tasks</td></tr><tr><td>Data Requirements</td><td>More data needed</td><td>Less data needed</td></tr></tbody></table>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Fine-tuning and feature-based approach</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Prompt Engineering - task_1.</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_promt_engineer_task_1/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/21/post_ai_promt_engineer_task_1/</id>
    <published>2024-11-20T23:56:12.000Z</published>
    <updated>2024-11-25T10:57:32.983Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Prompt Evaluation Guide: Assessing Prompt and Response Quality</strong></p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>In this guide, we will evaluate the quality of prompts and their corresponding responses using a machine learning model. The goal is to determine whether the outputs align with specified criteria, improving the model’s prompt-handling capability through fine-tuning or adjustments. We’ll use <strong>OpenAI’s GPT-based models</strong> as our foundation, showcasing how to configure, evaluate, and visualize results locally. </p><p>This guide includes a step-by-step walkthrough for local deployment, fine-tuning, and performance assessment, complete with visualization of results to understand the quality and impact of changes.</p><hr><h2 id="2-Required-Tools"><a href="#2-Required-Tools" class="headerlink" title="2. Required Tools"></a>2. Required Tools</h2><h3 id="Tools-and-Libraries"><a href="#Tools-and-Libraries" class="headerlink" title="Tools and Libraries"></a>Tools and Libraries</h3><ul><li><strong>Hugging Face Transformers</strong>: For model training and configuration.</li><li><strong>Datasets Library</strong>: To load and preprocess prompt-response datasets.</li><li><strong>PyTorch</strong> or <strong>TensorFlow</strong>: Backend for model execution.</li><li><strong>Matplotlib</strong> and <strong>Seaborn</strong>: For data visualization.</li><li><strong>Python 3.8+</strong>: Required for compatibility with libraries.</li><li><strong>Evaluation Metrics</strong>:<ul><li><a href="../../../../../glossary-of-machine-learning-and-ai-terms#BLEU">BLEU</a> Score</li><li><a href="(../../../../../glossary-of-machine-learning-and-ai-terms#ROUGE-L">ROUGE-L</a></li><li>Perplexity</li></ul></li></ul><h3 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h3><ul><li><strong>Model</strong>: Pretrained GPT-2 or similar transformer-based model. Download from <a href="https://huggingface.co/models">Hugging Face Model Hub</a>.</li><li><strong>Dataset</strong>: Use datasets like <code>squad_v2</code> or create a custom prompt-response dataset.</li><li><strong>Environment</strong>: A local Python environment or virtual environment for isolation.</li></ul><hr><h2 id="3-Installation-Guide"><a href="#3-Installation-Guide" class="headerlink" title="3. Installation Guide"></a>3. Installation Guide</h2><p><strong>Clone the repository for local setup.</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/huggingface/transformers.git</span><br><span class="line"><span class="built_in">cd</span> transformers</span><br></pre></td></tr></table></figure><p><strong>Create virtual environment.</strong><br><em>To create a virtual environment, execute the following commands in the command line:</em></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install virtualenv</span><br></pre></td></tr></table></figure><p><strong>Activate the virtual environment:</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">venv\Scripts\activate</span><br></pre></td></tr></table></figure><p><strong>Create <code>requirements.txt</code> in the project root directory.</strong><br>Add there list of Python libraries as</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">transformers</span><br><span class="line">datasets</span><br><span class="line">torch</span><br><span class="line">matplotlib </span><br><span class="line">seaborn</span><br></pre></td></tr></table></figure><p><strong>Install required Python libraries from <code>requirements.txt</code>:</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure><p>or if you are not using virtual env, execute</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers datasets torch matplotlib seaborn</span><br></pre></td></tr></table></figure><h2 id="4-Configuration-Guide"><a href="#4-Configuration-Guide" class="headerlink" title="4. Configuration Guide"></a>4. Configuration Guide</h2><ol><li>Prepare Configuration File</li><li>Create a config.json with the following parameters:<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;model_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt-2&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;dataset_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;custom_dataset.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;max_length&quot;</span><span class="punctuation">:</span> <span class="number">256</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;batch_size&quot;</span><span class="punctuation">:</span> <span class="number">16</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;learning_rate&quot;</span><span class="punctuation">:</span> <span class="number">5e-5</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;num_epochs&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;evaluation_metrics&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;bleu&quot;</span><span class="punctuation">,</span> <span class="string">&quot;rouge-l&quot;</span><span class="punctuation">,</span> <span class="string">&quot;perplexity&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li>Dataset Preparation<br>Ensure your dataset is in JSONL format:<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;What is AI?&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;response&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Artificial Intelligence is...&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Define Machine Learning&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;response&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Machine Learning is...&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="5-Core-for-Evaluation-Task"><a href="#5-Core-for-Evaluation-Task" class="headerlink" title="5. Core for Evaluation Task"></a>5. Core for Evaluation Task</h2><p>Define the evaluation process:</p><ol><li>Load Dataset: Preprocess prompts and responses.</li><li>Fine-Tune Model: Train on specific tasks to enhance response relevance.</li><li>Evaluate metrics, measure:<ol><li>BLEU, </li><li>ROUGE-L, </li><li>perplexity scores for outputs.</li></ol></li></ol><h2 id="6-Guidelines-for-Prompt-Evaluation"><a href="#6-Guidelines-for-Prompt-Evaluation" class="headerlink" title="6. Guidelines for Prompt Evaluation"></a>6. Guidelines for Prompt Evaluation</h2><p><strong>Key Evaluation Areas:</strong></p><ol><li><strong>Relevance</strong>: Does the response match the expected answer?</li><li><strong>Clarity</strong>: Is the response clear and concise?</li><li><strong>Adaptability</strong>: Does the model adjust to different prompt complexities?</li><li><strong>Consistency</strong>: Are responses uniform in quality across test cases?</li></ol><p><strong>Complexity Consideration:</strong></p><ul><li>Simple prompts: Direct, factual queries.</li><li>Complex prompts: Context-based or multi-turn questions.</li></ul><h2 id="7-Main-Scripts"><a href="#7-Main-Scripts" class="headerlink" title="7. Main Scripts"></a>7. Main Scripts</h2><p><strong>Training Script</strong></p><p>Save as <code>train.py</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load model and tokenizer</span></span><br><span class="line">model_name = <span class="string">&quot;gpt-2&quot;</span></span><br><span class="line">model = GPT2LMHeadModel.from_pretrained(model_name)</span><br><span class="line">tokenizer = GPT2Tokenizer.from_pretrained(model_name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load and preprocess dataset</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;json&quot;</span>, data_files=<span class="string">&quot;custom_dataset.json&quot;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">batch</span>):</span><br><span class="line">    <span class="keyword">return</span> tokenizer(batch[<span class="string">&quot;prompt&quot;</span>], padding=<span class="string">&quot;max_length&quot;</span>, truncation=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">tokenized_data = dataset.<span class="built_in">map</span>(tokenize, batched=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training arguments</span></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./results&quot;</span>,</span><br><span class="line">    evaluation_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">5e-5</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">16</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trainer</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=tokenized_data[<span class="string">&quot;train&quot;</span>]</span><br><span class="line">)</span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure><p><strong>Evaluation Script</strong></p><p>Save as <code>evaluate.py</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load model</span></span><br><span class="line">model_name = <span class="string">&quot;./results&quot;</span></span><br><span class="line">evaluator = pipeline(<span class="string">&quot;text-generation&quot;</span>, model=model_name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate prompts</span></span><br><span class="line">prompts = [<span class="string">&quot;What is AI?&quot;</span>, <span class="string">&quot;Define Machine Learning&quot;</span>]</span><br><span class="line">responses = [evaluator(prompt, max_length=<span class="number">50</span>) <span class="keyword">for</span> prompt <span class="keyword">in</span> prompts]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Metrics</span></span><br><span class="line">metric = load_metric(<span class="string">&quot;bleu&quot;</span>)</span><br><span class="line">metric_score = metric.compute(predictions=responses, references=[<span class="string">&quot;Artificial Intelligence is...&quot;</span>, <span class="string">&quot;Machine Learning is...&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;BLEU Score:&quot;</span>, metric_score)</span><br></pre></td></tr></table></figure><h2 id="8-Visualization-and-Explanation-of-Results"><a href="#8-Visualization-and-Explanation-of-Results" class="headerlink" title="8. Visualization and Explanation of Results"></a>8. Visualization and Explanation of Results</h2><p><strong>Visualization Script</strong></p><p>Save as <code>visualize.py</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example metric scores</span></span><br><span class="line">metrics = &#123;<span class="string">&quot;BLEU&quot;</span>: <span class="number">0.85</span>, <span class="string">&quot;ROUGE-L&quot;</span>: <span class="number">0.87</span>, <span class="string">&quot;Perplexity&quot;</span>: <span class="number">15.2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">5</span>))</span><br><span class="line">sns.barplot(x=<span class="built_in">list</span>(metrics.keys()), y=<span class="built_in">list</span>(metrics.values()))</span><br><span class="line">plt.title(<span class="string">&quot;Evaluation Metrics&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Scores&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Metric&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h2><ol><li>BLEU &amp; ROUGE-L: Higher scores indicate better text generation quality.</li><li>Perplexity: Lower scores indicate improved language model comprehension.</li></ol><hr><p>To improve the model’s performance here is possible to focus on the following activities based on the evaluation metrics and the provided GPT-2 configuration:</p><h3 id="1-Data-Preprocessing-and-Augmentation"><a href="#1-Data-Preprocessing-and-Augmentation" class="headerlink" title="1. Data Preprocessing and Augmentation"></a>1. <strong>Data Preprocessing and Augmentation</strong></h3><ul><li><strong>Data Cleaning</strong>: Ensure the training data is clean, well-structured, and consistent. Remove noisy or irrelevant content that could negatively affect performance.</li><li><strong>Augment Data</strong>: Introduce more varied examples, especially for underrepresented topics. Adding more diverse sentence structures, word choices, and contexts can help improve model robustness.</li></ul><h3 id="2-Prompt-Optimization"><a href="#2-Prompt-Optimization" class="headerlink" title="2. Prompt Optimization"></a>2. <strong>Prompt Optimization</strong></h3><ul><li><strong>Refining Prompts</strong>: Work on crafting more precise and detailed prompts to guide the model towards generating more accurate responses.</li><li><strong>Incorporate Context</strong>: Provide context-rich prompts (e.g., multi-turn conversations) or detailed instructions to ensure the model outputs relevant and coherent responses.</li><li><strong>Temperature and Sampling</strong>: Adjust the <code>do_sample</code> setting and modify <code>top_k</code> or <code>top_p</code> parameters to control the randomness and creativity of the model’s output. A lower temperature (e.g., 0.7) can reduce randomness and produce more deterministic outputs.</li></ul><h3 id="3-Model-Hyperparameters-Adjustment"><a href="#3-Model-Hyperparameters-Adjustment" class="headerlink" title="3. Model Hyperparameters Adjustment"></a>3. <strong>Model Hyperparameters Adjustment</strong></h3><ul><li><strong>Increase Layers or Heads</strong>: If you’re able to fine-tune, consider experimenting with increasing the number of layers or attention heads to help the model learn more complex patterns.</li><li><strong>Experiment with <code>n_inner</code></strong>: Fine-tuning the <code>n_inner</code> parameter (which controls the size of the intermediate layer in the transformer) may yield better results for more complex tasks.</li></ul><h3 id="4-Fine-Tuning-GPT-2"><a href="#4-Fine-Tuning-GPT-2" class="headerlink" title="4. Fine-Tuning GPT-2"></a>4. <strong>Fine-Tuning GPT-2</strong></h3><ul><li><strong>Fine-Tuning with Task-Specific Data</strong>: Fine-tune the model on your specific domain or task using high-quality, labeled datasets. Fine-tuning will allow the model to learn task-specific patterns.</li><li><strong>Transfer Learning</strong>: Use transfer learning techniques by starting with a pre-trained GPT-2 model, and then train it on your task-specific corpus to improve the output quality.</li></ul><h3 id="5-Evaluation-Metric-Specific-Adjustments"><a href="#5-Evaluation-Metric-Specific-Adjustments" class="headerlink" title="5. Evaluation Metric-Specific Adjustments"></a>5. <strong>Evaluation Metric-Specific Adjustments</strong></h3><ul><li><strong>BLEU</strong>: Since BLEU is currently 0.0, which indicates poor overlap with reference texts, consider focusing on improving the lexical similarity by training on text data with high-quality references.</li><li><strong>ROUGE</strong>: Improve the recall and precision for ROUGE scores by providing more informative prompts that encourage the model to capture key content and key phrases.</li><li><strong>METEOR</strong>: Since METEOR considers synonyms and paraphrases, increasing the model’s understanding of semantic equivalence might improve this score. Use data augmentation or adversarial training to enhance this aspect.</li><li><strong>BERTScore</strong>: BERTScore evaluates embeddings, so improving model embeddings can significantly help. You can experiment with fine-tuning GPT-2 using BERT-based models (like <code>bert-base-uncased</code>) for better contextual word representations.</li></ul><h3 id="6-Regularization-Techniques"><a href="#6-Regularization-Techniques" class="headerlink" title="6. Regularization Techniques"></a>6. <strong>Regularization Techniques</strong></h3><ul><li><strong>Dropout Regularization</strong>: Experiment with adjusting <code>attn_pdrop</code>, <code>embd_pdrop</code>, and other dropout parameters to control overfitting and improve generalization.</li><li><strong>Layer Normalization</strong>: Ensure that layer normalization parameters (<code>layer_norm_epsilon</code>) are tuned properly to stabilize learning and avoid vanishing&#x2F;exploding gradients.</li></ul><h3 id="7-Model-Size-and-Parameters"><a href="#7-Model-Size-and-Parameters" class="headerlink" title="7. Model Size and Parameters"></a>7. <strong>Model Size and Parameters</strong></h3><ul><li><strong>Larger Models</strong>: If feasible, switch to larger models (e.g., GPT-2 Medium, GPT-2 Large, or GPT-3) for more capacity and better performance in complex tasks.</li><li><strong>Learning Rate and Optimizer Tuning</strong>: Adjust the learning rate for better convergence. Use learning rate schedulers to optimize training over time and avoid issues like vanishing gradients or poor local minima.</li></ul><h3 id="8-Loss-Function-Adjustments"><a href="#8-Loss-Function-Adjustments" class="headerlink" title="8. Loss Function Adjustments"></a>8. <strong>Loss Function Adjustments</strong></h3><ul><li><strong>Loss Function Tweaks</strong>: Investigate the loss function (cross-entropy in GPT-2) to ensure it’s optimized for your specific task. Sometimes, switching the loss function can help improve performance in tasks like summarization or question-answering.</li></ul><h3 id="9-Sampling-Strategies"><a href="#9-Sampling-Strategies" class="headerlink" title="9. Sampling Strategies"></a>9. <strong>Sampling Strategies</strong></h3><ul><li><strong>Top-k Sampling</strong>: Adjust the <code>top_k</code> parameter during text generation to sample from the top K most likely words. This can prevent repetitive or irrelevant generation.</li><li><strong>Nucleus Sampling</strong>: Adjust the <code>top_p</code> value to sample words from the cumulative probability distribution of the top P words, ensuring more diversity in the outputs.</li></ul><h3 id="10-Model-Evaluation-and-Iteration"><a href="#10-Model-Evaluation-and-Iteration" class="headerlink" title="10. Model Evaluation and Iteration"></a>10. <strong>Model Evaluation and Iteration</strong></h3><ul><li><strong>Cross-validation</strong>: Use cross-validation to evaluate different configurations and fine-tuned models to find the optimal setup.</li><li><strong>Hyperparameter Search</strong>: Perform a hyperparameter search (e.g., grid search, random search) to find the best set of hyperparameters for improving performance metrics.</li></ul><h3 id="Example-Implementation"><a href="#Example-Implementation" class="headerlink" title="Example Implementation:"></a>Example Implementation:</h3><pre><code class="python">from transformers import GPT2LMHeadModel, GPT2Tokenizerimport torch# Load pre-trained model and tokenizermodel = GPT2LMHeadModel.from_pretrained(&#39;gpt2&#39;)tokenizer = GPT2Tokenizer.from_pretrained(&#39;gpt2&#39;)# Refine the prompt to improve resultsprompt = &quot;Describe the importance of artificial intelligence in healthcare.&quot;# Generate text using refined promptinputs = tokenizer(prompt, return_tensors=&quot;pt&quot;)outputs = model.generate(**inputs, max_length=100, do_sample=True, top_p=0.95, top_k=60)# Decode and print the outputgenerated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)print(generated_text)</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;strong&gt;Prompt Evaluation Guide: Asses</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
    <category term="prompt_engineering" scheme="https://ooge0.github.io/hexo-blog/tags/prompt-engineering/"/>
    
  </entry>
  
  <entry>
    <title>Web data handling</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/20/notes/notes_web_data_handling/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/20/notes/notes_web_data_handling/</id>
    <published>2024-11-20T19:38:30.000Z</published>
    <updated>2024-12-03T07:34:55.040Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Get-text-from-DOM-by-specific-locator-via-DevTools"><a href="#Get-text-from-DOM-by-specific-locator-via-DevTools" class="headerlink" title="Get text from DOM by specific locator via DevTools"></a>Get text from DOM by specific locator via DevTools</h2><ol><li><strong>Task</strong>: Retrieve text from DOM for elements that have locator “.gfg-similar-read-item-heading” using devtools<br>Solution:<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Retrieve all elements matching the locator</span></span><br><span class="line"><span class="keyword">const</span> elements = <span class="variable language_">document</span>.<span class="title function_">querySelectorAll</span>(<span class="string">&quot;.gfg-similar-read-item-heading&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Extract text content from each element</span></span><br><span class="line"><span class="keyword">const</span> texts = <span class="title class_">Array</span>.<span class="title function_">from</span>(elements).<span class="title function_">map</span>(<span class="function"><span class="params">element</span> =&gt;</span> element.<span class="property">textContent</span>.<span class="title function_">trim</span>());</span><br><span class="line"></span><br><span class="line"><span class="comment">// Output the text content as an array</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(texts);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Optional: Display the texts in format &#123;order_number&#125;&#123;text&#125;</span></span><br><span class="line">texts.<span class="title function_">forEach</span>(<span class="function">(<span class="params">text, index</span>) =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`<span class="subst">$&#123;index + <span class="number">1</span>&#125;</span>: <span class="subst">$&#123;text&#125;</span>`</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Optional: Display the texts in format &#123;text&#125;</span></span><br><span class="line">texts.<span class="title function_">forEach</span>(<span class="function">(<span class="params">text, index</span>) =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`<span class="subst">$&#123;text&#125;</span>`</span>));</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Get-text-from-DOM-by-specific-loc</summary>
      
    
    
    
    <category term="Notes" scheme="https://ooge0.github.io/hexo-blog/categories/Notes/"/>
    
    
    <category term="web" scheme="https://ooge0.github.io/hexo-blog/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>Windows services and VM usage</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/20/notes/notes_windows_services_and_vm_usage/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/20/notes/notes_windows_services_and_vm_usage/</id>
    <published>2024-11-20T19:38:30.000Z</published>
    <updated>2024-12-03T07:27:09.503Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><ol><li><p><strong>Virtual Machine Setup</strong><br>Steps to create a virtual machine:</p><ol><li>Download a hypervisor:<ol><li>Go to <a href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a> or <a href="https://www.vmware.com/">VMware</a>. Download and install the software on your machine.</li><li>Obtain an OS image:<ol><li>Download the required ISO file for the operating system.</li></ol></li><li>Create the virtual machine:<ol><li>Open VirtualBox&#x2F;VMware app.</li><li>Create a new virtual machine according to requested specification.&#96;&#96;&#96;&#96;</li><li>Configure name, OS type, hardware settings like RAM, CPU, and disk space.</li></ol></li><li>Install the OS<ol><li>Start the virtual machine.</li><li>Follow the installation steps in the OS setup wizard.</li></ol></li><li>Connect to the VM:<ol><li>For Linux VMs: Enable SSH in the VM during installation or after setup.</li><li>Use SSH (on Linux&#x2F;Mac) or tools like PuTTY (on Windows) to connect.</li></ol></li><li>Additional steps:<ol><li>Windows VM Remote Desktop:<ol><li>Enable Remote Desktop in the Windows VM settings. Use the RDP client, configuration described here &gt;&gt; <a href="https://learn.microsoft.com/uk-ua/windows-server/remote/remote-desktop-services/clients/remote-desktop-clients">Remote Desktop clients for Remote Desktop Services and remote PCs</a> on your host machine to connect.</li><li>Connect RDP client to remote machine.</li></ol></li></ol></li></ol></li></ol></li><li><p><strong>Windows Services Management in PowerShell.</strong></p><p>Task: </p><ol><li>Print  list of services</li><li>Run specific service</li><li>Stop specific service</li><li>Restart specific service</li><li>Check status for specific service</li></ol><p> To get list of running services I will use :</p> <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Get-Service</span> | <span class="built_in">Where-Object</span> &#123;<span class="variable">$_</span>.Status <span class="operator">-eq</span> <span class="string">&#x27;Running&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><p> Assuming that I want to run <code>&quot;WSLService&quot;</code></p><p> To start <code>&quot;WSLService&quot;</code> service  I’m using :<br> <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Start-Service</span> <span class="literal">-Name</span> <span class="string">&quot;WSLService&quot;</span></span><br></pre></td></tr></table></figure><br> To stop the service:<br> <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Stop-Service</span> <span class="literal">-Name</span> <span class="string">&quot;WSLService&quot;</span></span><br></pre></td></tr></table></figure></p><p> For restarting service:</p> <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Restart-Service</span> <span class="literal">-Name</span> <span class="string">&quot;WSLService&quot;</span></span><br></pre></td></tr></table></figure><p> For checking the status of monitored service:</p> <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Get-Service</span> <span class="literal">-Name</span> <span class="string">&quot;WSLService&quot;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>SSH connection to the Linux machine</strong> actions are below.</p><p>I added more information in advance because the original task does not contain information about the client machine from which the connection to the Linux machine will be made. There is 3 different cases:</p><ul><li>Case 1: From another Linux client to Linux host</li><li>Case 2: From a Windows client  to Linux host</li><li>Case 3: From macOS client to Linux host</li></ul><p>For Linux&#x2F;Mac: SSH is usually pre-installed but if it’s missing install an SSH client (e.g. on Ubuntu):<br>   <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install openssh-client -y</span><br></pre></td></tr></table></figure><br>After installation, start the service on Linux machine:<br>   <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl start ssh</span><br></pre></td></tr></table></figure><br>If SSH service not started , checked its status on Linux machine:<br>    <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status ssh</span><br></pre></td></tr></table></figure></p><p>Generate SSH keys (on the host machine):</p>  <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh<span class="literal">-keygen</span> <span class="literal">-t</span> rsa <span class="literal">-b</span> <span class="number">2048</span></span><br></pre></td></tr></table></figure><p>  The keys will be stored in ~&#x2F;.ssh&#x2F;id_rsa (private) and ~&#x2F;.ssh&#x2F;id_rsa.pub (public).<br>  Copy the public key to the Linux server:</p>  <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh<span class="literal">-copy-id</span> user@server_ip</span><br></pre></td></tr></table></figure><p>  Or manually append the content of id_rsa.pub to ~&#x2F;.ssh&#x2F;authorized_keys on the server.</p><p>  Connection via SSH for Linux:<br>   <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh user@server_ip</span><br></pre></td></tr></table></figure></p></li><li><p>Optional Configurations:</p><p>Edit the SSH config file (~&#x2F;.ssh&#x2F;config) for aliases:</p>   <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Host server_alias  </span><br><span class="line">   HostName server_ip  </span><br><span class="line">   User username  </span><br><span class="line">   IdentityFile ~/.ssh/id_rsa  </span><br></pre></td></tr></table></figure><p>This will simplify the connection:</p>   <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh server_alias</span><br></pre></td></tr></table></figure></li></ol><p><strong>Case 1</strong>: From another Linux client to Linux host</p><p>  Verify SSH Client on the Local Machine:</p><ul><li>Most Linux distributions come with the ssh client pre-installed. Confirm by running:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -V</span><br></pre></td></tr></table></figure> If it’s not installed, install it: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install openssh-client  </span><br></pre></td></tr></table></figure></li></ul><p>   Replace <code>&lt;username&gt;</code> with the remote machine’s username.</p><p>   Replace <code>&lt;remote_ip&gt;</code> with the target machine’s IP address.</p><ul><li>Use Public Key Authentication (Optional): <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br></pre></td></tr></table></figure></li><li>Copy the public key to the remote machine:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id &lt;username&gt;@&lt;remote_ip&gt;</span><br></pre></td></tr></table></figure></li><li>Now, log in without entering a password:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh &lt;username&gt;@&lt;remote_ip&gt;</span><br></pre></td></tr></table></figure></li></ul><p><strong>Case 2</strong>: From a Windows client  to Linux host</p><ul><li><p>Install an SSH Client:</p><ul><li>Use the built-in OpenSSH client on Windows 10+. Open PowerShell or Command Prompt and check if SSH is installed:  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -V</span><br></pre></td></tr></table></figure><ul><li>For Windows alternatively install <a href="https://www.openssh.com/">OpenSSH</a> client from <a href="https://learn.microsoft.com/en-us/windows/client-management/client-tools/add-remove-hide-features?pivots=windows-11">“Optional Features”</a> or <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">download PuTTY</a>( third-party SSH client).</li></ul></li></ul></li><li><p>Connect Using OpenSSH (Built-in).</p><p>Open PowerShell or Command Prompt and run:  </p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh &lt;username&gt;@&lt;remote_ip&gt;</span><br></pre></td></tr></table></figure></li><li><p>Connect Using PuTTY:</p><ul><li>Download and install PuTTY.</li><li>Open PuTTY and enter the hostname or IP address.</li><li>Set the Port to 22 and click Open.</li><li>Log in with your credentials.</li><li>Enable Key Authentication (Optional):<ul><li>Use <a href="https://www.puttygen.com/">puttygen</a> to generate a private&#x2F;public key pair.</li><li>Copy the public key to the Linux machine’s ~&#x2F;.ssh&#x2F;authorized_keys.</li><li>In PuTTY, configure the private key in Connection &gt; SSH &gt; Auth &gt; Browse Private Key.</li></ul></li></ul></li></ul><p><strong>Case 3</strong>: From macOS client to Linux host </p><ul><li><p>Verify SSH Client:</p><p> macOS includes an SSH client by default. Confirm it by running:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -V</span><br></pre></td></tr></table></figure></li><li><p>Connect to the Linux Machine:</p><p>Open Terminal and run:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh &lt;username&gt;@&lt;remote_ip&gt;</span><br></pre></td></tr></table></figure></li><li><p>Use Public Key Authentication (Optional):</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br></pre></td></tr></table></figure></li><li><p>Copy the public key to the remote machine:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id &lt;username&gt;@&lt;remote_ip&gt;</span><br></pre></td></tr></table></figure></li><li><p>Now, I can log in without entering a password:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh &lt;username&gt;@&lt;remote_ip&gt;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Virtual Machine Setup</summary>
      
    
    
    
    <category term="Notes" scheme="https://ooge0.github.io/hexo-blog/categories/Notes/"/>
    
    
    <category term="Dashdevs" scheme="https://ooge0.github.io/hexo-blog/tags/Dashdevs/"/>
    
  </entry>
  
  <entry>
    <title>Text Classification. Historical overview, tools, and techniques.</title>
    <link href="https://ooge0.github.io/hexo-blog/2024/11/19/post_ai_nlp__text_classification_intro_1/"/>
    <id>https://ooge0.github.io/hexo-blog/2024/11/19/post_ai_nlp__text_classification_intro_1/</id>
    <published>2024-11-19T10:05:30.000Z</published>
    <updated>2024-11-19T10:06:14.446Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Text classification is a fundamental task in Natural Language Processing (NLP) that involves categorizing text into predefined categories. Its applications range from sentiment analysis to spam detection, and news categorization to intent recognition in conversational AI. This document provides a historical overview, a comparative analysis of tools, and details about modern approaches like Word2Vec, FastText, GloVe, and deep learning.</p><ol><li><p>Historical Overview of Text Classification</p><ol><li><strong>Traditional Methods (1950s - 2000s)</strong><ol><li><em>Bag of Words (BoW):</em><ul><li>Represents text as a frequency vector of words.</li><li>Pros: Simple and interpretable.</li><li>Cons: Ignores word order and semantics.</li></ul></li><li><em>TF-IDF (Term Frequency-Inverse Document Frequency):</em><ul><li>Improves BoW by weighting rare words higher.</li><li>Pros: Better at distinguishing important terms.</li><li>Cons: Still ignores context and word relationships.</li></ul></li><li><em>Naive Bayes:</em><ul><li>Commonly used with BoW or TF-IDF for classification.</li><li>Pros: Fast and robust for small datasets.</li><li>Cons: Assumes word independence, which rarely holds.</li></ul></li></ol></li></ol></li><li><p><strong>Emergence of Distributed Representations (2010s)</strong><br>The advent of distributed word representations marked a significant leap, addressing the limitations of sparse representations.</p><ol><li><em>Word2Vec (2013, Mikolov et al.):</em><ul><li>Generates dense vector embeddings using Skip-gram or CBOW.</li><li>Paper: Efficient Estimation of Word Representations in Vector Space<ul><li>DOI: <a href="https://doi.org/10.48550/arXiv.1301.3781">10.48550&#x2F;arXiv.1301.3781</a></li></ul></li><li>Pros: Captures semantic relationships and is computationally efficient.</li><li>Cons: Fixed-size embeddings and lacks out-of-vocabulary word handling.</li></ul></li><li><em>GloVe (2014, Pennington et al.):</em><br> Combines global word co-occurrence statistics with local context to produce embeddings.<ul><li>Paper: GloVe: Global Vectors for Word Representation<ul><li>DOI: <a href="https://aclanthology.org/D14-1162.pdf">10.3115&#x2F;v1&#x2F;D14-1162</a></li></ul></li><li>Pros: Effective at capturing statistical information.</li><li>Cons: Pre-trained on fixed corpora; inflexible for dynamic contexts.</li></ul></li><li><em>FastText (2016, Bojanowski et al.):</em><br>   Extends Word2Vec by representing words as n-grams of characters.</li></ol><ul><li>Paper:Enriching Word Vectors with Subword Information, 2016<ul><li>DOI: <a href="https://arxiv.org/pdf/1607.04606">10.48550&#x2F;arXiv.1607.04606</a></li></ul></li><li>Pros: Handles rare and out-of-vocabulary words better.</li><li>Cons: Increased computational cost compared to Word2Vec.</li></ul></li><li><p><strong>Deep Learning Era (Late 2010s - Present)</strong><br>The rise of neural networks transformed text classification. Key innovations include:</p><ol><li><em>Recurrent Neural Networks (RNNs):</em><br>Captures sequential dependencies but suffers from vanishing gradients.</li><li><em>Convolutional Neural Networks (CNNs):</em><br>Effective for capturing local patterns in text.<ul><li>Paper: An Introduction to Convolutional Neural Networks<ul><li>DOI: <a href="https://arxiv.org/pdf/1511.08458">10.48550&#x2F;arXiv.1511.08458</a></li></ul></li><li>Papper: A review of convolutional neural networks in computer<ul><li>Read the doc &gt;&gt;&gt; <a href="../../../../../docs/other/a_review_of_convolutional_neural_networks_in_computer_vision.pdf">A review of convolutional neural networks in computer</a></li></ul></li></ul></li><li><em>Transformers and Pre-trained Models (2018 - Present):</em><br>Models like:<ul><li>BERT<ul><li>Paper: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, 2018 <ul><li>DOI:<a href="https://doi.org/10.48550/arXiv.1810.04805">10.48550&#x2F;arXiv.1810.04805</a></li></ul></li></ul></li><li>GPT<ul><li>GPT-2<ul><li>Paper: Release Strategies and the Social Impacts of Language Models, 2019 </li><li>DOI:<a href="https://arxiv.org/pdf/1908.09203">10.48550&#x2F;arXiv.1908.09203</a></li></ul></li><li>GPT-3.5<ul><li>Paper: Language Models are Few-Shot Learners, 2020 </li><li>DOI:<a href="https://arxiv.org/pdf/2005.14165">10.48550&#x2F;arXiv.2005.14165</a></li></ul></li><li>GPT-4<ul><li>Paper: GPT-4 Technical Report, 2023 </li><li>DOI:<a href="https://doi.org/10.48550/arXiv.2303.08774">10.48550&#x2F;arXiv.2303.08774</a></li></ul></li></ul></li><li>and T5 revolutionized NLP by leveraging attention mechanisms and transfer learning.<ul><li>Paper: T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, 2019</li><li>DOI:<a href="https://arxiv.org/pdf/1910.10683">10.48550&#x2F;arXiv.1910.10683</a></li></ul></li></ul></li></ol></li></ol><h2 id="Footnotes"><a href="#Footnotes" class="headerlink" title="Footnotes"></a>Footnotes</h2><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">GLUE - The General Language Understanding Evaluation (GLUE) benchmark is a collection of resources for training, evaluating, and analyzing natural language understanding systems.</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">IMDB Dataset - Large Movie Review Dataset for Sentiment Analysis by Stanford.</span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;">CoNLL-2003 - Dataset for Named Entity Recognition and other sequence modeling tasks.</span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;">OntoNotes - Annotated dataset covering various linguistic phenomena.</span><a href="#fnref:4" rev="footnote"> ↩</a></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">5.</span><span style="display: inline-block; vertical-align: top;">WMT - Workshop on Machine Translation datasets for translation tasks.</span><a href="#fnref:5" rev="footnote"> ↩</a></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">6.</span><span style="display: inline-block; vertical-align: top;">OpenSubtitles - Large corpus of subtitles for multilingual tasks.</span><a href="#fnref:6" rev="footnote"> ↩</a></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">7.</span><span style="display: inline-block; vertical-align: top;">CNN/DailyMail - Dataset for abstractive summarization tasks.</span><a href="#fnref:7" rev="footnote"> ↩</a></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">8.</span><span style="display: inline-block; vertical-align: top;">XSum - Dataset for extreme summarization of news articles.</span><a href="#fnref:8" rev="footnote"> ↩</a></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">9.</span><span style="display: inline-block; vertical-align: top;">AG News - News topic classification dataset.</span><a href="#fnref:9" rev="footnote"> ↩</a></li><li id="fn:10"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">10.</span><span style="display: inline-block; vertical-align: top;">Reuters-21578 - Text categorization benchmark dataset.</span><a href="#fnref:10" rev="footnote"> ↩</a></li><li id="fn:11"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">11.</span><span style="display: inline-block; vertical-align: top;">SQuAD - Stanford Question Answering Dataset for reading comprehension tasks.</span><a href="#fnref:11" rev="footnote"> ↩</a></li><li id="fn:12"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">12.</span><span style="display: inline-block; vertical-align: top;">TriviaQA - Dataset containing trivia questions and evidence passages.</span><a href="#fnref:12" rev="footnote"> ↩</a></li><li id="fn:13"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">13.</span><span style="display: inline-block; vertical-align: top;">WikiText - Dataset for language modeling based on Wikipedia articles.</span><a href="#fnref:13" rev="footnote"> ↩</a></li><li id="fn:14"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">14.</span><span style="display: inline-block; vertical-align: top;">Penn Treebank - Corpus for linguistic annotation and modeling.</span><a href="#fnref:14" rev="footnote"> ↩</a></li><li id="fn:15"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">15.</span><span style="display: inline-block; vertical-align: top;">Universal Dependencies - Framework for consistent grammatical annotation across languages.</span><a href="#fnref:15" rev="footnote"> ↩</a></li><li id="fn:16"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">16.</span><span style="display: inline-block; vertical-align: top;">WSJ Corpus - Dataset from Wall Street Journal articles for POS tagging.</span><a href="#fnref:16" rev="footnote"> ↩</a></li><li id="fn:17"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">17.</span><span style="display: inline-block; vertical-align: top;">Coreference resolution (CR) is the task of finding all linguistic expressions (called mentions) in a given text that refer to the same real-world entity.</span><a href="#fnref:17" rev="footnote"> ↩</a></li><li id="fn:18"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">18.</span><span style="display: inline-block; vertical-align: top;">CoNLL-2012 - Shared task on coreference resolution and other NLP challenges.</span><a href="#fnref:18" rev="footnote"> ↩</a></li><li id="fn:19"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">19.</span><span style="display: inline-block; vertical-align: top;">Annotated dataset created to evaluate RoBERTa’s performance on coreference tasks, with a focus on contextual embeddings.</span><a href="#fnref:19" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Text classification is a fundamental t</summary>
      
    
    
    
    <category term="Posts" scheme="https://ooge0.github.io/hexo-blog/categories/Posts/"/>
    
    
    <category term="AI" scheme="https://ooge0.github.io/hexo-blog/tags/AI/"/>
    
    <category term="ML" scheme="https://ooge0.github.io/hexo-blog/tags/ML/"/>
    
    <category term="NLP" scheme="https://ooge0.github.io/hexo-blog/tags/NLP/"/>
    
    <category term="text_classification" scheme="https://ooge0.github.io/hexo-blog/tags/text-classification/"/>
    
  </entry>
  
  <entry>
    <title>Довідник для Лікаря Сімейної Медицини</title>
    <link href="https://ooge0.github.io/hexo-blog/nastusja/"/>
    <id>https://ooge0.github.io/hexo-blog/nastusja/</id>
    <published>2024-11-18T09:28:32.625Z</published>
    <updated>2024-11-18T09:52:44.381Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Цей довідник створений власними силами та за допомогою відкритих джерел для допомоги лікарям сімейної медицини, надаючи ключові ресурси, офіційні українські портали, посилання на довідники, глосарії та інші корисні інструменти.</p><hr><h2 id="Офіційні-Українські-Ресурси"><a href="#Офіційні-Українські-Ресурси" class="headerlink" title="Офіційні Українські Ресурси"></a>Офіційні Українські Ресурси</h2><ol><li><p><strong>Міністерство охорони здоров’я України (МОЗ)</strong>  </p><ul><li>Офіційний сайт: <a href="https://moz.gov.ua/">moz.gov.ua</a>  </li><li>Новини, нормативна база, протоколи лікування.</li></ul></li><li><p><strong>Національна служба здоров’я України (НСЗУ)</strong>  </p><ul><li>Офіційний сайт: <a href="https://nszu.gov.ua/">nszu.gov.ua</a>  </li><li>Інформація про медичні послуги, звіти, та декларації з лікарями.</li></ul></li><li><p><strong>Центр громадського здоров’я МОЗ України</strong>  </p><ul><li>Сайт: <a href="https://phc.org.ua/">phc.org.ua</a>  </li><li>Вакцинація, профілактика хвороб, епідеміологія.</li></ul></li></ol><hr><h2 id="Медичні-Довідники-та-Компедіуми"><a href="#Медичні-Довідники-та-Компедіуми" class="headerlink" title="Медичні Довідники та Компедіуми"></a>Медичні Довідники та Компедіуми</h2><ol><li><p><strong>Компендіум Лікарських Засобів</strong>  </p><ul><li>Сайт: <a href="https://compendium.com.ua/">compendium.com.ua</a>  </li><li>Інформація про ліки, інструкції, дозування.</li></ul></li><li><p><strong>Реєстр Ліків України</strong>  </p><ul><li>Сайт: <a href="https://www.drlz.com.ua/">drlz.com.ua</a>  </li><li>Офіційний перелік зареєстрованих ліків.</li></ul></li><li><p><strong>Клінічні протоколи лікування</strong>  </p><ul><li>МОЗ регулярно оновлює протоколи: <a href="https://guidelines.moz.gov.ua/">Протоколи МОЗ</a>.</li></ul></li></ol><hr><h2 id="Глосарії-та-Довідкові-Матеріали"><a href="#Глосарії-та-Довідкові-Матеріали" class="headerlink" title="Глосарії та Довідкові Матеріали"></a>Глосарії та Довідкові Матеріали</h2><ol><li><p><strong>Медичний Глосарій</strong>  </p><ul><li>Глосарій МОЗ: <a href="https://moz.gov.ua/uk/glosarij">moz.gov.ua</a>.</li><li>МОЗ Про затвердження Єдиного термінологічного словника (Глосарій) з питань управління  якості медичної допомоги: <a href="https://zakon.rada.gov.ua/rada/show/v0427282-11#Text">zakon.rada.gov.ua</a></li></ul></li><li><p><strong>Довідники для лікарів первинної ланки</strong>  </p><ul><li>Рекомендації для первинної допомоги: <a href="https://phc.org.ua/">phc.org.ua</a>.</li><li>Кишеньковий довідник лікаря первинної медичної допомоги для роботи з дітьми та підлітками: настанови щодо зміцнення здоров’я, профілактики та лікування захворювань від народження до підліткового віку: <a href="https://www.who.int/ukraine/uk/publications/9789289057622">who.int</a></li><li>Що входить до обов’язків лікаря первинної ланки?: <a href="https://moz.gov.ua/uk/scho-vhodit-do-obovjazkiv-likarja-pervinnoi-lanki">moz.gov.ua</a></li></ul></li></ol><hr><h2 id="Лабораторії-та-Діагностика"><a href="#Лабораторії-та-Діагностика" class="headerlink" title="Лабораторії та Діагностика"></a>Лабораторії та Діагностика</h2><ol><li><p><strong>Сінево Україна</strong>  </p><ul><li><a href="https://www.synevo.ua/">synevo.ua</a></li></ul></li><li><p><strong>Діла Лабораторія</strong>  </p><ul><li><a href="https://dila.ua/">dila.ua</a></li></ul></li><li><p><strong>Меділаб</strong>  </p><ul><li><a href="https://www.medilab.com.ua/">medilab.com.ua</a></li></ul></li></ol><hr><h2 id="Глобальні-Медичні-Ресурси"><a href="#Глобальні-Медичні-Ресурси" class="headerlink" title="Глобальні Медичні Ресурси"></a>Глобальні Медичні Ресурси</h2><ol><li><p><strong>Всесвітня організація охорони здоров’я (ВООЗ)</strong>  </p><ul><li>Сайт: <a href="https://www.who.int/">who.int</a>  </li><li>Міжнародні рекомендації та дослідження.</li></ul></li><li><p><strong>Медична Бібліотека США (PubMed)</strong>  </p><ul><li>Сайт: <a href="https://pubmed.ncbi.nlm.nih.gov/">pubmed.ncbi.nlm.nih.gov</a>  </li><li>Наукові статті з медицини.</li></ul></li><li><p><strong>CDC (Центри контролю та профілактики захворювань, США)</strong>  </p><ul><li>Сайт: <a href="https://www.cdc.gov/">cdc.gov</a>  </li><li>Профілактика, контроль хвороб.</li></ul></li></ol><hr><h2 id="Корисні-Інструменти"><a href="#Корисні-Інструменти" class="headerlink" title="Корисні Інструменти"></a>Корисні Інструменти</h2><ul><li><p><strong>Клінічні калькулятори</strong>: <a href="https://www.msdmanuals.com/uk/professional/pages-with-widgets/clinical-calculators?mode=list">msdmanuals.com</a>  </p></li><li><p><strong>Медичні калькулятори</strong>: <a href="https://medcalc.com.ua/">medcalc.com.ua</a>  </p></li><li><p><strong>Калькулятор маси тіла</strong>: <a href="https://cardioprostir.com.ua/applications-and-calculators/calculators/imt">cardioprostir.com.ua</a>  </p></li><li><p><strong>Калькулятор Калькулятор оцінки прихильності пацієнта</strong>: <a href="https://cardioprostir.com.ua/applications-and-calculators/calculators/goodwill">cardioprostir.com.ua</a>  </p></li><li><p><strong>Розрахунок дозувань</strong>: <a href="https://clincalc.com/">clincalc.com</a>  </p></li><li><p><strong>Медичний калькулятор: Дозування таблеток в залежності від маси тіла</strong>: <a href="https://testresult.org/ua/medical-calc/dozuvannia-tabletok-za-vahoiu">testresult.org</a>  </p></li><li><p><strong>Перевірка взаємодії препаратів</strong> Після переходу на сайт для перекладу натисніть правою кнопкою миші та оберіть “Перекласти”: <a href="https://reference.medscape.com/drug-interactionchecker">cardioprostir.com.ua</a></p></li></ul><hr><h2 id="Завантаження-та-Контакти"><a href="#Завантаження-та-Контакти" class="headerlink" title="Завантаження та Контакти"></a>Завантаження та Контакти</h2><p>Зберігайте цей список для швидкого доступу до корисних ресурсів! Якщо у вас є запитання чи пропозиції, будь ласка, зв’яжіться з автором через офіційні канали МОЗ або НСЗУ.</p><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Цей довідник створений власними силами</summary>
      
    
    
    
    <category term="Notes" scheme="https://ooge0.github.io/hexo-blog/categories/Notes/"/>
    
    
    <category term="nst" scheme="https://ooge0.github.io/hexo-blog/tags/nst/"/>
    
  </entry>
  
</feed>
